{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The attached data files are part of the UK Road Safety Data for 2019, available from [the UK Department for Transport](https://data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-safety-data). The dataset contains three types of files: one with records of accidents, the other with vehicles, and the third on casualties. \n",
    "\n",
    "We will create a new dataset from these, where for each vehicle, there is information on the age of the vehicle, severity of the accident, weather conditions, and the date of the accident. The relevant information is kept in the first two files:\n",
    "\n",
    "`Road Safety Data - Accidents_2019.csv`:\n",
    "\n",
    "* `Accident_Severity`\n",
    "* `Date`\n",
    "* `Weather_Conditions`\n",
    "\n",
    "`Road Safety Data - Vehicles_2019.csv`\n",
    "\n",
    "* `Age_of_Vehicle`\n",
    "\n",
    "To link vehicles to accidents, we will also need the `Accident_Index` column, present in both files.\n",
    "\n",
    "We will also perform several cleaning steps, check the quality of the data, and plot some of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Accidents data\n",
    "\n",
    "## 1.1 Load the data\n",
    "\n",
    "Read the Accidents file into a dataframe, find out its shape (the number of rows and columns) and the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 1.2. Select relevant columns\n",
    "\n",
    "We are going to use \"Accident_Index\", \"Accident_Severity\", \"Date\", \"Time\" and \"Weather_Conditions\", so delete the rest, for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Convert columns to correct data types\n",
    "\n",
    "1. Convert `Date` to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[:, 'Date'] = pd.to_datetime(df1['Date'], format=\"???\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Replace `Weather_conditions` to contain actual nominal values (the replacement values are in \"variable lookup.xls\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use nominal values for Weather conditions\n",
    "replacement_dict = {\n",
    "    1: \"Fine no high winds\",\n",
    "    2: \"Raining no high winds\",\n",
    "    3: \"Snowing no high winds\",\n",
    "    4: \"Fine + high winds\",\n",
    "    5: \"Raining + high winds\",\n",
    "    6: \"Snowing + high winds\",\n",
    "    7: \"Fog or mist\",\n",
    "    8: \"Other\",\n",
    "    9: \"Unknown\",\n",
    "    -1: \"Data missing or out of range\"\n",
    "}\n",
    "df1.loc[:, 'Weather_Conditions'] = df1['Weather_Conditions'].map(replacement_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the values in `Weather_Conditions`, we see that each cell encodes two categories: precipitation and wind. So let's separate them, i.e., create a new column with only wind information (\"True\" for wind, \"False\" for no wind):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column called high winds\n",
    "def func(row):\n",
    "    \"\"\"Return True is high winds, False otherwise\n",
    "    \"\"\"\n",
    "    ???\n",
    "    return result\n",
    "\n",
    "df1[\"high_winds\"] = df1.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"high winds\" from Weather_Conditions\n",
    "df1[\"Weather_Conditions\"] = df1[\"Weather_Conditions\"].str.replace(\" no high winds\", \"\", regex=False)\n",
    "df1[\"Weather_Conditions\"] = df1[\"Weather_Conditions\"].str.replace(\" + high winds\", \"\", regex=False)\n",
    "\n",
    "# rename Weather_Conditions to \"precipitation\"\n",
    "df1 = df1.rename(columns={\"Weather_Conditions\": \"precipitation\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace \"Unknown\" and \"Data missing or out of range\" with NaN, so later on we can deal with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['precipitation'] = df1['precipitation'].replace(\"Unknown\", np.NaN)\n",
    "df1['precipitation'] = df1['precipitation'].replace(\"Data missing or out of range\", np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Replace `Accident_Severity` to contain nominal values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {\n",
    "    1: \"Fatal\",\n",
    "    2: \"Serious\",\n",
    "    3: \"Slight\"\n",
    "}\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vehicle data\n",
    "\n",
    "## 2.1. Load data\n",
    "\n",
    "Extract the vehicle age from the vehicle file. This information will then be linked with the data on accidents from the accidents dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need only two columns: accident index and vehicle age, so we can use the usecol attribute:\n",
    "df2 = pd.read_csv(??? + \"/Road Safety Data - Vehicles 2019.csv\",\n",
    "                  usecols=[\"Accident_Index\", \"Age_of_Vehicle\"])\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there are \"-1\" values. Most likely, they indicate missing values. So replace them with `np.NaN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Age_of_Vehicle\"] = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Join the two dataframes\n",
    "\n",
    "The first df contains unique accidents as rows, while the second df contains all vehicles involved in the accidents as rows, i.e. multiple vehicles can map to the same accident. The `Accident_Index` column is present in both dataframes, and can help us link vehicles to accidents.\n",
    "\n",
    "So we need to create a new dataframe where each row is a vehicle, the first column is its age (from the vehicles dataframe), and the rest of the columns are taken from the accidents dataframe, containing precipiations, wind, and date of the accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can confirm that the number of unique accident indices in df2 is the same as the number of\n",
    "# unique accidents in df1\n",
    "len(df2['Accident_Index'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge two dataframes, on a column, we can use `pd.merge`. It works as follows:\n",
    "\n",
    "`result = pd.merge(left, right, on='key')`\n",
    "\n",
    "<img src=\"https://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_on_key.png\">\n",
    "\n",
    "That is, given two tables, \"left\" and \"right\", we merge them on the column called `key`. The result is the third dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another important attribute for `pd.merge`: `how`. If the keys do not correspond exactly between the two dataframes, it can help specify how the merge should occur. It takes the following values:\n",
    "* `left`: use keys in the first dataframe only and attach records from the second dataframe only for matching keys\n",
    "* `right`: use keys in the second dataframe only and attach records from the first dataframe only for matching keys\n",
    "* `inner`: use the intersection of the keys in the two dataframes (this is the default value)\n",
    "* `outer`: use the union of the keys in the two dataframe\n",
    "\n",
    "More details in the pandas [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html), see the \"Brief primer on merge methods (relational algebra)\".\n",
    "\n",
    "We need to attach columns from accidents (df1) to the vehicle dataframe (df2). The \"Accident_Index\" column from df2 is the basis for the merge (the column is indicated with the \"on\" argument):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df1, df2, on=\"Accident_Index\", how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of rows in the new dataframe is the same as in df2\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Drop missing values\n",
    "\n",
    "Drop those rows, where at least one column has an NaN value (this is the default behavior of `dropna` so we don't need to specify any arguments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???\n",
    "\n",
    "# The number of rows now\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Display unique values\n",
    "\n",
    "We can print unique values (e.g., using `value_counts`) or plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accident Severity\n",
    "df[\"Accident_Severity\"].value_counts().plot(kind=\"bar\", rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precipitation\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High winds\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age of vehicle in a histogram\n",
    "# Using logarithmic scale for the y-axis, as there are very many new cars\n",
    "df[\"Age_of_Vehicle\"].plot.hist(logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Daily counts\n",
    "\n",
    "Count number of vehicles involved in accidents per day. We can choose any column to select the counts, e.g. \"Accident_Index\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.groupby(df[\"Date\"]).count()[\"Accident_Index\"]\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it, use a wider figure\n",
    "counts.plot(figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Convert nominal values to numerical\n",
    "\n",
    "In order to use a nominal value within, e.g., a linear regression model, it needs to be converted to a numerical value. It can be achieved with `pd.get_dummies`. Let's convert the precipitation column (we use `drop_first=True` to avoid perfect multicollinearity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df['precipitation'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign these as columns in df\n",
    "df_tmp = pd.get_dummies(df['precipitation'], drop_first=True)\n",
    "for c in df_tmp.columns:\n",
    "    df[c] = df_tmp[c]\n",
    "    \n",
    "# delete the precipitation column\n",
    "del df['precipitation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Convert numerical values to nominal\n",
    "\n",
    "Create a nominal category, holding the age group of the vehicle. We'd like 3 age groups, named \"new\", \"medium\" and \"old\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_groups = pd.cut(df['Age_of_Vehicle'], bins=3, labels=[\"new\", \"medium\", \"old\"])\n",
    "age_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age_group\"] = age_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
