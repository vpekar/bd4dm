{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook shows an example how text files, labelled for sentiment (positive or negative), can be converted to a tabular format and then used to train a machine learning model capable of classifying new texts by sentiment.\n",
    "\n",
    "As an example, we will use a corpus of movie reviews first used in Pang and Lee (2004), for details see [here](http://www.cs.cornell.edu/people/pabo/movie-review-data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T10:59:17.901604Z",
     "start_time": "2023-03-03T10:59:15.859686Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting logging to print only error messages of sklearnex\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"SKLEARNEX\").setLevel(logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# execution time\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "If the data has not been downloaded before, download it, and save to a folder called \"datasets\", alongside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:04:47.311401Z",
     "start_time": "2023-03-03T11:03:49.320767Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import tarfile\n",
    "\n",
    "url = \"https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\"\n",
    "    \n",
    "def download_data(url):\n",
    "    \"\"\"Download the data and extract the mo\n",
    "    \"\"\"\n",
    "    \n",
    "    # if the \"datasets\" folder does not exist, create it\n",
    "    if not os.path.exists(\"datasets\"):\n",
    "        os.makedirs(\"datasets\")\n",
    "    \n",
    "    # if the archived file does not exist, download it\n",
    "    if not os.path.exists(\"datasets/review_polarity.tar.gz\"):\n",
    "        urllib.request.urlretrieve(url, \"datasets/review_polarity.tar.gz\")\n",
    "    \n",
    "    # if the unpacked file does not exist, unpack it\n",
    "    if not os.path.exists(\"datasets/txt_sentoken\"):\n",
    "        infile = tarfile.open(\"datasets/review_polarity.tar.gz\")\n",
    "        infile.extractall(path=\"datasets\")\n",
    "        infile.close()\n",
    "\n",
    "download_data(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above will produce a folder inside \"datasets\", called \"txt_sentoken\". That folder will contain two subfolders - \"pos\" (containing 1000 files manually labelled as positive) and \"neg\" (containing 1000 files manually labelled as \"negative\"). Each file is a separate movie review, after minimal normalization (inserting spaces around punctuation symbols, lower-casing all words, etc).\n",
    "\n",
    "We will use Scikit-learn's `load_files` function to load these data into a format that can be input directly into other scikit-learn tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:15.801419Z",
     "start_time": "2023-03-03T11:07:00.418776Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "# loading all files. \n",
    "movie = load_files(\"./datasets/txt_sentoken/\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:32.378066Z",
     "start_time": "2023-03-03T11:07:32.356125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:33.128797Z",
     "start_time": "2023-03-03T11:07:33.121815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target names (\"classes\") are automatically generated from subfolder names\n",
    "movie.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:34.543297Z",
     "start_time": "2023-03-03T11:07:34.521356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so called dark thriller , the devil ( gabriel byrne ) has come upon earth , to impregnate a woman ( robin tunney ) which happens every 1000 years , and basically destroy the world , but apparently god has chosen one man , and that one man is jericho cane ( arnold himself ) . \\nwith the help of a trusty sidekick ( kevin pollack ) , they will stop at nothing to let the devil take over the world ! \\nparts of this are actually so absurd , that they would fit right in with dogma . \\nyes , the film is that weak , but it's better than the other blockbuster right now ( sleepy hollow ) , but it makes the world is not enough look like a 4 star film . \\nanyway , this definitely doesn't seem like an arnold movie . \\nit just wasn't the type of film you can see him doing . \\nsure he gave us a few chuckles with his well known one-liners , but he seemed confused as to where his character and the film was going . \\nit's understandable , especially when the ending had to be changed according to some sources . \\naside form that , he still walked through it , much like he has in the past few films . \\ni'm sorry to say this arnold but maybe these are the end of your action days . \\nspeaking of action , where was it in this film ? \\nthere was hardly any explosions or fights . \\nthe devil made a few places explode , but arnold wasn't kicking some devil butt . \\nthe ending was changed to make it more spiritual , which undoubtedly ruined the film . \\ni was at least hoping for a cool ending if nothing else occurred , but once again i was let down . \\ni also don't know why the film took so long and cost so much . \\nthere was really no super affects at all , unless you consider an invisible devil , who was in it for 5 minutes tops , worth the overpriced budget . \\nthe budget should have gone into a better script , where at least audiences could be somewhat entertained instead of facing boredom . \\nit's pitiful to see how scripts like these get bought and made into a movie . \\ndo they even read these things anymore ? \\nit sure doesn't seem like it . \\nthankfully gabriel's performance gave some light to this poor film . \\nwhen he walks down the street searching for robin tunney , you can't help but feel that he looked like a devil . \\nthe guy is creepy looking anyway ! \\nwhen it's all over , you're just glad it's the end of the movie . \\ndon't bother to see this , if you're expecting a solid action flick , because it's neither solid nor does it have action . \\nit's just another movie that we are suckered in to seeing , due to a strategic marketing campaign . \\nsave your money and see the world is not enough for an entertaining experience . \\n\"\n"
     ]
    }
   ],
   "source": [
    "# First file seems to be about a Schwarzenegger movie. \n",
    "print(movie.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:37.161072Z",
     "start_time": "2023-03-03T11:07:37.149105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split\n",
    "\n",
    "The data has been loaded by scikit-learn into a special data structure, which is neither a numpy array or a pandas dataframe. Nonetheless, we can use scikit-learn's `train_test_split` to split the data into the training and test parts:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:39.577156Z",
     "start_time": "2023-03-03T11:07:39.407117Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "docs_train, docs_test, ytrain, ytest = train_test_split(movie.data, movie.target, \n",
    "                                                          test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:39.793373Z",
     "start_time": "2023-03-03T11:07:39.764772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 train and 400 test instances\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(docs_train)} train and {len(docs_test)} test instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation\n",
    "\n",
    "## Create Bag-of-Words representations\n",
    "\n",
    "`CountVectorizer` is a convenient facility to create bag-of-words representations of documents into a numpy array. Setting the arguments of the constructor class, we can configure the basic linguistic preprocessing steps that should be applied to it: supplying a custom tokenizer, stopword list, ngram range, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:42.442353Z",
     "start_time": "2023-03-03T11:07:42.432379Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "    strip_accents=\"unicode\", # convert accented chars to non-accented versions\n",
    "    lowercase=True,\n",
    "    tokenizer=None,        # None - use the default tokenizer\n",
    "    preprocessor=None,     # None - use the default preprocessor\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1,1),     # min and max range of ngrams\n",
    "    analyzer=\"word\",       # split the document into words, rather than e.g. characters\n",
    "    max_df=1.0,            # ignore words with df greater than the value (int represents count, \n",
    "                           # float represents proportion of documents)\n",
    "    min_df=1               # ignore words the df lower than the value (int represents count, \n",
    "                           # float represents proportion)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create an instance of `CountVectorizer` and then call its `fit_transform` method. It first \"fits\" on the data, i.e., extracts individual features from each document, as specified by the arguments to the constructor method (e.g., extract bigrams), and then \"transforms\" the data, i.e. creates numpy arrays where rows are documents, columns are features extracted from the documents, and values in the cells are counts of each feature in each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:46.641206Z",
     "start_time": "2023-03-03T11:07:45.679613Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit and tranform using training text \n",
    "docs_train_counts = count_vectorizer.fit_transform(docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:46.657291Z",
     "start_time": "2023-03-03T11:07:46.642115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 36034)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, there 1600 rows, one for each document, and 36304 columns, one for each feature.\n",
    "\n",
    "Let's check the datatype of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:48.790446Z",
     "start_time": "2023-03-03T11:07:48.782467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the data is stored in a special data structure called \"sparse matrix\", specifically Compressed Sparse Row. Because there are many zeros in each row (in the first row, there are 139 non-zero values, out of the total of 36034), the sparse matrix stores the data more efficiently and thus is able to represent relatively large text collections, without running into memory errors.\n",
    "\n",
    "We can, however, convert a sparse matrix to a normal, \"dense\", numpy array, if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.226903Z",
     "start_time": "2021-12-11T17:35:23.213937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train_counts[0, :].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted `count_vectorizer` stores also the vocabulary of the text collection on which it was fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.336608Z",
     "start_time": "2021-12-11T17:35:23.229894Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plot': 24052,\n",
       " 'realization': 25791,\n",
       " 'failing': 11553,\n",
       " 'classes': 5942,\n",
       " 'roommates': 27226,\n",
       " 'try': 33121,\n",
       " 'roomie': 27222,\n",
       " 'kill': 17734,\n",
       " 'school': 27926,\n",
       " 'charter': 5499,\n",
       " 'automatically': 2499,\n",
       " 'grants': 13861,\n",
       " 'grades': 13811,\n",
       " 'student': 30873,\n",
       " 'succeeds': 31043,\n",
       " 'suicide': 31109,\n",
       " 'critique': 7553,\n",
       " 'despite': 8653,\n",
       " 'film': 12018,\n",
       " 'interesting': 16674,\n",
       " 'premise': 24584,\n",
       " 'dark': 8005,\n",
       " 'subject': 30959,\n",
       " 'matter': 19840,\n",
       " 'movie': 21035,\n",
       " 'sucks': 31067,\n",
       " 'unfunny': 33708,\n",
       " 'boring': 3981,\n",
       " 'presents': 24632,\n",
       " 'tom': 32536,\n",
       " 'everett': 11073,\n",
       " 'scott': 28022,\n",
       " 'worst': 35631,\n",
       " 'acting': 859,\n",
       " 'performances': 23449,\n",
       " 'add': 910,\n",
       " 'completely': 6534,\n",
       " 'unsuccessful': 33966,\n",
       " 'romance': 27177,\n",
       " 'element': 10325,\n",
       " 'lame': 18102,\n",
       " 'corny': 7168,\n",
       " 'jokes': 17312,\n",
       " 'long': 18947,\n",
       " 'wait': 34801,\n",
       " 'setup': 28462,\n",
       " 'ending': 10603,\n",
       " 'takes': 31651,\n",
       " 'blackness': 3571,\n",
       " 'black': 3556,\n",
       " 'comedy': 6376,\n",
       " 'gonna': 13689,\n",
       " 'create': 7449,\n",
       " 'don': 9527,\n",
       " 'chicken': 5634,\n",
       " 'end': 10588,\n",
       " 'bad': 2674,\n",
       " 'things': 32187,\n",
       " '10': 9,\n",
       " 'perfect': 23436,\n",
       " 'example': 11139,\n",
       " 've': 34306,\n",
       " 'got': 13764,\n",
       " 'trite': 33019,\n",
       " 'mtv': 21073,\n",
       " 'creation': 7453,\n",
       " 'worthy': 35637,\n",
       " 'barely': 2864,\n",
       " 'laughed': 18247,\n",
       " 'gags': 13030,\n",
       " 'bong': 3897,\n",
       " 'contrived': 7015,\n",
       " 'repetitive': 26433,\n",
       " 'horrified': 15349,\n",
       " 'gratuitous': 13887,\n",
       " 'nudity': 21945,\n",
       " 'tossed': 32646,\n",
       " 'make': 19411,\n",
       " 'college': 6294,\n",
       " 'slap': 29273,\n",
       " 'free': 12750,\n",
       " 'shots': 28816,\n",
       " 'kids': 17720,\n",
       " 'worth': 35632,\n",
       " 'rental': 26395,\n",
       " 'fellas': 11839,\n",
       " 'skip': 29222,\n",
       " 'altogether': 1434,\n",
       " 'little': 18809,\n",
       " 'known': 17892,\n",
       " 'facts': 11535,\n",
       " 'stars': 30404,\n",
       " 'auditions': 2433,\n",
       " 'thing': 32181,\n",
       " 'feature': 11789,\n",
       " 'role': 27156,\n",
       " 'director': 9001,\n",
       " 'hanks': 14450,\n",
       " 'opposed': 22362,\n",
       " 'hiring': 15073,\n",
       " 'fact': 11524,\n",
       " 'passed': 23129,\n",
       " '15': 56,\n",
       " 'years': 35813,\n",
       " 'ago': 1177,\n",
       " 'wasn': 34946,\n",
       " 'wife': 35319,\n",
       " 'rita': 27022,\n",
       " 'wilson': 35363,\n",
       " 'saw': 27779,\n",
       " 'audition': 2431,\n",
       " 'tape': 31736,\n",
       " 'decided': 8178,\n",
       " 'cute': 7809,\n",
       " 'risk': 27013,\n",
       " 'actor': 873,\n",
       " 'played': 23991,\n",
       " 'cooper': 7093,\n",
       " 'mark': 19651,\n",
       " 'paul': 23215,\n",
       " 'gosselaar': 13761,\n",
       " 'best': 3357,\n",
       " 'having': 14640,\n",
       " 'character': 5447,\n",
       " 'zack': 35919,\n",
       " 'morris': 20922,\n",
       " 'tv': 33229,\n",
       " 'saved': 27762,\n",
       " 'bell': 3237,\n",
       " 'parents': 23043,\n",
       " 'dutch': 10004,\n",
       " 'named': 21314,\n",
       " 'hans': 14461,\n",
       " 'paula': 23216,\n",
       " 'guessed': 14149,\n",
       " 'alan': 1265,\n",
       " 'cohn': 6221,\n",
       " 'shot': 28814,\n",
       " 'directing': 8995,\n",
       " 'enduring': 10619,\n",
       " 'mariah': 19626,\n",
       " 'carey': 5038,\n",
       " 'debut': 8143,\n",
       " 'glitter': 13547,\n",
       " 'reminded': 26326,\n",
       " 'bit': 3529,\n",
       " 'chris': 5752,\n",
       " 'rock': 27114,\n",
       " 'bigger': 3434,\n",
       " 'blacker': 3559,\n",
       " 'response': 26624,\n",
       " 'women': 35521,\n",
       " 'saying': 27788,\n",
       " 'raise': 25556,\n",
       " 'child': 5644,\n",
       " 'man': 19470,\n",
       " 'says': 27792,\n",
       " 'drive': 9819,\n",
       " 'car': 5005,\n",
       " 'feet': 11823,\n",
       " 'mean': 19996,\n",
       " 'say': 27786,\n",
       " 'certainly': 5352,\n",
       " 'sure': 31272,\n",
       " 'plenty': 24037,\n",
       " 'pop': 24246,\n",
       " 'star': 30378,\n",
       " 'vehicles': 34322,\n",
       " 'beatles': 3078,\n",
       " 'hard': 14493,\n",
       " 'day': 8067,\n",
       " 'night': 21678,\n",
       " 'spice': 30022,\n",
       " 'girls': 13455,\n",
       " 'world': 35602,\n",
       " 'vapidly': 34264,\n",
       " 'pointless': 24131,\n",
       " 'laughable': 18245,\n",
       " 'complete': 6532,\n",
       " 'tripe': 33004,\n",
       " 'ludicrous': 19132,\n",
       " 'start': 30408,\n",
       " 'story': 30675,\n",
       " 'gruesomely': 14104,\n",
       " 'predictable': 24539,\n",
       " 'offensive': 22188,\n",
       " 'inexplicably': 16291,\n",
       " 'set': 28447,\n",
       " '80s': 366,\n",
       " 'period': 23467,\n",
       " 'piece': 23768,\n",
       " 'really': 25797,\n",
       " 'shows': 28853,\n",
       " 'sign': 28964,\n",
       " 'chicks': 5636,\n",
       " 'leg': 18405,\n",
       " 'warmers': 34909,\n",
       " 'worse': 35622,\n",
       " 'speaking': 29945,\n",
       " 'late': 18227,\n",
       " '90s': 382,\n",
       " 'hip': 15059,\n",
       " 'hop': 15300,\n",
       " 'slang': 29272,\n",
       " '1983': 179,\n",
       " 'meant': 20012,\n",
       " 'partially': 23087,\n",
       " 'autobiographical': 2494,\n",
       " 'plays': 24003,\n",
       " 'billie': 3464,\n",
       " 'frank': 12704,\n",
       " 'young': 35878,\n",
       " 'singer': 29075,\n",
       " 'new': 21580,\n",
       " 'york': 35870,\n",
       " 'struggles': 30850,\n",
       " 'overcome': 22656,\n",
       " 'rough': 27293,\n",
       " 'childhood': 5648,\n",
       " 'abandonment': 598,\n",
       " 'alcoholic': 1292,\n",
       " 'mother': 20960,\n",
       " 'influential': 16344,\n",
       " 'club': 6104,\n",
       " 'dj': 9411,\n",
       " 'julian': 17427,\n",
       " 'dice': 8836,\n",
       " 'lucky': 19127,\n",
       " 'max': 19871,\n",
       " 'beesley': 3152,\n",
       " 'playing': 24000,\n",
       " 'mix': 20649,\n",
       " 'puff': 25178,\n",
       " 'daddy': 7874,\n",
       " 'robert': 27085,\n",
       " 'niro': 21726,\n",
       " 'hears': 14730,\n",
       " 'sing': 29070,\n",
       " 'track': 32723,\n",
       " 'decides': 8181,\n",
       " 'predictably': 24540,\n",
       " 'rapid': 25647,\n",
       " 'succession': 31048,\n",
       " 'fall': 11594,\n",
       " 'starts': 30416,\n",
       " 'hitting': 15116,\n",
       " 'big': 3430,\n",
       " 'gets': 13355,\n",
       " 'jealous': 17133,\n",
       " 'like': 18667,\n",
       " 'ass': 2198,\n",
       " 'suddenly': 31071,\n",
       " 'roller': 27163,\n",
       " 'coaster': 6150,\n",
       " 'superstardom': 31225,\n",
       " 'meantime': 20013,\n",
       " 'emotional': 10506,\n",
       " 'hunt': 15587,\n",
       " 'missing': 20603,\n",
       " 'mom': 20754,\n",
       " 'won': 35524,\n",
       " 'away': 2569,\n",
       " 'honestly': 15252,\n",
       " 'just': 17478,\n",
       " 'think': 32188,\n",
       " 'unicorns': 33726,\n",
       " 'rainbows': 25542,\n",
       " 'll': 18836,\n",
       " 'figure': 11996,\n",
       " 'screams': 28064,\n",
       " 'camp': 4861,\n",
       " 'fun': 12928,\n",
       " 'filmmakers': 12031,\n",
       " 'thought': 32229,\n",
       " 'making': 19419,\n",
       " 'bulk': 4520,\n",
       " 'weepy': 35087,\n",
       " 'dramatic': 9717,\n",
       " 'better': 3380,\n",
       " 'mistake': 20617,\n",
       " 'brief': 4280,\n",
       " 'attempts': 2374,\n",
       " 'comic': 6388,\n",
       " 'relief': 26267,\n",
       " 'scene': 27859,\n",
       " 'effeminate': 10220,\n",
       " 'russian': 27444,\n",
       " 'sounding': 29842,\n",
       " 'wacky': 34767,\n",
       " 'filming': 12029,\n",
       " 'music': 21202,\n",
       " 'video': 34481,\n",
       " 'lead': 18322,\n",
       " 'balloons': 2760,\n",
       " 'instead': 16570,\n",
       " 'audience': 2425,\n",
       " 'screening': 28072,\n",
       " 'tended': 31967,\n",
       " 'laugh': 18244,\n",
       " 'loudest': 19035,\n",
       " 'scenes': 27861,\n",
       " 'brings': 4313,\n",
       " 'good': 13695,\n",
       " 'said': 27552,\n",
       " 'primarily': 24725,\n",
       " 'seen': 28249,\n",
       " 'wide': 35297,\n",
       " 'eyed': 11475,\n",
       " 'deer': 8258,\n",
       " 'headlights': 14695,\n",
       " 'look': 18967,\n",
       " 'frozen': 12872,\n",
       " 'face': 11504,\n",
       " 'actually': 884,\n",
       " 'looks': 18975,\n",
       " 'scared': 27830,\n",
       " 'love': 19055,\n",
       " 'wonder': 35526,\n",
       " 'writing': 35695,\n",
       " 'isn': 16974,\n",
       " 'dialogue': 8811,\n",
       " 'hackneyed': 14291,\n",
       " 'watered': 34976,\n",
       " 'virginal': 34591,\n",
       " 'target': 31757,\n",
       " 'probably': 24781,\n",
       " 'impossible': 15997,\n",
       " 'pull': 25190,\n",
       " 'aplomb': 1823,\n",
       " 'characters': 5459,\n",
       " 'couldn': 7248,\n",
       " 'written': 35697,\n",
       " 'absurdly': 699,\n",
       " 'members': 20126,\n",
       " 'barbie': 2852,\n",
       " 'playset': 24004,\n",
       " 'important': 15986,\n",
       " 'swoons': 31492,\n",
       " 'time': 32390,\n",
       " 'record': 25943,\n",
       " 'executive': 11224,\n",
       " 'demo': 8446,\n",
       " 'oh': 22216,\n",
       " 'team': 31835,\n",
       " 'listens': 18785,\n",
       " 'morning': 20903,\n",
       " 'device': 8755,\n",
       " 'painful': 22863,\n",
       " 'watching': 34970,\n",
       " 'appear': 1855,\n",
       " 'waste': 34950,\n",
       " 'wrong': 35698,\n",
       " 'pains': 22868,\n",
       " 'ego': 10241,\n",
       " 'sanity': 27672,\n",
       " 'fragile': 12670,\n",
       " 'condition': 6669,\n",
       " 'days': 8072,\n",
       " 'evidenced': 11087,\n",
       " 'multiple': 21129,\n",
       " 'hospital': 15375,\n",
       " 'stays': 30454,\n",
       " 'suffer': 31076,\n",
       " 'negative': 21485,\n",
       " 'reviews': 26789,\n",
       " 'likely': 18672,\n",
       " 'heard': 14726,\n",
       " 'priest': 24712,\n",
       " 'rabbi': 25453,\n",
       " 'dosage': 9604,\n",
       " 'featherweight': 11786,\n",
       " 'charm': 5487,\n",
       " 'sprinkled': 30185,\n",
       " 'keeping': 17607,\n",
       " 'faith': 11577,\n",
       " 'fluffy': 12383,\n",
       " 'thoroughly': 32222,\n",
       " 'glazed': 13510,\n",
       " 'sense': 28343,\n",
       " 'innocuous': 16468,\n",
       " 'innocence': 16464,\n",
       " 'cheer': 5561,\n",
       " 'regarding': 26114,\n",
       " 'moral': 20865,\n",
       " 'topics': 32591,\n",
       " 'religion': 26271,\n",
       " 'romantic': 27187,\n",
       " 'triangle': 32955,\n",
       " 'causes': 5235,\n",
       " 'collide': 6298,\n",
       " 'head': 14680,\n",
       " 'youngsters': 35883,\n",
       " 'brian': 4262,\n",
       " 'finn': 12091,\n",
       " 'jacob': 17036,\n",
       " 'schramm': 27942,\n",
       " 'anna': 1699,\n",
       " 'reilly': 26181,\n",
       " 'inseparable': 16507,\n",
       " 'trio': 33002,\n",
       " 'friendship': 12817,\n",
       " 'progressed': 24880,\n",
       " 'compassion': 6489,\n",
       " 'shower': 28842,\n",
       " 'support': 31250,\n",
       " 'feel': 11815,\n",
       " 'excluded': 11193,\n",
       " 'tragedy': 32748,\n",
       " 'soon': 29783,\n",
       " 'struck': 30841,\n",
       " 'forced': 12516,\n",
       " 'adults': 1028,\n",
       " 'edward': 10200,\n",
       " 'norton': 21842,\n",
       " 'ben': 3271,\n",
       " 'stiller': 30573,\n",
       " 'hold': 15162,\n",
       " 'similar': 29021,\n",
       " 'contrastive': 7005,\n",
       " 'jobs': 17271,\n",
       " 'likable': 18666,\n",
       " 'kind': 17760,\n",
       " 'hearted': 14739,\n",
       " 'father': 11724,\n",
       " 'catholic': 5213,\n",
       " 'spry': 30204,\n",
       " 'outgoing': 22556,\n",
       " 'acts': 878,\n",
       " 'jewish': 17218,\n",
       " 'basketball': 2955,\n",
       " 'court': 7308,\n",
       " 'refer': 26053,\n",
       " 'god': 13618,\n",
       " 'squad': 30226,\n",
       " 'relationship': 26235,\n",
       " 'field': 11964,\n",
       " 'abides': 626,\n",
       " 'principle': 24742,\n",
       " 'celibacy': 5293,\n",
       " 'reached': 25749,\n",
       " 'point': 24124,\n",
       " 'finding': 12063,\n",
       " 'bride': 4272,\n",
       " 'practically': 24457,\n",
       " 'mandatory': 19486,\n",
       " 'changes': 5416,\n",
       " 'jenna': 17169,\n",
       " 'elfman': 10338,\n",
       " 'returns': 26742,\n",
       " 'visit': 34626,\n",
       " 'chums': 5795,\n",
       " 'workaholic': 35583,\n",
       " 'devotes': 8781,\n",
       " 'endless': 10605,\n",
       " 'hours': 15417,\n",
       " 'week': 35076,\n",
       " 'business': 4659,\n",
       " 'does': 9455,\n",
       " 'spare': 29912,\n",
       " 'reminisce': 26333,\n",
       " 'ecstatic': 10146,\n",
       " 'seeing': 28239,\n",
       " 'elementary': 10326,\n",
       " 'sweetheart': 31440,\n",
       " 'oddball': 22150,\n",
       " 'ingredients': 16393,\n",
       " 'cocktail': 6180,\n",
       " 'bound': 4036,\n",
       " 'awkward': 2581,\n",
       " 'central': 5328,\n",
       " 'predicting': 24543,\n",
       " 'outcome': 22540,\n",
       " 'entirely': 10767,\n",
       " 'difficult': 8889,\n",
       " 'open': 22323,\n",
       " 'entertaining': 10745,\n",
       " 'refreshingly': 26091,\n",
       " 'relaxed': 26243,\n",
       " 'travels': 32888,\n",
       " 'en': 10548,\n",
       " 'route': 27316,\n",
       " 'emerged': 10473,\n",
       " 'finest': 12071,\n",
       " 'flexibly': 12292,\n",
       " 'versatile': 34402,\n",
       " 'actors': 874,\n",
       " 'hollywood': 15192,\n",
       " 'success': 31044,\n",
       " 'sparked': 29917,\n",
       " 'critically': 7542,\n",
       " 'lauded': 18243,\n",
       " '1996': 193,\n",
       " 'thriller': 32263,\n",
       " 'primal': 24723,\n",
       " 'fear': 11768,\n",
       " 'shockingly': 28763,\n",
       " 'bitter': 3544,\n",
       " 'roles': 27157,\n",
       " 'american': 1507,\n",
       " 'history': 15094,\n",
       " 'recently': 25875,\n",
       " 'david': 8054,\n",
       " 'fincher': 12061,\n",
       " 'vicious': 34459,\n",
       " 'fight': 11985,\n",
       " 'quaint': 25336,\n",
       " 'peculiar': 23295,\n",
       " 'choice': 5702,\n",
       " 'slips': 29375,\n",
       " 'chair': 5380,\n",
       " 'incisive': 16108,\n",
       " 'resourceful': 26605,\n",
       " 'approach': 1907,\n",
       " 'helps': 14859,\n",
       " 'additional': 923,\n",
       " 'craft': 7387,\n",
       " 'surprisingly': 31304,\n",
       " 'perceptive': 23423,\n",
       " 'screenplay': 28074,\n",
       " 'stuart': 30860,\n",
       " 'blumberg': 3762,\n",
       " 'weighing': 35091,\n",
       " 'aspect': 2189,\n",
       " 'unanimously': 33389,\n",
       " 'impressive': 16020,\n",
       " 'directorial': 9003,\n",
       " 'addition': 922,\n",
       " 'pushes': 25300,\n",
       " 'right': 26950,\n",
       " 'buttons': 4703,\n",
       " 'sheepish': 28649,\n",
       " 'generating': 13260,\n",
       " 'screen': 28069,\n",
       " 'presence': 24624,\n",
       " 'zipper': 35997,\n",
       " 'guy': 14252,\n",
       " 'mary': 19727,\n",
       " 'firm': 12122,\n",
       " 'funny': 12962,\n",
       " 'boasting': 3801,\n",
       " 'fully': 12921,\n",
       " 'ripened': 26996,\n",
       " 'maturity': 19852,\n",
       " 'perky': 23485,\n",
       " 'repetition': 26429,\n",
       " 'grow': 14085,\n",
       " 'tiresome': 32453,\n",
       " 'occasionally': 22114,\n",
       " 'case': 5128,\n",
       " 'dharma': 8796,\n",
       " 'greg': 13952,\n",
       " 'perfectly': 23441,\n",
       " 'rambunctious': 25582,\n",
       " 'remaining': 26299,\n",
       " 'cast': 5149,\n",
       " 'offer': 22190,\n",
       " 'fine': 12066,\n",
       " 'anne': 1704,\n",
       " 'bancroft': 2780,\n",
       " 'animated': 1679,\n",
       " 'milos': 20422,\n",
       " 'forman': 12589,\n",
       " 'elderly': 10294,\n",
       " 'quick': 25389,\n",
       " 'contribute': 7007,\n",
       " 'intelligent': 16633,\n",
       " 'advice': 1056,\n",
       " 'date': 8041,\n",
       " 'flick': 12295,\n",
       " 'perfection': 23439,\n",
       " 'word': 35570,\n",
       " 'associate': 2259,\n",
       " 'general': 13251,\n",
       " 'turbulence': 33179,\n",
       " 'process': 24797,\n",
       " 'lift': 18644,\n",
       " 'numerous': 21967,\n",
       " 'failed': 11552,\n",
       " 'establishing': 10976,\n",
       " 'situation': 29134,\n",
       " 'cloud': 6095,\n",
       " 'projected': 24889,\n",
       " 'ahead': 1194,\n",
       " 'settle': 28456,\n",
       " 'cheerful': 5563,\n",
       " 'created': 7450,\n",
       " 'enormously': 10705,\n",
       " 'lovable': 19053,\n",
       " 'personalities': 23537,\n",
       " 'enjoy': 10674,\n",
       " 'interaction': 16658,\n",
       " 'understand': 33560,\n",
       " 'various': 34280,\n",
       " 'dilemmas': 8928,\n",
       " 'humbled': 15532,\n",
       " 'realize': 25793,\n",
       " 'rings': 26983,\n",
       " 'true': 33089,\n",
       " 'excluding': 11194,\n",
       " 'acceptable': 736,\n",
       " 'lack': 18042,\n",
       " 'spontaneity': 30122,\n",
       " 'preceding': 24505,\n",
       " 'entanglements': 10733,\n",
       " 'nonetheless': 21794,\n",
       " 'narrowly': 21356,\n",
       " 'mishandled': 20573,\n",
       " 'finale': 12047,\n",
       " 'wipe': 35428,\n",
       " 'smile': 29475,\n",
       " 'highly': 15003,\n",
       " 'enjoyable': 10676,\n",
       " 'observant': 22069,\n",
       " 'surveying': 31323,\n",
       " 'questions': 25382,\n",
       " 'aww': 2590,\n",
       " 'hell': 14833,\n",
       " 'quality': 25343,\n",
       " 'quite': 25427,\n",
       " 'heaven': 14761,\n",
       " 'sent': 28361,\n",
       " 'charmer': 5490,\n",
       " 'revive': 26806,\n",
       " 'potentially': 24403,\n",
       " 'tired': 32448,\n",
       " 'filmmaking': 12032,\n",
       " 'genre': 13289,\n",
       " 'altman': 1432,\n",
       " 'cookie': 7078,\n",
       " 'fortune': 12627,\n",
       " 'rare': 25666,\n",
       " 'depend': 8524,\n",
       " 'sentimentality': 28369,\n",
       " 'uplifting': 34053,\n",
       " 'viewers': 34506,\n",
       " 'sunny': 31173,\n",
       " 'delightful': 8387,\n",
       " 'dreamy': 9769,\n",
       " 'filled': 12011,\n",
       " 'lovely': 19064,\n",
       " 'skillful': 29206,\n",
       " 'direction': 8996,\n",
       " 'topped': 32595,\n",
       " 'understated': 33567,\n",
       " 'clever': 6008,\n",
       " 'extraordinary': 11439,\n",
       " 'script': 28095,\n",
       " 'ensemble': 10716,\n",
       " 'slowly': 29408,\n",
       " 'introduces': 16794,\n",
       " 'residing': 26567,\n",
       " 'southern': 29863,\n",
       " 'town': 32698,\n",
       " 'called': 4817,\n",
       " 'holly': 15191,\n",
       " 'springs': 30181,\n",
       " 'meet': 20075,\n",
       " 'willie': 35351,\n",
       " 'charles': 5480,\n",
       " 'dutton': 10009,\n",
       " 'honest': 15251,\n",
       " 'slight': 29353,\n",
       " 'drinking': 9811,\n",
       " 'habit': 14278,\n",
       " 'care': 5022,\n",
       " 'lady': 18066,\n",
       " 'nicknamed': 21648,\n",
       " 'losing': 19021,\n",
       " 'grip': 14008,\n",
       " 'loneliness': 18941,\n",
       " 'despair': 8641,\n",
       " 'want': 34880,\n",
       " 'dead': 8087,\n",
       " 'husband': 15617,\n",
       " 'cut': 7806,\n",
       " 'camille': 4857,\n",
       " 'glenn': 13529,\n",
       " 'close': 6075,\n",
       " 'obsessively': 22087,\n",
       " 'play': 23985,\n",
       " 'sister': 29116,\n",
       " 'cora': 7133,\n",
       " 'julianne': 17430,\n",
       " 'moore': 20856,\n",
       " 'briefly': 4284,\n",
       " 'acquainted': 838,\n",
       " 'emma': 10493,\n",
       " 'liv': 18814,\n",
       " 'tyler': 33281,\n",
       " 'apparent': 1847,\n",
       " 'relative': 26237,\n",
       " 'teen': 31886,\n",
       " 'outcast': 22537,\n",
       " 'hope': 15301,\n",
       " 'real': 25777,\n",
       " 'place': 23921,\n",
       " 'live': 18815,\n",
       " 'fleetingly': 12275,\n",
       " 'lover': 19067,\n",
       " 'jason': 17112,\n",
       " 'donnell': 9546,\n",
       " 'ambitious': 1487,\n",
       " 'far': 11659,\n",
       " 'excitable': 11178,\n",
       " 'cop': 7103,\n",
       " 'quarter': 25355,\n",
       " 'hour': 15415,\n",
       " 'picture': 23759,\n",
       " 'motion': 20971,\n",
       " 'stare': 30384,\n",
       " 'hopefully': 15304,\n",
       " 'exclaims': 11190,\n",
       " 'come': 6365,\n",
       " 'puts': 25308,\n",
       " 'pillow': 23814,\n",
       " 'shoots': 28786,\n",
       " 'niece': 21663,\n",
       " 'stops': 30660,\n",
       " 'fruit': 12874,\n",
       " 'salad': 27576,\n",
       " 'bowl': 4062,\n",
       " 'comes': 6380,\n",
       " 'upstairs': 34085,\n",
       " 'finds': 12065,\n",
       " 'flips': 12321,\n",
       " 'convinced': 7064,\n",
       " 'disgrace': 9142,\n",
       " 'family': 11622,\n",
       " 'eats': 10113,\n",
       " 'note': 21869,\n",
       " 'convinces': 7065,\n",
       " 'slightly': 29356,\n",
       " 'slow': 29403,\n",
       " 'sweet': 31436,\n",
       " 'murder': 21168,\n",
       " 'makes': 19415,\n",
       " 'stages': 30303,\n",
       " 'scattering': 27851,\n",
       " 'jewelry': 17216,\n",
       " 'floor': 12345,\n",
       " 'breaking': 4204,\n",
       " 'cabinets': 4744,\n",
       " 'windows': 35384,\n",
       " 'doors': 9573,\n",
       " 'throwing': 32284,\n",
       " 'gun': 14205,\n",
       " 'yard': 35787,\n",
       " 'reasonable': 25816,\n",
       " 'suspect': 31338,\n",
       " 'immediately': 15888,\n",
       " 'taken': 31646,\n",
       " 'custody': 7800,\n",
       " 'jail': 17053,\n",
       " 'cell': 5295,\n",
       " 'know': 17886,\n",
       " 'didn': 8861,\n",
       " 'scrabble': 28034,\n",
       " 'sheriff': 28694,\n",
       " 'faithful': 11578,\n",
       " 'unperturbed': 33861,\n",
       " 'continues': 6972,\n",
       " 'subtle': 31023,\n",
       " 'manipulations': 19539,\n",
       " 'trying': 33122,\n",
       " 'cover': 7330,\n",
       " 'easter': 10099,\n",
       " 'begins': 3179,\n",
       " 'aptly': 1928,\n",
       " 'described': 8603,\n",
       " 'critic': 7540,\n",
       " 'renshaw': 26393,\n",
       " 'spin': 30047,\n",
       " 'fargo': 11668,\n",
       " 'funnier': 12960,\n",
       " 'coen': 6197,\n",
       " 'brothers': 4392,\n",
       " 'darker': 8008,\n",
       " 'somewhat': 29758,\n",
       " 'disturbing': 9353,\n",
       " 'overrated': 22735,\n",
       " 'escapade': 10932,\n",
       " 'ways': 35010,\n",
       " 'reminiscent': 26335,\n",
       " 'midnight': 20344,\n",
       " 'garden': 13117,\n",
       " 'evil': 11091,\n",
       " 'films': 12037,\n",
       " 'focus': 12423,\n",
       " 'eccentricities': 10119,\n",
       " 'residents': 26565,\n",
       " 'loads': 18847,\n",
       " 'observe': 22074,\n",
       " 'portion': 24305,\n",
       " 'fascinating': 11694,\n",
       " 'multi': 21121,\n",
       " 'dimensional': 8941,\n",
       " 'turns': 33201,\n",
       " 'insubstantial': 16598,\n",
       " 'terms': 32020,\n",
       " 'career': 5027,\n",
       " 'magnificent': 19355,\n",
       " 'performance': 23448,\n",
       " 'conniving': 6798,\n",
       " 'source': 29854,\n",
       " 'laughs': 18254,\n",
       " 'prolific': 24901,\n",
       " 'aunt': 2448,\n",
       " 'alexandria': 1314,\n",
       " 'endlessly': 10606,\n",
       " 'obsessed': 22081,\n",
       " 'dignity': 8917,\n",
       " 'equally': 10854,\n",
       " 'essential': 10969,\n",
       " 'handled': 14422,\n",
       " 'intangible': 16619,\n",
       " 'grace': 13797,\n",
       " 'veteran': 34422,\n",
       " 'thespian': 32160,\n",
       " 'mimic': 20427,\n",
       " 'leaves': 18361,\n",
       " 'feeling': 11818,\n",
       " 'warm': 34906,\n",
       " 'fuzzy': 13001,\n",
       " 'inside': 16514,\n",
       " 'ends': 10614,\n",
       " 'loved': 19058,\n",
       " 'light': 18650,\n",
       " 'kindhearted': 17766,\n",
       " 'project': 24888,\n",
       " 'intense': 16640,\n",
       " 'drama': 9715,\n",
       " 'gingerbread': 13438,\n",
       " 'took': 32575,\n",
       " 'tricky': 32978,\n",
       " 'enjoyed': 10678,\n",
       " 'talented': 31659,\n",
       " 'liked': 18670,\n",
       " 'south': 29860,\n",
       " 'everybody': 11078,\n",
       " 'related': 26230,\n",
       " 'cliche': 6013,\n",
       " 'inevitably': 16283,\n",
       " 'employed': 10531,\n",
       " 'draws': 9747,\n",
       " 'pleasing': 24024,\n",
       " 'effect': 10213,\n",
       " 'ol': 22230,\n",
       " 'practical': 24456,\n",
       " 'magic': 19340,\n",
       " 'misguided': 20569,\n",
       " 'high': 14994,\n",
       " 'profile': 24856,\n",
       " 'involved': 16877,\n",
       " 'embarrassing': 10439,\n",
       " 'clap': 5916,\n",
       " 'trap': 32857,\n",
       " 'sandra': 27655,\n",
       " 'bullock': 4534,\n",
       " 'nicole': 21656,\n",
       " 'kidman': 17708,\n",
       " 'sally': 27596,\n",
       " 'gillian': 13425,\n",
       " 'owens': 22797,\n",
       " 'sisters': 29118,\n",
       " 'line': 18727,\n",
       " 'witches': 35463,\n",
       " 'spanning': 29909,\n",
       " '200': 202,\n",
       " 'die': 8863,\n",
       " 'children': 5652,\n",
       " 'zany': 35940,\n",
       " 'aunts': 2450,\n",
       " 'stockard': 30609,\n",
       " 'channing': 5423,\n",
       " 'dianne': 8823,\n",
       " 'wiest': 35316,\n",
       " 'switch': 31484,\n",
       " 'present': 24626,\n",
       " 'stronger': 30835,\n",
       " 'rebellious': 25835,\n",
       " 'sibling': 28910,\n",
       " 'home': 15211,\n",
       " 'meets': 20078,\n",
       " 'abusive': 711,\n",
       " 'goran': 13735,\n",
       " 'visjnic': 34633,\n",
       " 'hometown': 15223,\n",
       " 'falls': 11600,\n",
       " 'caring': 5047,\n",
       " 'devastated': 8733,\n",
       " 'hit': 15096,\n",
       " 'truck': 33079,\n",
       " 'killed': 17736,\n",
       " 'minutes': 20503,\n",
       " 'calls': 4826,\n",
       " 'spat': 29930,\n",
       " 'accidentally': 749,\n",
       " 'desperation': 8647,\n",
       " 'bury': 4647,\n",
       " 'body': 3826,\n",
       " 'backyard': 2670,\n",
       " 'house': 15418,\n",
       " 'wildly': 35337,\n",
       " 'convoluted': 7068,\n",
       " 'subplots': 30988,\n",
       " 'involving': 16880,\n",
       " 'rising': 27012,\n",
       " 'exorcism': 11279,\n",
       " 'mention': 20168,\n",
       " 'spattering': 29935,\n",
       " 'whimsy': 35214,\n",
       " 'pretty': 24679,\n",
       " 'idea': 15723,\n",
       " 'messy': 20243,\n",
       " 'reflected': 26070,\n",
       " 'humor': 15552,\n",
       " 'astoundingly': 2296,\n",
       " 'flat': 12233,\n",
       " 'occasional': 22113,\n",
       " 'moments': 20759,\n",
       " 'touching': 32667,\n",
       " 'charming': 5491,\n",
       " 'way': 35004,\n",
       " 'bird': 3506,\n",
       " 'brained': 4119,\n",
       " 'spirit': 30063,\n",
       " 'taking': 31653,\n",
       " 'terribly': 32033,\n",
       " 'getting': 13357,\n",
       " 'reason': 25815,\n",
       " 'standing': 30360,\n",
       " 'attempt': 2371,\n",
       " 'flesh': 12279,\n",
       " 'actual': 879,\n",
       " 'people': 23400,\n",
       " 'goes': 13645,\n",
       " 'aidan': 1204,\n",
       " 'quinn': 25411,\n",
       " 'handsome': 14430,\n",
       " 'police': 24165,\n",
       " 'investigator': 16852,\n",
       " 'misfortune': 20566,\n",
       " 'opposite': 22365,\n",
       " '70': 344,\n",
       " 'minute': 20502,\n",
       " 'develop': 8738,\n",
       " 'service': 28436,\n",
       " 'moving': 21052,\n",
       " 'lines': 18736,\n",
       " 'headed': 14684,\n",
       " 'trouble': 33062,\n",
       " 'opening': 22326,\n",
       " 'credits': 7471,\n",
       " 'deeply': 8257,\n",
       " 'hated': 14608,\n",
       " 'akiva': 1256,\n",
       " 'goldsman': 13670,\n",
       " 'managed': 19472,\n",
       " 'destroy': 8663,\n",
       " 'batman': 2989,\n",
       " 'series': 28416,\n",
       " 'forever': 12560,\n",
       " 'robin': 27094,\n",
       " 'directed': 8994,\n",
       " 'griffin': 13986,\n",
       " 'dunne': 9971,\n",
       " 'year': 35806,\n",
       " 'clumsy': 6119,\n",
       " 'addicted': 916,\n",
       " 'meg': 20079,\n",
       " 'ryan': 27462,\n",
       " 'matthew': 19845,\n",
       " 'broderick': 4352,\n",
       " 'disliked': 9180,\n",
       " 'taste': 31777,\n",
       " 'talentless': 31660,\n",
       " 'filmmaker': 12030,\n",
       " 'tell': 31926,\n",
       " 'quit': 25426,\n",
       " 'ultimately': 33352,\n",
       " 'buried': 4607,\n",
       " 'rip': 26994,\n",
       " 'movies': 21048,\n",
       " 'woody': 35557,\n",
       " 'allen': 1365,\n",
       " 'bananas': 2779,\n",
       " 'martin': 19710,\n",
       " 'scorsese': 28015,\n",
       " 'woo': 35543,\n",
       " 'falling': 11598,\n",
       " 'def': 8259,\n",
       " 'jam': 17066,\n",
       " 'player': 23992,\n",
       " 'awful': 2576,\n",
       " 'booty': 3962,\n",
       " 'ok': 22227,\n",
       " 'embarassing': 10431,\n",
       " 'showing': 28848,\n",
       " 'african': 1128,\n",
       " 'americans': 1513,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary is just a dictionary, where keys are original words and values are their indices in the produced matrix. The vocabulary will be used internally by the fitted vectorizer, when we transform the test data, deriving a document-by-feature matrix, which has the same columns in the same order as the training data.\n",
    "\n",
    "Let's apply the fitted vectorizer also to the test data. Note we call the `transform` method, not `fit` or `fit_transform`, because the vectorizer has been fitted already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.877682Z",
     "start_time": "2021-12-11T17:35:23.339599Z"
    }
   },
   "outputs": [],
   "source": [
    "docs_test_counts = count_vectorizer.transform(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.892913Z",
     "start_time": "2021-12-11T17:35:23.880675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 36034)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_test_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 400 rows (one per document), but the same number of columns as the training data, 36034."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF weighting\n",
    "\n",
    "Further, we can transform the observed counts into TF-IDF weights in order to reflect the importance of every word in the document. This is achieved with `TfidfTransformer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.908388Z",
     "start_time": "2021-12-11T17:35:23.896418Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the transformer needs to be \"fitted\" on the training data and then the fitted transformer should be used to transform both the training and the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.987175Z",
     "start_time": "2021-12-11T17:35:23.912376Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit and transform the training set with \"fit_transform()\"\n",
    "docs_train_tfidf = tfidf_transformer.fit_transform(docs_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:24.003136Z",
     "start_time": "2021-12-11T17:35:23.989170Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform test\n",
    "docs_test_tfidf = tfidf_transformer.transform(docs_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize features\n",
    "\n",
    "Fit a scaler on the training set and use it to transform both the training and test sets. We'll use a `MaxAbsScaler` as it is capable of dealing with sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:24.066963Z",
     "start_time": "2021-12-11T17:35:24.006126Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler \n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "Xtrain = scaler.fit_transform(docs_train_tfidf)\n",
    "Xtest = scaler.transform(docs_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:24.082919Z",
     "start_time": "2021-12-11T17:35:24.069955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1600x36034 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 389594 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:24.098876Z",
     "start_time": "2021-12-11T17:35:24.085911Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "Classifying everything as \"pos\"\n",
    "\n",
    "*pos*:\n",
    "* precision: 800/1600 = 0.5\n",
    "* recall: 800/800 = 1.0\n",
    "* f-score: 2/(1/p + 1/r) = 0.66\n",
    "\n",
    "*neg*:\n",
    "* precision: 0/0 = 0.0\n",
    "* recall: 0/800 = 0.0\n",
    "* f-score: 2/(1/p + 1/r) = 0.0\n",
    "\n",
    "*Macro-averaged*:\n",
    "* precision: 0.25\n",
    "* recall: 0.5\n",
    "* **f-score: 0.33**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Precision: 0.254\n",
      "Recall: 0.500\n",
      "F score: 0.337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(Xtrain, ytrain)\n",
    "yhat = dummy_clf.predict(Xtrain)\n",
    "\n",
    "p, r, f, s = precision_recall_fscore_support(ytrain, yhat, average=\"macro\", zero_division=0.0)\n",
    "print(f\"Precision: {p:.3f}\")\n",
    "print(f\"Recall: {r:.3f}\")\n",
    "print(f\"F score: {f:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:36:20.848451Z",
     "start_time": "2021-12-11T17:35:24.102866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time HH:MM:SS: 0:00:43.547586\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=7)\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 3 x 3 = 9 combinations in the grid\n",
    "param_grid = {\n",
    "    'max_depth': [15, 30, 50],\n",
    "    'min_samples_split': [10, 20, 50],\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(dtree, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True)\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "print(\"Execution time HH:MM:SS:\", timedelta(seconds=timer() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:36:20.896361Z",
     "start_time": "2021-12-11T17:36:20.850446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>diff, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 20}</td>\n",
       "      <td>0.912413</td>\n",
       "      <td>0.652250</td>\n",
       "      <td>28.513711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 50}</td>\n",
       "      <td>0.876511</td>\n",
       "      <td>0.649245</td>\n",
       "      <td>25.928450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10}</td>\n",
       "      <td>0.927735</td>\n",
       "      <td>0.641545</td>\n",
       "      <td>30.848243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 50}</td>\n",
       "      <td>0.916266</td>\n",
       "      <td>0.640543</td>\n",
       "      <td>30.092016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10}</td>\n",
       "      <td>0.976244</td>\n",
       "      <td>0.639679</td>\n",
       "      <td>34.475545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 20}</td>\n",
       "      <td>0.952784</td>\n",
       "      <td>0.638564</td>\n",
       "      <td>32.979132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 50}</td>\n",
       "      <td>0.913624</td>\n",
       "      <td>0.637586</td>\n",
       "      <td>30.213491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 10}</td>\n",
       "      <td>0.979524</td>\n",
       "      <td>0.635997</td>\n",
       "      <td>35.070779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 20}</td>\n",
       "      <td>0.954968</td>\n",
       "      <td>0.634126</td>\n",
       "      <td>33.597160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       params  mean_train_score  \\\n",
       "1  {'max_depth': 15, 'min_samples_split': 20}          0.912413   \n",
       "2  {'max_depth': 15, 'min_samples_split': 50}          0.876511   \n",
       "0  {'max_depth': 15, 'min_samples_split': 10}          0.927735   \n",
       "8  {'max_depth': 50, 'min_samples_split': 50}          0.916266   \n",
       "3  {'max_depth': 30, 'min_samples_split': 10}          0.976244   \n",
       "4  {'max_depth': 30, 'min_samples_split': 20}          0.952784   \n",
       "5  {'max_depth': 30, 'min_samples_split': 50}          0.913624   \n",
       "6  {'max_depth': 50, 'min_samples_split': 10}          0.979524   \n",
       "7  {'max_depth': 50, 'min_samples_split': 20}          0.954968   \n",
       "\n",
       "   mean_test_score    diff, %  \n",
       "1         0.652250  28.513711  \n",
       "2         0.649245  25.928450  \n",
       "0         0.641545  30.848243  \n",
       "8         0.640543  30.092016  \n",
       "3         0.639679  34.475545  \n",
       "4         0.638564  32.979132  \n",
       "5         0.637586  30.213491  \n",
       "6         0.635997  35.070779  \n",
       "7         0.634126  33.597160  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)[['params', 'mean_train_score', 'mean_test_score']]\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:08.082930Z",
     "start_time": "2021-12-11T17:36:20.898319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time HH:MM:SS: 0:15:11.518075\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=7)\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 4 x 3 x 3 = 36 combinations in the grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_depth': [5, 15, 30],\n",
    "    'min_samples_split': [5, 10, 20]\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True)\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "print(\"Execution time HH:MM:SS:\", timedelta(seconds=timer() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:08.145332Z",
     "start_time": "2021-12-11T17:52:08.084929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>diff, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 500}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.815016</td>\n",
       "      <td>18.447407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 1000}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.811225</td>\n",
       "      <td>18.826733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 500}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.809618</td>\n",
       "      <td>18.987553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 1000}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.808318</td>\n",
       "      <td>19.117678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 500}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.808068</td>\n",
       "      <td>19.142700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 500}</td>\n",
       "      <td>0.996562</td>\n",
       "      <td>0.806829</td>\n",
       "      <td>19.038693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 1000}</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>0.806778</td>\n",
       "      <td>19.018431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 500}</td>\n",
       "      <td>0.994374</td>\n",
       "      <td>0.802435</td>\n",
       "      <td>19.302540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.801997</td>\n",
       "      <td>19.473118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 500}</td>\n",
       "      <td>0.996718</td>\n",
       "      <td>0.801635</td>\n",
       "      <td>19.572526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 1000}</td>\n",
       "      <td>0.996562</td>\n",
       "      <td>0.801081</td>\n",
       "      <td>19.615528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 200}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.799931</td>\n",
       "      <td>19.956897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 1000}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.799220</td>\n",
       "      <td>20.028016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.799159</td>\n",
       "      <td>20.034106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 200}</td>\n",
       "      <td>0.992187</td>\n",
       "      <td>0.796379</td>\n",
       "      <td>19.734917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 200}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.796306</td>\n",
       "      <td>20.319610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 1000}</td>\n",
       "      <td>0.994687</td>\n",
       "      <td>0.794892</td>\n",
       "      <td>20.086247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.994218</td>\n",
       "      <td>0.791815</td>\n",
       "      <td>20.358030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 200}</td>\n",
       "      <td>0.994843</td>\n",
       "      <td>0.791191</td>\n",
       "      <td>20.470726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.990312</td>\n",
       "      <td>0.789903</td>\n",
       "      <td>20.236967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}</td>\n",
       "      <td>0.954507</td>\n",
       "      <td>0.789168</td>\n",
       "      <td>17.321921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.993905</td>\n",
       "      <td>0.788087</td>\n",
       "      <td>20.708075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}</td>\n",
       "      <td>0.952944</td>\n",
       "      <td>0.787461</td>\n",
       "      <td>17.365452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.787153</td>\n",
       "      <td>21.223172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 1000}</td>\n",
       "      <td>0.946840</td>\n",
       "      <td>0.786694</td>\n",
       "      <td>16.913727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.785702</td>\n",
       "      <td>21.331414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 500}</td>\n",
       "      <td>0.946834</td>\n",
       "      <td>0.781563</td>\n",
       "      <td>17.455073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 500}</td>\n",
       "      <td>0.947302</td>\n",
       "      <td>0.779075</td>\n",
       "      <td>17.758488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 500}</td>\n",
       "      <td>0.941355</td>\n",
       "      <td>0.778959</td>\n",
       "      <td>17.251255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 200}</td>\n",
       "      <td>0.936194</td>\n",
       "      <td>0.778693</td>\n",
       "      <td>16.823497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.941362</td>\n",
       "      <td>0.774847</td>\n",
       "      <td>17.688799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.774678</td>\n",
       "      <td>22.483735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 200}</td>\n",
       "      <td>0.939950</td>\n",
       "      <td>0.769247</td>\n",
       "      <td>18.160941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.927887</td>\n",
       "      <td>0.762463</td>\n",
       "      <td>17.828081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.926176</td>\n",
       "      <td>0.760748</td>\n",
       "      <td>17.861371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.919736</td>\n",
       "      <td>0.758750</td>\n",
       "      <td>17.503473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              params  \\\n",
       "34   {'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 500}   \n",
       "35  {'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 1000}   \n",
       "26    {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 500}   \n",
       "27   {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 1000}   \n",
       "30   {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 500}   \n",
       "18   {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 500}   \n",
       "19  {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 1000}   \n",
       "22   {'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 500}   \n",
       "13    {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 200}   \n",
       "14    {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 500}   \n",
       "15   {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 1000}   \n",
       "29   {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 200}   \n",
       "31  {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 1000}   \n",
       "25    {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 200}   \n",
       "21   {'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 200}   \n",
       "33   {'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 200}   \n",
       "23  {'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 1000}   \n",
       "12    {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 100}   \n",
       "17   {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 200}   \n",
       "20   {'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 100}   \n",
       "3     {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}   \n",
       "16   {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 100}   \n",
       "7    {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}   \n",
       "28   {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 100}   \n",
       "11   {'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 1000}   \n",
       "32   {'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 100}   \n",
       "6     {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 500}   \n",
       "2      {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 500}   \n",
       "10    {'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 500}   \n",
       "9     {'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 200}   \n",
       "1      {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 200}   \n",
       "24    {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}   \n",
       "5     {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 200}   \n",
       "4     {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}   \n",
       "0      {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}   \n",
       "8     {'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 100}   \n",
       "\n",
       "    mean_train_score  mean_test_score    diff, %  \n",
       "34          0.999375         0.815016  18.447407  \n",
       "35          0.999375         0.811225  18.826733  \n",
       "26          0.999375         0.809618  18.987553  \n",
       "27          0.999375         0.808318  19.117678  \n",
       "30          0.999375         0.808068  19.142700  \n",
       "18          0.996562         0.806829  19.038693  \n",
       "19          0.996249         0.806778  19.018431  \n",
       "22          0.994374         0.802435  19.302540  \n",
       "13          0.995937         0.801997  19.473118  \n",
       "14          0.996718         0.801635  19.572526  \n",
       "15          0.996562         0.801081  19.615528  \n",
       "29          0.999375         0.799931  19.956897  \n",
       "31          0.999375         0.799220  20.028016  \n",
       "25          0.999375         0.799159  20.034106  \n",
       "21          0.992187         0.796379  19.734917  \n",
       "33          0.999375         0.796306  20.319610  \n",
       "23          0.994687         0.794892  20.086247  \n",
       "12          0.994218         0.791815  20.358030  \n",
       "17          0.994843         0.791191  20.470726  \n",
       "20          0.990312         0.789903  20.236967  \n",
       "3           0.954507         0.789168  17.321921  \n",
       "16          0.993905         0.788087  20.708075  \n",
       "7           0.952944         0.787461  17.365452  \n",
       "28          0.999219         0.787153  21.223172  \n",
       "11          0.946840         0.786694  16.913727  \n",
       "32          0.998750         0.785702  21.331414  \n",
       "6           0.946834         0.781563  17.455073  \n",
       "2           0.947302         0.779075  17.758488  \n",
       "10          0.941355         0.778959  17.251255  \n",
       "9           0.936194         0.778693  16.823497  \n",
       "1           0.941362         0.774847  17.688799  \n",
       "24          0.999375         0.774678  22.483735  \n",
       "5           0.939950         0.769247  18.160941  \n",
       "4           0.927887         0.762463  17.828081  \n",
       "0           0.926176         0.760748  17.861371  \n",
       "8           0.919736         0.758750  17.503473  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)[['params', 'mean_train_score', 'mean_test_score']]\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the most important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:08.534463Z",
     "start_time": "2021-12-11T17:52:08.153313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad: 0.01012763195975312\n",
      "worst: 0.007295317299470134\n",
      "supposed: 0.004601026444555701\n",
      "waste: 0.004474678835466964\n",
      "boring: 0.004382501581631053\n",
      "stupid: 0.004376471394903765\n",
      "ridiculous: 0.004100202860159638\n",
      "life: 0.003971495389244511\n",
      "awful: 0.003923475979040344\n",
      "reason: 0.0033764147159750808\n",
      "plot: 0.00310844509310445\n",
      "lame: 0.003084276150923772\n",
      "script: 0.0029994261813080392\n",
      "dull: 0.002976750430702203\n",
      "mess: 0.002971203491250243\n",
      "better: 0.0029071293333055776\n",
      "great: 0.0028408260561642515\n",
      "movie: 0.0027524840896753096\n",
      "wonderfully: 0.0027469561177701205\n",
      "unfortunately: 0.002657658991420461\n",
      "worse: 0.0025836016140119732\n",
      "poor: 0.002492967386859242\n",
      "looks: 0.0024727491095436495\n",
      "problem: 0.002435864261799686\n",
      "wasted: 0.002348432160459075\n",
      "excellent: 0.0023401009873775455\n",
      "attempt: 0.002296575182907708\n",
      "performances: 0.0022028718431327823\n",
      "bland: 0.0021912683310899884\n",
      "dialogue: 0.002054419063239258\n",
      "maybe: 0.002038743526878255\n",
      "just: 0.0020286107057533318\n",
      "perfect: 0.0019964047711216416\n",
      "poorly: 0.0019770383975408353\n",
      "don: 0.0019096439306525432\n",
      "different: 0.0019063234712198213\n",
      "terrible: 0.001828671887841876\n",
      "tries: 0.001803450375877582\n",
      "wasn: 0.0017853780220064483\n",
      "world: 0.0017596363333552867\n",
      "make: 0.0017031228478503282\n",
      "memorable: 0.001692489636869473\n",
      "cheap: 0.0016827272738333175\n",
      "perfectly: 0.0016477364803212137\n",
      "rent: 0.0016276609235298808\n",
      "outstanding: 0.0016226959127291797\n",
      "true: 0.0016000233821390852\n",
      "minute: 0.0015754775466994759\n",
      "flat: 0.0015754005926433446\n",
      "minutes: 0.0014786790031033764\n"
     ]
    }
   ],
   "source": [
    "# put them into a separate variable for convenience\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "# the order of the features in `feature_importances` is the same as in count_vectorizer.get_feature_names(),\n",
    "# so we can \"zip\" the two and print the first 50 in the descending order:\n",
    "for k, v in sorted(zip(feature_importances, count_vectorizer.get_feature_names_out()), reverse=True)[:50]:\n",
    "    print(f\"{v}: {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:09.275240Z",
     "start_time": "2021-12-11T17:52:08.535493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/rf-clf.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# create a folder where all trained models will be kept\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "    \n",
    "dump(grid_search.best_estimator_, 'models/rf-clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:28.723094Z",
     "start_time": "2021-12-11T17:52:09.278233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time HH:MM:SS: 0:00:07.515499\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvm = LinearSVC(random_state=7, max_iter=10000)\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 7 combinations in the grid\n",
    "param_grid = {\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 5, 10]\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(lsvm, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "print(\"Execution time HH:MM:SS:\", timedelta(seconds=timer() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:28.753971Z",
     "start_time": "2021-12-11T17:52:28.725083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>diff, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.856222</td>\n",
       "      <td>14.377845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>14.939852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846202</td>\n",
       "      <td>15.379848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845576</td>\n",
       "      <td>15.442441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845576</td>\n",
       "      <td>15.442441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.989368</td>\n",
       "      <td>0.835817</td>\n",
       "      <td>15.520090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.0001}</td>\n",
       "      <td>0.938045</td>\n",
       "      <td>0.737694</td>\n",
       "      <td>21.358343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          params  mean_train_score  mean_test_score    diff, %\n",
       "2    {'C': 0.01}          1.000000         0.856222  14.377845\n",
       "3     {'C': 0.1}          1.000000         0.850601  14.939852\n",
       "4       {'C': 1}          1.000000         0.846202  15.379848\n",
       "5       {'C': 5}          1.000000         0.845576  15.442441\n",
       "6      {'C': 10}          1.000000         0.845576  15.442441\n",
       "1   {'C': 0.001}          0.989368         0.835817  15.520090\n",
       "0  {'C': 0.0001}          0.938045         0.737694  21.358343"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)[['params', 'mean_train_score', 'mean_test_score']]\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the best model to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:28.800326Z",
     "start_time": "2021-12-11T17:52:28.755966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/svm-linear-clf.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(grid_search.best_estimator_, 'models/svm-linear-clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:56.245366Z",
     "start_time": "2021-12-11T17:52:28.801323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time HH:MM:SS: 0:10:33.593056\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_poly = SVC(kernel=\"poly\", degree=2, random_state=7)\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 5 x 4 = 20 combinations in the grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': [\"scale\", 0.1, 0.5, 0.9],\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(svm_poly, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "print(\"Execution time HH:MM:SS:\", timedelta(seconds=timer() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:56.293270Z",
     "start_time": "2021-12-11T17:52:56.250350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>diff, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821244</td>\n",
       "      <td>17.875562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803703</td>\n",
       "      <td>19.629682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'C': 10, 'gamma': 'scale'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802935</td>\n",
       "      <td>19.706465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.9}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>23.281398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749173</td>\n",
       "      <td>25.082685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 1, 'gamma': 'scale'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672644</td>\n",
       "      <td>32.735599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645332</td>\n",
       "      <td>35.466835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'C': 100, 'gamma': 'scale'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639623</td>\n",
       "      <td>36.037688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'C': 1, 'gamma': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'C': 10, 'gamma': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'C': 100, 'gamma': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'C': 10, 'gamma': 0.9}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'C': 100, 'gamma': 0.9}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'C': 1, 'gamma': 0.9}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.9}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1}</td>\n",
       "      <td>0.671546</td>\n",
       "      <td>0.340003</td>\n",
       "      <td>49.370137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale'}</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale'}</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           params  mean_train_score  mean_test_score  \\\n",
       "5        {'C': 0.1, 'gamma': 0.1}          1.000000         0.821244   \n",
       "2       {'C': 0.01, 'gamma': 0.5}          1.000000         0.803703   \n",
       "12    {'C': 10, 'gamma': 'scale'}          1.000000         0.802935   \n",
       "3       {'C': 0.01, 'gamma': 0.9}          1.000000         0.767186   \n",
       "9          {'C': 1, 'gamma': 0.1}          1.000000         0.749173   \n",
       "8      {'C': 1, 'gamma': 'scale'}          1.000000         0.672644   \n",
       "6        {'C': 0.1, 'gamma': 0.5}          1.000000         0.645332   \n",
       "16   {'C': 100, 'gamma': 'scale'}          1.000000         0.639623   \n",
       "10         {'C': 1, 'gamma': 0.5}          1.000000         0.612874   \n",
       "14        {'C': 10, 'gamma': 0.5}          1.000000         0.612874   \n",
       "18       {'C': 100, 'gamma': 0.5}          1.000000         0.612874   \n",
       "17       {'C': 100, 'gamma': 0.1}          1.000000         0.612874   \n",
       "15        {'C': 10, 'gamma': 0.9}          1.000000         0.612874   \n",
       "19       {'C': 100, 'gamma': 0.9}          1.000000         0.612874   \n",
       "13        {'C': 10, 'gamma': 0.1}          1.000000         0.612874   \n",
       "11         {'C': 1, 'gamma': 0.9}          1.000000         0.612874   \n",
       "7        {'C': 0.1, 'gamma': 0.9}          1.000000         0.612874   \n",
       "1       {'C': 0.01, 'gamma': 0.1}          0.671546         0.340003   \n",
       "4    {'C': 0.1, 'gamma': 'scale'}          0.337200         0.337199   \n",
       "0   {'C': 0.01, 'gamma': 'scale'}          0.337200         0.337199   \n",
       "\n",
       "      diff, %  \n",
       "5   17.875562  \n",
       "2   19.629682  \n",
       "12  19.706465  \n",
       "3   23.281398  \n",
       "9   25.082685  \n",
       "8   32.735599  \n",
       "6   35.466835  \n",
       "16  36.037688  \n",
       "10  38.712646  \n",
       "14  38.712646  \n",
       "18  38.712646  \n",
       "17  38.712646  \n",
       "15  38.712646  \n",
       "19  38.712646  \n",
       "13  38.712646  \n",
       "11  38.712646  \n",
       "7   38.712646  \n",
       "1   49.370137  \n",
       "4    0.000127  \n",
       "0    0.000127  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)[['params', 'mean_train_score', 'mean_test_score']]\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:53:26.501246Z",
     "start_time": "2021-12-11T17:52:56.295263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time HH:MM:SS: 0:10:37.792199\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_poly = SVC(kernel=\"rbf\", gamma=\"scale\", random_state=7)\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 5 x 4 = 20 combinations in the grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': [\"scale\", 0.1, 0.5, 0.9],\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(svm_poly, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "print(\"Execution time HH:MM:SS:\", timedelta(seconds=timer() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:53:26.597317Z",
     "start_time": "2021-12-11T17:53:26.503240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>diff, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'C': 100, 'gamma': 'scale'}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.850599</td>\n",
       "      <td>14.940077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'C': 10, 'gamma': 'scale'}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.850599</td>\n",
       "      <td>14.940077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 1, 'gamma': 'scale'}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.838058</td>\n",
       "      <td>16.194179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'C': 1, 'gamma': 0.5}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'C': 100, 'gamma': 0.5}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'C': 10, 'gamma': 0.5}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'C': 1, 'gamma': 0.9}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.342814</td>\n",
       "      <td>65.718561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'C': 10, 'gamma': 0.9}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.342814</td>\n",
       "      <td>65.718561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'C': 100, 'gamma': 0.9}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.342814</td>\n",
       "      <td>65.718561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.9}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.5}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale'}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.9}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.5}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale'}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           params  mean_train_score  mean_test_score  \\\n",
       "16   {'C': 100, 'gamma': 'scale'}            1.0000         0.850599   \n",
       "12    {'C': 10, 'gamma': 'scale'}            1.0000         0.850599   \n",
       "8      {'C': 1, 'gamma': 'scale'}            1.0000         0.838058   \n",
       "10         {'C': 1, 'gamma': 0.5}            1.0000         0.345611   \n",
       "18       {'C': 100, 'gamma': 0.5}            1.0000         0.345611   \n",
       "17       {'C': 100, 'gamma': 0.1}            1.0000         0.345611   \n",
       "14        {'C': 10, 'gamma': 0.5}            1.0000         0.345611   \n",
       "13        {'C': 10, 'gamma': 0.1}            1.0000         0.345611   \n",
       "9          {'C': 1, 'gamma': 0.1}            1.0000         0.345611   \n",
       "11         {'C': 1, 'gamma': 0.9}            1.0000         0.342814   \n",
       "15        {'C': 10, 'gamma': 0.9}            1.0000         0.342814   \n",
       "19       {'C': 100, 'gamma': 0.9}            1.0000         0.342814   \n",
       "1       {'C': 0.01, 'gamma': 0.1}            0.3372         0.337199   \n",
       "7        {'C': 0.1, 'gamma': 0.9}            0.3372         0.337199   \n",
       "6        {'C': 0.1, 'gamma': 0.5}            0.3372         0.337199   \n",
       "5        {'C': 0.1, 'gamma': 0.1}            0.3372         0.337199   \n",
       "4    {'C': 0.1, 'gamma': 'scale'}            0.3372         0.337199   \n",
       "3       {'C': 0.01, 'gamma': 0.9}            0.3372         0.337199   \n",
       "2       {'C': 0.01, 'gamma': 0.5}            0.3372         0.337199   \n",
       "0   {'C': 0.01, 'gamma': 'scale'}            0.3372         0.337199   \n",
       "\n",
       "      diff, %  \n",
       "16  14.940077  \n",
       "12  14.940077  \n",
       "8   16.194179  \n",
       "10  65.438925  \n",
       "18  65.438925  \n",
       "17  65.438925  \n",
       "14  65.438925  \n",
       "13  65.438925  \n",
       "9   65.438925  \n",
       "11  65.718561  \n",
       "15  65.718561  \n",
       "19  65.718561  \n",
       "1    0.000127  \n",
       "7    0.000127  \n",
       "6    0.000127  \n",
       "5    0.000127  \n",
       "4    0.000127  \n",
       "3    0.000127  \n",
       "2    0.000127  \n",
       "0    0.000127  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)[['params', 'mean_train_score', 'mean_test_score']]\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:53:26.661046Z",
     "start_time": "2021-12-11T17:53:26.602302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8518541797611565\n",
      "Recall: 0.8515978293638831\n",
      "F score: 0.8517206064375876\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "lsvm = load(\"models/svm-linear-clf.joblib\")\n",
    "\n",
    "yhat = lsvm.predict(Xtest)\n",
    "\n",
    "# micro-averaged precision, recall and f-score\n",
    "p, r, f, s = precision_recall_fscore_support(ytest, yhat, average=\"macro\")\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"Recall: {r}\")\n",
    "print(f\"F score: {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy scores on the test set turn out to be very similar to the one achieved during cross-validation.\n",
    "\n",
    "Plot a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:54:15.852292Z",
     "start_time": "2021-12-11T17:54:15.596140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17b464afc10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGrCAYAAAAy+7WVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA310lEQVR4nO3deVyU9fr/8fcAsriAIoqYiKSl5i6YopltUtbpp6dFOpZbUHGszNQWjie3UvJUplmQS65Zx/Y6pRbfykLNCkKzJFvUQAMRNFBMEJjfH+acMzHaDDMDztyvZ4/78YjPfO77vqZ8cHld9+e+b5PZbDYLAAB4BZ+GDgAAALgOiR0AAC9CYgcAwIuQ2AEA8CIkdgAAvAiJHQAAL0JiBwDAi/g1dADOqKmp0S+//KJmzZrJZDI1dDgAAAeZzWYdPXpUbdu2lY+P+2rNEydOqLKy0unj+Pv7KzAw0AURuY9HJ/ZffvlFkZGRDR0GAMBJ+fn5ateunVuOfeLECQU1aylVHXf6WG3atNHevXvP6eTu0Ym9WbNmkiT/vhNk8g1o4GgA9/j+P480dAiA2xw9WqbuF3Sw/D53h8rKSqnquAIuGiv5+tf9QNWVKty1SpWVlSR2dzndfjf5BsjkR2KHdwoODm7oEAC3q5fLqX6BMjmR2M0mz1iW5tGJHQAAu5kkOfMXCA9ZyuUZf/0AAAB2oWIHABiDyefU5sz+HoDEDgAwBpPJyVa8Z/TiSewAAGMwSMXuGVECAAC7ULEDAIyBVjwAAN7EyVa8hzS5PSNKAABgFyp2AIAx0IoHAMCLsCoeAAB4Gip2AIAx0IoHAMCL0IoHAACehoodAGAMtOIBAPAiBmnFk9gBAMZgMjmZ2D2jYveMv34AAAC7ULEDAIzBx3Rqc2Z/D0BiBwAYg0GusXtGlAAAwC5U7AAAY+B2NwAAvAiteAAA4Gmo2AEAxmCQVjwVOwDAGE634p3Z6iAtLU3R0dEKDAxUTEyMMjMzzzp/7dq16tWrlxo3bqyIiAiNHz9eJSUldp+PxA4AgJusW7dOkyZN0rRp05STk6PBgwdr2LBhysvLszl/8+bNGjNmjBITE/Xtt9/q1Vdf1ZdffqmkpCS7z0liBwAYw+lWvDObg+bPn6/ExEQlJSWpa9euWrBggSIjI5Wenm5z/rZt29ShQwdNnDhR0dHRuuSSS3TXXXcpKyvL7nOS2AEAxuCiVnxZWZnVVlFRYfN0lZWVys7OVnx8vNV4fHy8tm7danOfgQMHav/+/Vq/fr3MZrMOHjyo1157Tdddd53dX5PEDgAwBhdV7JGRkQoJCbFsqampNk9XXFys6upqhYeHW42Hh4ersLDQ5j4DBw7U2rVrlZCQIH9/f7Vp00bNmzfXokWL7P6aJHYAAByQn5+v0tJSy5aSknLW+aY/tPDNZnOtsdN27dqliRMnavr06crOztbGjRu1d+9eJScn2x0ft7sBAAzCyQfU/F4LBwcHKzg4+E9nh4WFydfXt1Z1XlRUVKuKPy01NVWDBg3SAw88IEnq2bOnmjRposGDB+uxxx5TRESEnVECAODt6nnxnL+/v2JiYpSRkWE1npGRoYEDB9rc5/jx4/LxsU7Nvr6+kk5V+vYgsQMA4CaTJ0/WsmXLtHz5cuXm5ur+++9XXl6epbWekpKiMWPGWOZff/31euONN5Senq49e/Zoy5Ytmjhxoi6++GK1bdvWrnPSigcAGIPJ5OSz4h2/3S0hIUElJSWaPXu2CgoK1L17d61fv15RUVGSpIKCAqt72seNG6ejR4/q2Wef1ZQpU9S8eXNdccUVmjdvnv1hmu2t7c9BZWVlCgkJUUC/+2XyC2jocAC3KPjwsYYOAXCbsrIyRbUJVWlpqV3Xret6jpCQEAVc/aRMjYLqfBzzyd9U8f5Ut8bqCrTiAQDwIrTiAQDGYJCXwJDYAQDGwPvYAQCAp6FiBwAYA614AAC8iEFa8SR2AIAxGKRi94y/fgAAALtQsQMADMFkMp3xrWp2HsB1wbgRiR0AYAhGSey04gEA8CJU7AAAYzD9vjmzvwcgsQMADIFWPAAA8DhU7AAAQzBKxU5iBwAYglESO614AAC8CBU7AMAQjFKxk9gBAMbA7W4AAHgPo1TsXGMHAMCLULEDAAzh1FtbnanYXReLO5HYAQCGYJKTrXgPyey04gEA8CJU7AAAQzDK4jkSOwDAGAxyuxuteAAAvAgVOwDAGJxsxZtpxQMAcO5w9hq7cyvq6w+teAAAvAgVOwDAEIxSsZPYAQDGYJBV8SR2AIAhGKVi5xo7AABehIodAGAIRqnYSewAAEMwSmKnFQ8AgBehYgcAGIJRKnYSOwDAGAxyuxuteAAAvAiJHQBgCKdb8c5sdZGWlqbo6GgFBgYqJiZGmZmZZ5w7btw4m+ft1q2b3ecjsQMADKEhEvu6des0adIkTZs2TTk5ORo8eLCGDRumvLw8m/MXLlyogoICy5afn6/Q0FDdfPPNdp+TxA4AgJvMnz9fiYmJSkpKUteuXbVgwQJFRkYqPT3d5vyQkBC1adPGsmVlZenIkSMaP3683ecksQMADMFVFXtZWZnVVlFRYfN8lZWVys7OVnx8vNV4fHy8tm7dalfML7zwgq666ipFRUXZ/T1J7AAAYzC5YJMUGRmpkJAQy5aammrzdMXFxaqurlZ4eLjVeHh4uAoLC/803IKCAm3YsEFJSUkOfU1udwMAGIKr7mPPz89XcHCwZTwgIMCu/U4zm812xbFy5Uo1b95cI0aMcChOEjsAAA4IDg62SuxnEhYWJl9f31rVeVFRUa0q/o/MZrOWL1+u0aNHy9/f36H4aMUbXOKIAdq+7gEVZMzWx0vvUVzPDmedf/PQ3spcPlEHPpil3DdT9OzDN6pFcGObc2+4oqeOfJqqF+fc5obIAfusfD1TF984Sx0um6L48U9o2/afzjj3YHGpJsxYpUtumaO2gybpkQVv2JxXevS4Up58Vb2uf0QdLpuiwX+bqw+3fuuurwAXqe9V8f7+/oqJiVFGRobVeEZGhgYOHHjWfT/55BP9+OOPSkxMdPh7ktgN7K9X9NDce6/TU6s/1pCkRfrs63165V/j1K51iM35A3pEKf0fN2vNe1mKG7tA46e/pL5d2umZB2+oNTcyvLlmT7hWW3fsdffXAM7o7f/7StMXvqn7xsbrg5UPqH+vjrp1yvPaX3jY5vzKk1UKbd5UE8cOVbdObc84J+G+NOUXHNbSOeOV+fI0Pflwgtq0au7GbwJXMMnJxF6HR89NnjxZy5Yt0/Lly5Wbm6v7779feXl5Sk5OliSlpKRozJgxtfZ74YUX1L9/f3Xv3t3hczZ4Ynfkxn241oSRg/Xie1la816Wvv/5kP6x6F0dOFSq20cMsDk/tlt75RUe0ZLXtyqv4Ii27fxZK975Qn26nGc1z8fHpCWPJOjxFf+nfb/Y/gUK1IfF/96kv10/QLf+vzhd2KGNHp10g9q2bqFVb26xOT8yoqUeu/9GjRx2sZo1DbI55+V3t+nXsuNaMS9JF/c8X5ERoerfq6O6XXCezfkwtoSEBC1YsECzZ89W79699emnn2r9+vWWVe4FBQW17mkvLS3V66+/XqdqXWrgxO7ojftwnUZ+vup9YVt99OUPVuMff/mDLu7e3uY+X3zzs9q2CtHQAZ0lSa1aNNXwy7rrg892W817cOyVKv61XC++l+We4AE7VJ6s0te78zXk4s5W40Mu7qysnXXvJH2w+RvFdO+glCdfVY/rpumyW1O1cNUHqq6ucTZkuFlDPXluwoQJ2rdvnyoqKpSdna1LL73U8tnKlSu1adMmq/khISE6fvy47rjjjjqdr0ETu6M37sN1WoY0lp+frw4dOWY1fujwMbUObWZzny++ydOdj67TCzP/pqKPHtP3b09T6bETenDBO5Y5/btH6bbrYnXfE7avTQL15fCv5aqurlGrUOtFTq1Cm+nQ4aN1Pu7PB0r03qYdqqmp0YtPJWvSuKu1+OWPtXDVB86GDHdz0e1u57oGS+x1uXG/oqKi1oMB4Byz2fpnk+nUakxbOke11uP3Xa8nVn6oy5Oe1Y1TlisqooXmTx0hSWoa5K/Fj4zUpCfe0OHS426OHLDPH38Xn+GPt93MZrNatmiqJx66Rb26RGrE0L6aODb+jO19oL412O1udblxPzU1VbNmzaqP8LxeSelxVVVVq3VoU6vxsBZNa1Xxp91/22X6fOfPWvTvU+sgvt1TqOPzK7XhuWTNWZahVi2aKioiVC+n/nchiI/PqV+rhz56TP1um881d9Sb0OZN5Ovro6LD1gVA8ZGjanWGrpQ9WrcMViM/X/n6/rcuuqBDuIpKylR5skr+jbiL+FxllPexN/jiOUdu3E9JSVFpaally8/Pr48QvdLJqmpt//4XXR57gdX4ZbGd9MU3ttc4BAU2Us0fyp3qmlM/myT9kHdIA8cu0KWJiyzbhi25yszZo0sTF+lAUalbvgtgi38jP/XsHKlPv7BeA/Lpl7sV2yO6zsft1zNae/cXq6bmv9fU9+QVKTwsmKR+jmuoa+z1rcH+FNblxv2AgIA/fcIP7Jf2SqaenzZSObv368tv8zT2+ovVrnVzrXj7c0nS9DuvVkRYsP4+91VJ0sYtuVr44A26fXh/ffjF92rTMlhz7/2Lsnblq7Dk1DXL3L0Hrc5ReuyEzXGgPtx1y2W6d/aL6tW1vWK6d9CLb2/VgYNHNGbEIEnSnPT/qPBQqRZN/++zFr75fr8kqfy3CpX8ekzffL9fjRr5qXN0G0nS2L9eouWvZeqRBW/o9psu1d78Q3pmdYYSbx5S/18QsKHBEvv/3rj/17/+1TKekZGh4cOHN1RYhvLmRzsVGtxED469UuEtmyl370ElPLRS+Qd/lSSFt2ymduHNLfNf3viVmjYOUNINcXr07mtVeuyEMr/6STOf39gwXwD4E8Ov6qsjpeWav/x9FZWUqvP5EXrxybsUGREqSSoqKdOBg0es9hk67gnLv3/9Xb7e/CBb7dqE6ss3ZkiSzgtvoX8//XfNeOZNXTlmntqEhShp5BDdc9tV9ffFUCcm06nNmf09gcl8ppVS9WDdunUaPXq0nn/+ecXFxWnJkiVaunSpvv32W7veZFNWVqaQkBAF9LtfJj8qeXingg8fa+gQALcpKytTVJtQlZaW2vWY1rqeIyQkROff+5p8AprU+Tg1FeXas+gmt8bqCg16QSghIUElJSWaPXu2CgoK1L17d6sb9wEAcBknK3ZPud2twVd6TJgwQRMmTGjoMAAA8AoNntgBAKgPRrndjcQOADAEoyyea/D72AEAgOtQsQMADMHHx2R5GmZdmJ3Ytz6R2AEAhkArHgAAeBwqdgCAIbAqHgAAL0IrHgAAeBwqdgCAIdCKBwDAi5DYAQDwIlxjBwAAHoeKHQBgCCY52Yr3kPe2ktgBAIZAKx4AAHgcKnYAgCGwKh4AAC9CKx4AAHgcKnYAgCHQigcAwIvQigcAAB6Hih0AYAi04gEA8CZOtuI95MFzJHYAgDEYpWLnGjsAAF6Eih0AYAhGWRVPYgcAGAKteAAA4HGo2AEAhkArHgAAL0IrHgAAOC0tLU3R0dEKDAxUTEyMMjMzzzq/oqJC06ZNU1RUlAICAtSxY0ctX77c7vNRsQMADKEhKvZ169Zp0qRJSktL06BBg7R48WINGzZMu3btUvv27W3uM3LkSB08eFAvvPCCOnXqpKKiIlVVVdl9ThI7AMAQXHWNvayszGo8ICBAAQEBNveZP3++EhMTlZSUJElasGCB3n//faWnpys1NbXW/I0bN+qTTz7Rnj17FBoaKknq0KGDQ3HSigcAwAGRkZEKCQmxbLYStCRVVlYqOztb8fHxVuPx8fHaunWrzX3eeecdxcbG6l//+pfOO+88XXjhhZo6dap+++03u+OjYgcAGIKrWvH5+fkKDg62jJ+pWi8uLlZ1dbXCw8OtxsPDw1VYWGhznz179mjz5s0KDAzUm2++qeLiYk2YMEGHDx+2+zo7iR0AYAiuasUHBwdbJfY/38/6pGaz+Yx/waipqZHJZNLatWsVEhIi6VQ7/6abbtJzzz2noKCgPz0frXgAgCGcrtid2RwRFhYmX1/fWtV5UVFRrSr+tIiICJ133nmWpC5JXbt2ldls1v79++06L4kdAAA38Pf3V0xMjDIyMqzGMzIyNHDgQJv7DBo0SL/88ouOHTtmGfv+++/l4+Ojdu3a2XVeEjsAwBBM+m87vk5bHc45efJkLVu2TMuXL1dubq7uv/9+5eXlKTk5WZKUkpKiMWPGWOaPGjVKLVu21Pjx47Vr1y59+umneuCBB3T77bfb1YaXuMYOADAIH5NJPk5cZK/LvgkJCSopKdHs2bNVUFCg7t27a/369YqKipIkFRQUKC8vzzK/adOmysjI0L333qvY2Fi1bNlSI0eO1GOPPWb3OUnsAAC40YQJEzRhwgSbn61cubLWWJcuXWq17x1BYgcAGAIvgQEAwIvwEhgAAOBxqNgBAIbgYzq1ObO/JyCxAwCMweRkO91DEjuteAAAvAgVOwDAEFgVDwCAFzH9/o8z+3sCEjsAwBCMsniOa+wAAHgRKnYAgCEY5QE1JHYAgCGweO5/PPPMM3YfcOLEiXUOBgAAOMeuxP7000/bdTCTyURiBwCckxrita0Nwa7EvnfvXnfHAQCAWxmlFV/nVfGVlZXavXu3qqqqXBkPAABwgsOJ/fjx40pMTFTjxo3VrVs35eXlSTp1bf3xxx93eYAAALjC6VXxzmyewOHEnpKSoh07dmjTpk0KDAy0jF911VVat26dS4MDAMBVTrfindk8gcO3u7311ltat26dBgwYYPW3l4suukg//fSTS4MDAACOcTixHzp0SK1bt641Xl5e7jFtCgCA8RhlVbzDrfh+/frpvffes/x8OpkvXbpUcXFxrosMAAAXMrlg8wQOV+ypqam65pprtGvXLlVVVWnhwoX69ttv9dlnn+mTTz5xR4wAADjNKI+UdbhiHzhwoLZs2aLjx4+rY8eO+uCDDxQeHq7PPvtMMTEx7ogRAADYqU7Piu/Ro4dWrVrl6lgAAHAbo7y2tU6Jvbq6Wm+++aZyc3NlMpnUtWtXDR8+XH5+vFMGAHBuMkor3uFM/M0332j48OEqLCxU586dJUnff/+9WrVqpXfeeUc9evRweZAAAMA+Dl9jT0pKUrdu3bR//3599dVX+uqrr5Sfn6+ePXvqzjvvdEeMAAC4hLc/nEaqQ8W+Y8cOZWVlqUWLFpaxFi1aaM6cOerXr59LgwMAwFWM0op3uGLv3LmzDh48WGu8qKhInTp1cklQAACgbuyq2MvKyiz/PnfuXE2cOFEzZ87UgAEDJEnbtm3T7NmzNW/ePPdECQCAk1gV/z+aN29u1YIwm80aOXKkZcxsNkuSrr/+elVXV7shTAAAnGOUVrxdif3jjz92dxwAALiVs4+F9Yy0bmdiHzJkiLvjAAAALlDnJ8ocP35ceXl5qqystBrv2bOn00EBAOBqRnm7W51e2zp+/Hht2LDB5udcYwcAnIucvR/dQ/K647e7TZo0SUeOHNG2bdsUFBSkjRs3atWqVbrgggv0zjvvuCNGAABgJ4cr9o8++khvv/22+vXrJx8fH0VFRWno0KEKDg5WamqqrrvuOnfECQCAU4yyKt7hir28vFytW7eWJIWGhurQoUOSTr3x7auvvnJtdAAAuIgzj5P1pMfK1unJc7t375Yk9e7dW4sXL9aBAwf0/PPPKyIiwuUBAgAA+9XpGntBQYEkacaMGdq4caPat2+vZ555RnPnznV5gAAAuMLpVfHObHWRlpam6OhoBQYGKiYmRpmZmWecu2nTJsslg//dvvvuO7vP5/A19ltvvdXy73369NG+ffv03XffqX379goLC3P0cAAA1IuGWBW/bt06TZo0SWlpaRo0aJAWL16sYcOGadeuXWrfvv0Z99u9e7eCg4MtP7dq1cruczpcsf9R48aN1bdvX5I6AAB/MH/+fCUmJiopKUldu3bVggULFBkZqfT09LPu17p1a7Vp08ay+fr62n1Ouyr2yZMn233A+fPn2z0XAID64qpV8f/7YjRJCggIUEBAQK35lZWVys7O1sMPP2w1Hh8fr61bt571XH369NGJEyd00UUX6Z///Kcuv/xyu+O0K7Hn5OTYdbCGuhUgb+NMq5YF4E1a9LunoUMA3MZcXfnnk1zER861qU/vGxkZaTU+Y8YMzZw5s9b84uJiVVdXKzw83Go8PDxchYWFNs8RERGhJUuWKCYmRhUVFVqzZo2uvPJKbdq0SZdeeqldcfISGACAIbiqYs/Pz7cqJm1V67b2O81sNp8xjs6dO6tz586Wn+Pi4pSfn68nn3zS7sTu9DV2AACMJDg42Go7U2IPCwuTr69vreq8qKioVhV/NgMGDNAPP/xg93wSOwDAEEwmyceJzdFi39/fXzExMcrIyLAaz8jI0MCBA+0+Tk5OjkPPianz290AAPAkpxO0M/s7avLkyRo9erRiY2MVFxenJUuWKC8vT8nJyZKklJQUHThwQKtXr5YkLViwQB06dFC3bt1UWVmpF198Ua+//rpef/11u89JYgcAwE0SEhJUUlKi2bNnq6CgQN27d9f69esVFRUlSSooKFBeXp5lfmVlpaZOnaoDBw4oKChI3bp103vvvadrr73W7nOazGaz2eXfpJ6UlZUpJCREB0tKWRUPr8WqeHgzc3WlKnYuVWmp+36Pn84Vd/87SwGNm9b5OBXHj+m5W2LdGqsr1Oka+5o1azRo0CC1bdtWP//8s6RT7YO3337bpcEBAOAqzlxfd7aNX58cTuzp6emaPHmyrr32Wv3666+qrq6WJDVv3lwLFixwdXwAAMABDif2RYsWaenSpZo2bZrVI+5iY2O1c+dOlwYHAICrGOW1rQ4vntu7d6/69OlTazwgIEDl5eUuCQoAAFdz5g1tp/f3BA5X7NHR0dq+fXut8Q0bNuiiiy5yRUwAAKCOHK7YH3jgAd199906ceKEzGazvvjiC7388stKTU3VsmXL3BEjAABOc9Wz4s91Dif28ePHq6qqSg8++KCOHz+uUaNG6bzzztPChQt1yy23uCNGAACc1hDvY28IdXpAzR133KE77rhDxcXFqqmpUevWrV0dFwAALuUjJ6+xyzMyu1NPngsLC3NVHAAAwAUcTuzR0dFnfe3dnj17nAoIAAB3oBV/BpMmTbL6+eTJk8rJydHGjRv1wAMPuCouAABcqiFeAtMQHE7s9913n83x5557TllZWU4HBAAA6s5lq/eHDRvm0GvlAACoT6fex26q8+a1rfgzee211xQaGuqqwwEA4FJcYz+DPn36WC2eM5vNKiws1KFDh5SWlubS4AAAgGMcTuwjRoyw+tnHx0etWrXSZZddpi5durgqLgAAXIrFczZUVVWpQ4cOuvrqq9WmTRt3xQQAgMuZfv/Hmf09gUOL5/z8/PT3v/9dFRUV7ooHAAA4weFV8f3791dOTo47YgEAwG1Ot+Kd2TyBw9fYJ0yYoClTpmj//v2KiYlRkyZNrD7v2bOny4IDAMBVuMb+B7fffrsWLFighIQESdLEiRMtn5lMJpnNZplMJlVXV7s+SgAAnGQymc76SHR79vcEdif2VatW6fHHH9fevXvdGQ8AAHCC3YndbDZLkqKiotwWDAAA7kIr3gZPaUMAAPBHPHnOhgsvvPBPk/vhw4edCggAANSdQ4l91qxZCgkJcVcsAAC4zemXuTizvydwKLHfcsstat26tbtiAQDAbYxyjd3uB9RwfR0AgHOfw6viAQDwSE4unvOQR8Xbn9hramrcGQcAAG7lI5N8nMjOzuxbnxx+VjwAADh3OfyseAAAPBH3sQMA4EWMsiqexA4AMASj3MfONXYAALwIFTsAwBC4xg4AgBfxkZOteG53AwAA9Y2KHQBgCLTiAQDwIj5yrk3tKS1uT4kTAACPlJaWpujoaAUGBiomJkaZmZl27bdlyxb5+fmpd+/eDp2PxA4AMASTyeT05qh169Zp0qRJmjZtmnJycjR48GANGzZMeXl5Z92vtLRUY8aM0ZVXXunwOUnsAABDMLlgc9T8+fOVmJiopKQkde3aVQsWLFBkZKTS09PPut9dd92lUaNGKS4uzuFzktgBAHBAWVmZ1VZRUWFzXmVlpbKzsxUfH281Hh8fr61bt57x+CtWrNBPP/2kGTNm1Ck+EjsAwBBOP1LWmU2SIiMjFRISYtlSU1Ntnq+4uFjV1dUKDw+3Gg8PD1dhYaHNfX744Qc9/PDDWrt2rfz86ra+nVXxAADDcMUda/n5+QoODrb8HBAQcPZz/uHavNlstnm9vrq6WqNGjdKsWbN04YUX1jk+EjsAwBBcdR97cHCwVWI/k7CwMPn6+taqzouKimpV8ZJ09OhRZWVlKScnR/fcc48kqaamRmazWX5+fvrggw90xRVX/Ol5acUDAOAG/v7+iomJUUZGhtV4RkaGBg4cWGt+cHCwdu7cqe3bt1u25ORkde7cWdu3b1f//v3tOi8VOwDAEOp6y9r/7u+oyZMna/To0YqNjVVcXJyWLFmivLw8JScnS5JSUlJ04MABrV69Wj4+PurevbvV/q1bt1ZgYGCt8bMhsQMADKEhnjyXkJCgkpISzZ49WwUFBerevbvWr1+vqKgoSVJBQcGf3tPuKJPZbDa79Ij1qKysTCEhITpYUmrX9Q7AE7Xod09DhwC4jbm6UhU7l6q01H2/x0/niuWf5qpx02Z1Ps7xY0d1+6Vd3RqrK1CxAwAMoSFa8Q2BxA4AMIS6Pj3uf/f3BKyKBwDAi1CxAwAMgVY8AABehPexAwAAj0PFDgAwBFrxAAB4EaOsiiexAwAMwVUvgTnXcY0dAAAvQsUOADAEH5nk40RD3Zl96xOJHQBgCLTiAQCAx6FiBwAYgun3f5zZ3xOQ2AEAhkArHgAAeBwqdgCAIZicXBVPKx4AgHMIrXgAAOBxqNgBAIZglIqdxA4AMARudwMAwIv4mE5tzuzvCbjGDgCAF6FiBwAYAq14AAC8iFEWz9GKBwDAi1CxAwAMwSTn2ukeUrCT2AEAxsCqeAAA4HFI7Aa37NVP1Wv4DLUZNEmXjZ6nrTk/nnFuYXGpkv65Qv1unK3Qi+9VylOvnfXYr3+QpRb97tGtU5e4OmzAbok3Ddb2t2aqYPPT+nj1g4rr3fGs82++JlaZax/Wgcz5yt0wR89Ov00tQppYzQluGqQnHhyp3A1zVLD5aW175Z8aOvAid34NuIDJBf94AhK7gb3xQbb+Mf91TRl/tT558WHF9e6okfelKb/wsM35lZVVCmveTFNuv1rdLzjvrMfOKzis6QvfUlyfs/8SBdzpr0P7au7kG/XUivc15LbH9dn2n/TKwglqF97C5vwBvc5X+swxWvPOZ4pLmKPxD7+gvhe11zPTRlnmNPLz1ZvP3aP2EaEa99ALuvim2Zo05yUVHCqtr6+FOjq9Kt6ZzRM0aGL/9NNPdf3116tt27YymUx66623GjIcw0l76SPdNjxOY0YMVOfoNkqdcpPOC2+h5a9l2pzfvm1LPT71Jt1yXX8FNw0843Grq2t05yMr9fCd16pD2zB3hQ/8qQmjrtCLb3+mNW9/pu/3HdQ/5r+uAweP6PabBtucH9sjWnkFJVqy7hPl/VKibTv2aMUbW9TnovaWObf9vzi1CG6sW6cu0edf71F+4RFt27FH3/xwoL6+FnBWDZrYy8vL1atXLz377LMNGYYhVZ6s0vbv8nVF/65W45f376ovvt7r1LH/tWyDwlo01ejhA506DuCMRn6+6t0lUh99nms1/vHnubq4Z7TNfb74eo/atm5uaau3Cm2m4Vf21gebv7XMGXZpD325c6+eeChBuzfO1dZ//0OTx8XLx1NWVhmYyQWbJ2jQVfHDhg3TsGHD7J5fUVGhiooKy89lZWXuCMsQSn49purqGrUKbWY13qplMxWV1P2/67YdP+nFdz7Tp2sfdjZEwCktmzeVn5+vDh0+ajV+qOSoWrcMtrnPF1/v1Z2PrNILc29XYEAjNfLz1fpPvtaDT7ximRN1XksNjr1Qr278UiMnpatjZGs98eBI+fr56IllG936neAcH5nk40Q/3cdDUrtHXWNPTU1VSEiIZYuMjGzokDzeH/+Mm81mmer4B/9o+QndNX21Fvzjb2rZvKkLogOcZzZb/2wymWT+4+DvOke30eNTb9YTyzbo8tHzdOO9zymqbUvNT7nFMsfH5KPiI0c1ae7L2vFdvt7IyNZTK97X7Tfabu/j3EHFfg5KSUnR5MmTLT+XlZWR3OuoZfOm8vX1UVGJdTVTfPhYrSreXvv2FyvvlxL9bcpiy1hNzalfoGEDJurL1x5RdLtWdQ8acEDJr8dUVVWt1i2t/zyHhTatVcWfdv+4eH2+4yctevFDSdK3P/6i479VaMOyyZqT/q4OlpTpYEmpTlZVW/5sS9L3+wrVJixEjfx8dbKq2n1fCrCDRyX2gIAABQQENHQYXsG/kZ96d4nUx59/p79c3ssyvumL7zTs0h51OuYFHcK15eV/WI3Nef5dHSs/YVmYB9SXk1XV2v5dvi7v30XvbfraMn7ZxV204dOdNvcJCvRXVbV1Yq7+PYGf7mR9vmOPbro61qry79i+tQoOlZLUz3XOlt0eUrJ7VGKHa00YdYWSZ6xWn4vaq1+PaK16c4v2Fx7W+N9birOefVsFh0r1/Kwxln127t4vSSr/rULFR45p5+79atTIV13Oj1BgQCNd1Kmt1TlCmgZJUq1xoD6kvfSRnp81Rjm78vTlzr0a+9dBatcmVCteP3Xnx/S7/58iWoXo7zPXSJI2Zu7UwmmjdPuNl+jDbblq0zJEc6fcqKxv9qmw+NTtbMtfz9QdI4fo8Sk3ackrn6hjZCtNHhevJes+abDvCfvwdjd4vRviY3S4tFz/WrZBB4vL1LVjhNYtmKD2EaGSpIPFZdr/h3vaL73tccu/b8/N12vvZykyIlRfvzO7XmMH7PFmxlcKDWmiB5OGKTwsWLk/FShhUpryC49IksLDgtWuTahl/svvfq6mjQOVNHKIHp10g0qP/qbMrN2auehty5wDB3/Vjfc+pzn336DNL6Wo4NCvWvzvTVqwOqPevx9gi8l8plUk9eDYsWP68cdTTzrr06eP5s+fr8svv1yhoaFq3779n+x96hp7SEiIDpaUKjjY9ipXwNO16HdPQ4cAuI25ulIVO5eqtNR9v8dP54oPt+epabO6n+PY0TJd2bu9W2N1hQZdFZ+VlaU+ffqoT58+kqTJkyerT58+mj59ekOGBQDwQg21Kj4tLU3R0dEKDAxUTEyMMjNtPwRMkjZv3qxBgwapZcuWCgoKUpcuXfT00087dL4GbcVfdtllZ7ztBAAAT7du3TpNmjRJaWlpGjRokBYvXqxhw4Zp165dNjvTTZo00T333KOePXuqSZMm2rx5s+666y41adJEd955p13nbNBWvLNoxcMIaMXDm9VnK/6jHc634q/o1V75+flWsZ7tjq3+/furb9++Sk9Pt4x17dpVI0aMUGpqql3nveGGG9SkSROtWbPGrvke9YAaAADqylVvd4uMjLR6WNqZEnRlZaWys7MVHx9vNR4fH6+tW7faFXNOTo62bt2qIUOG2P09WRUPAIADbFXsthQXF6u6ulrh4eFW4+Hh4SosLDzrOdq1a6dDhw6pqqpKM2fOVFJSkt3xkdgBAIbg7KtXT+8bHBzs0GWDPz6m255Hd2dmZurYsWPatm2bHn74YXXq1El/+9vf7DofiR0AYAj1/eC5sLAw+fr61qrOi4qKalXxfxQdfeoNhD169NDBgwc1c+ZMuxM719gBAMZQz/e7+fv7KyYmRhkZ1g8vysjI0MCB9r/W2mw2W73Z9M9QsQMA4CaTJ0/W6NGjFRsbq7i4OC1ZskR5eXlKTk6WdOrlZgcOHNDq1aslSc8995zat2+vLl26SDp1X/uTTz6pe++91+5zktgBAIbQEM+KT0hIUElJiWbPnq2CggJ1795d69evV1RUlCSpoKBAeXl5lvk1NTVKSUnR3r175efnp44dO+rxxx/XXXfdZX+c3McOnNu4jx3erD7vY8/8Zr/T97EP7t6OR8oCAID6QyseAGAIBnkdO4kdAGAQBsnstOIBAPAiVOwAAENoiFXxDYHEDgAwBFc9UvZcRyseAAAvQsUOADAEg6ydI7EDAAzCIJmdxA4AMASjLJ7jGjsAAF6Eih0AYAhGWRVPYgcAGIJBLrHTigcAwJtQsQMAjMEgJTuJHQBgCKyKBwAAHoeKHQBgCKyKBwDAixjkEjuteAAAvAkVOwDAGAxSspPYAQCGYJRV8SR2AIAxOLl4zkPyOtfYAQDwJlTsAABDMMgldhI7AMAgDJLZacUDAOBFqNgBAIbAqngAALyIUR4pSyseAAAvQsUOADAEg6ydI7EDAAzCIJmdVjwAAF6Eih0AYAisigcAwIuY5OSqeJdF4l4kdgCAIRjkEjvX2AEA8CZU7AAAQzDKA2pI7AAAgzBGM55WPAAAbpSWlqbo6GgFBgYqJiZGmZmZZ5z7xhtvaOjQoWrVqpWCg4MVFxen999/36HzkdgBAIZwuhXvzOaodevWadKkSZo2bZpycnI0ePBgDRs2THl5eTbnf/rppxo6dKjWr1+v7OxsXX755br++uuVk5Nj//c0m81mx0M9N5SVlSkkJEQHS0oVHBzc0OEAbtGi3z0NHQLgNubqSlXsXKrSUvf9Hj+dK777+ZCaOXGOo2Vl6hLVyqFY+/fvr759+yo9Pd0y1rVrV40YMUKpqal2HaNbt25KSEjQ9OnT7ZpPxQ4AgAPKysqstoqKCpvzKisrlZ2drfj4eKvx+Ph4bd261a5z1dTU6OjRowoNDbU7PhI7AMAQXNWKj4yMVEhIiGU7U+VdXFys6upqhYeHW42Hh4ersLDQrpifeuoplZeXa+TIkXZ/T1bFAwAMwVWPlM3Pz7dqxQcEBJx9vz9cnDebzbXGbHn55Zc1c+ZMvf3222rdurXdcZLYAQBwQHBwsF3X2MPCwuTr61urOi8qKqpVxf/RunXrlJiYqFdffVVXXXWVQ/HRigcAGIPJBZsD/P39FRMTo4yMDKvxjIwMDRw48Iz7vfzyyxo3bpxeeuklXXfddY6dVFTsAACDaIjH00yePFmjR49WbGys4uLitGTJEuXl5Sk5OVmSlJKSogMHDmj16tWSTiX1MWPGaOHChRowYICl2g8KClJISIhd5ySxAwAMoSEeKZuQkKCSkhLNnj1bBQUF6t69u9avX6+oqChJUkFBgdU97YsXL1ZVVZXuvvtu3X333ZbxsWPHauXKlfbFyX3swLmN+9jhzerzPvYf9xc7fR97p3Zhbo3VFajYAQCG4KpV8ec6EjsAwBiM8Q4YVsUDAOBNqNgBAIZgkIKdxA4AMIaGWBXfEGjFAwDgRajYAQAG4dyqeE9pxpPYAQCGQCseAAB4HBI7AABehFY8AMAQjNKKJ7EDAAzBKI+UpRUPAIAXoWIHABgCrXgAALyIUR4pSyseAAAvQsUOADAGg5TsJHYAgCGwKh4AAHgcKnYAgCGwKh4AAC9ikEvstOIBAPAmVOwAAGMwSMlOYgcAGIJRVsWT2AEAhsDiOQ9gNpslSUfLyho4EsB9zNWVDR0C4Dan/3yf/n3uTmVO5gpn968vHp3Yjx49KknqFB3ZwJEAAJxx9OhRhYSEuOXY/v7+atOmjS5wQa5o06aN/P39XRCV+5jM9fHXJDepqanRL7/8ombNmsnkKT0SD1dWVqbIyEjl5+crODi4ocMBXIo/3/XPbDbr6NGjatu2rXx83Hej1okTJ1RZ6Xz3y9/fX4GBgS6IyH08umL38fFRu3btGjoMQwoODuYXH7wWf77rl7sq9f8VGBh4zidkV+E+dgAAvAiJHQAAL0Jih0MCAgI0Y8YMBQQENHQogMvx5xvewKMXzwEAAGtU7AAAeBESOwAAXoTEDgCAFyGxAwDgRUjsAAB4EY9+8hzca//+/UpPT9fWrVtVWFgok8mk8PBwDRw4UMnJyYqM5Bn9AHCu4XY32LR582YNGzZMkZGRio+PV3h4uMxms4qKipSRkaH8/Hxt2LBBgwYNauhQAbfJz8/XjBkztHz58oYOBbAbiR029evXT5dccomefvppm5/ff//92rx5s7788st6jgyoPzt27FDfvn1VXV3d0KEAdiOxw6agoCBt375dnTt3tvn5d999pz59+ui3336r58gA13nnnXfO+vmePXs0ZcoUEjs8CtfYYVNERIS2bt16xsT+2WefKSIiop6jAlxrxIgRMplMOlt9wyuh4WlI7LBp6tSpSk5OVnZ2toYOHarw8HCZTCYVFhYqIyNDy5Yt04IFCxo6TMApEREReu655zRixAibn2/fvl0xMTH1GxTgJBI7bJowYYJatmypp59+WosXL7a0In19fRUTE6PVq1dr5MiRDRwl4JyYmBh99dVXZ0zsf1bNA+cirrHjT508eVLFxcWSpLCwMDVq1KiBIwJcIzMzU+Xl5brmmmtsfl5eXq6srCwNGTKkniMD6o7EDgCAF+HJcwAAeBESOwAAXoTEDgCAFyGxAwDgRUjsgJNmzpyp3r17W34eN27cGW+fcqd9+/bJZDJp+/btZ5zToUMHh54/sHLlSjVv3tzp2Ewmk9566y2njwPgz5HY4ZXGjRsnk8kkk8mkRo0a6fzzz9fUqVNVXl7u9nMvXLhQK1eutGuuPckYABzBA2rgta655hqtWLFCJ0+eVGZmppKSklReXq709PRac0+ePOmy+/NDQkJcchwAqAsqdnitgIAAtWnTRpGRkRo1apRuvfVWSzv4dPt8+fLlOv/88xUQECCz2azS0lLdeeedat26tYKDg3XFFVdox44dVsd9/PHHFR4ermbNmikxMVEnTpyw+vyPrfiamhrNmzdPnTp1UkBAgNq3b685c+ZIkqKjoyVJffr0kclk0mWXXWbZb8WKFeratasCAwPVpUsXpaWlWZ3niy++UJ8+fRQYGKjY2Fjl5OQ4/N9o/vz56tGjh5o0aaLIyEhNmDBBx44dqzXvrbfe0oUXXqjAwEANHTpU+fn5Vp//5z//UUxMjAIDA3X++edr1qxZqqqqcjgeAM4jscMwgoKCdPLkScvPP/74o1555RW9/vrrllb4ddddp8LCQq1fv17Z2dnq27evrrzySh0+fFiS9Morr2jGjBmaM2eOsrKyFBERUSvh/lFKSormzZunRx55RLt27dJLL72k8PBwSaeSsyT93//9nwoKCvTGG29IkpYuXapp06Zpzpw5ys3N1dy5c/XII49o1apVkk49Ee0vf/mLOnfurOzsbM2cOVNTp051+L+Jj4+PnnnmGX3zzTdatWqVPvroIz344INWc44fP645c+Zo1apV2rJli8rKynTLLbdYPn///fd12223aeLEidq1a5cWL16slStXWv7yAqCemQEvNHbsWPPw4cMtP3/++efmli1bmkeOHGk2m83mGTNmmBs1amQuKiqyzPnwww/NwcHB5hMnTlgdq2PHjubFixebzWazOS4uzpycnGz1ef/+/c29evWyee6ysjJzQECAeenSpTbj3Lt3r1mSOScnx2o8MjLS/NJLL1mNPfroo+a4uDiz2Ww2L1682BwaGmouLy+3fJ6enm7zWP8rKirK/PTTT5/x81deecXcsmVLy88rVqwwSzJv27bNMpabm2uWZP7888/NZrPZPHjwYPPcuXOtjrNmzRpzRESE5WdJ5jfffPOM5wXgOlxjh9d699131bRpU1VVVenkyZMaPny4Fi1aZPk8KipKrVq1svycnZ2tY8eOqWXLllbH+e233/TTTz9JknJzc5WcnGz1eVxcnD7++GObMeTm5qqiokJXXnml3XEfOnRI+fn5SkxM1B133GEZr6qqsly/z83NVa9evdS4cWOrOBz18ccfa+7cudq1a5fKyspUVVWlEydOqLy8XE2aNJEk+fn5KTY21rJPly5d1Lx5c+Xm5uriiy9Wdna2vvzyS6sKvbq6WidOnNDx48etYgTgfiR2eK3LL79c6enpatSokdq2bVtrcdzpxHVaTU2NIiIitGnTplrHqustX0FBQQ7vU1NTI+lUO75///5Wn/n6+kqSS9449vPPP+vaa69VcnKyHn30UYWGhmrz5s1KTEy0umQh2X4n+emxmpoazZo1SzfccEOtOYGBgU7HCcAxJHZ4rSZNmqhTp052z+/bt68KCwvl5+enDh062JzTtWtXbdu2TWPGjLGMbdu27YzHvOCCCxQUFKQPP/xQSUlJtT739/eXJMtrcSUpPDxc5513nvbs2aNbb73V5nEvuugirVmzRr/99pvlLw9ni8OWrKwsVVVV6amnnpKPz6nlNq+88kqteVVVVcrKytLFF18sSdq9e7d+/fVXdenSRdKp/267d+926L81APchsQO/u+qqqxQXF6cRI0Zo3rx56ty5s3755RetX79eI0aMUGxsrO677z6NHTtWsbGxuuSSS7R27Vp9++23Ov/8820eMzAwUA899JAefPBB+fv7a9CgQTp06JC+/fZbJSYmqnXr1goKCtLGjRvVrl07BQYGKiQkRDNnztTEiRMVHBysYcOGqaKiQllZWTpy5IgmT56sUaNGadq0aUpMTNQ///lP7du3T08++aRD37djx46qqqrSokWLdP3112vLli16/vnna81r1KiR7r33Xj3zzDNq1KiR7rnnHg0YMMCS6KdPn66//OUvioyM1M033ywfHx99/fXX2rlzpx577DHH/0cAcAqr4oHfmUwmrV+/Xpdeeqluv/12XXjhhbrlllu0b98+yyr2hIQETZ8+XQ899JBiYmL0888/6+9///tZj/vII49oypQpmj59urp27aqEhAQVFRVJOnX9+plnntHixYvVtm1bDR8+XJKUlJSkZcuWaeXKlerRo4eGDBmilStXWm6Pa9q0qf7zn/9o165d6tOnj6ZNm6Z58+Y59H179+6t+fPna968eerevbvWrl2r1NTUWvMaN26shx56SKNGjVJcXJyCgoL073//2/L51VdfrXfffVcZGRnq16+fBgwYoPnz5ysqKsqheAC4Bu9jBwDAi1CxAwDgRUjsAAB4ERI7AABehMQOAIAXIbEDAOBFSOwAAHgREjsAAF6ExA4AgBchsQMA4EVI7AAAeBESOwAAXuT/A+yE5rK7dfrwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(ytest, yhat, labels=lsvm.classes_,\n",
    "                                        xticks_rotation=\"vertical\", normalize=\"true\",\n",
    "                                        cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify previously unseen reviews\n",
    "\n",
    "Some reviews from the Rotten Tomatoes website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:53:26.993250Z",
     "start_time": "2021-12-11T17:53:26.981249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Never let the audience off the hook, Hitchcock once said. \n",
      "               Ho achieves this in spades and with more than one hook. => neg\n",
      "\n",
      "The smartest mainstream film about class made in many \n",
      "               years, Bong Joon-ho's Parasite lays bare the lie that hard \n",
      "               work can bring anyone closer to their dreams. => pos\n",
      "\n",
      "[A] funny, inventive, scary film. => pos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_reviews = [\n",
    "               \"\"\"Never let the audience off the hook, Hitchcock once said. \n",
    "               Ho achieves this in spades and with more than one hook.\"\"\",\n",
    "    \n",
    "               \"\"\"The smartest mainstream film about class made in many \n",
    "               years, Bong Joon-ho's Parasite lays bare the lie that hard \n",
    "               work can bring anyone closer to their dreams.\"\"\",\n",
    "    \n",
    "               \"\"\"[A] funny, inventive, scary film.\"\"\"\n",
    "            ]\n",
    "\n",
    "# preprocess and transform\n",
    "new_reviews_counts = count_vectorizer.transform(new_reviews)\n",
    "new_reviews_tfidf = tfidf_transformer.transform(new_reviews_counts)\n",
    "new_scaled = scaler.transform(new_reviews_tfidf)\n",
    "\n",
    "# predict labels\n",
    "predictions = lsvm.predict(new_scaled)\n",
    "\n",
    "# print results\n",
    "for review, category in zip(new_reviews, predictions):\n",
    "    print(f'{review} => {movie.target_names[category]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citing this notebook\n",
    "\n",
    "If you use this notebook in your work, please cite it as follows:\n",
    "    \n",
    "Pekar, V. (2024). Big Data for Decision Making. Lecture examples and exercises. (Version 1.0.0). URL: https://github.com/vpekar/bd4dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
