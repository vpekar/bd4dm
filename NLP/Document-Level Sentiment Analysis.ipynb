{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook shows an example how text files, labelled for sentiment (positive or negative), can be converted to a tabular format and then used to train a machine learning model capable of classifying new texts by sentiment.\n",
    "\n",
    "As an example, we will use a corpus of movie reviews first used in (Pang and Lee, 2004), for details see [here](http://www.cs.cornell.edu/people/pabo/movie-review-data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T10:59:17.901604Z",
     "start_time": "2023-03-03T10:59:15.859686Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting logging to print only error messages of sklearnex\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"SKLEARNEX\").setLevel(logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "If the data has not been downloaded before, download it, and save to a folder called \"datasets\", alongside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:04:47.311401Z",
     "start_time": "2023-03-03T11:03:49.320767Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import tarfile\n",
    "\n",
    "url = \"https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\"\n",
    "    \n",
    "def download_data(url):\n",
    "    \"\"\"Download the data and extract the mo\n",
    "    \"\"\"\n",
    "    \n",
    "    # if the \"datasets\" folder does not exist, create it\n",
    "    if not os.path.exists(\"datasets\"):\n",
    "        os.makedirs(\"datasets\")\n",
    "    \n",
    "    # if the archived file does not exist, download it\n",
    "    if not os.path.exists(\"datasets/review_polarity.tar.gz\"):\n",
    "        urllib.request.urlretrieve(url, \"datasets/review_polarity.tar.gz\")\n",
    "    \n",
    "    # if the unpacked file does not exist, unpack it\n",
    "    if not os.path.exists(\"datasets/txt_sentoken\"):\n",
    "        infile = tarfile.open(\"datasets/review_polarity.tar.gz\")\n",
    "        infile.extractall(path=\"datasets\")\n",
    "        infile.close()\n",
    "\n",
    "download_data(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above will produce a folder inside \"datasets\", called \"txt_sentoken\". That folder will contain two subfolders - \"pos\" (containing 1000 files manually labelled as positive) and \"neg\" (containing 1000 files manually labelled as \"negative\"). Each file is a separate movie review, after minimal normalization (inserting spaces around punctuation symbols, lower-casing all words, etc).\n",
    "\n",
    "We will use Scikit-learn's `load_files` function to load these data into a format that can be input directly into other scikit-learn tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:15.801419Z",
     "start_time": "2023-03-03T11:07:00.418776Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "# loading all files. \n",
    "movie = load_files(\"./datasets/txt_sentoken/\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:32.378066Z",
     "start_time": "2023-03-03T11:07:32.356125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:33.128797Z",
     "start_time": "2023-03-03T11:07:33.121815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target names (\"classes\") are automatically generated from subfolder names\n",
    "movie.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:34.543297Z",
     "start_time": "2023-03-03T11:07:34.521356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so called dark thriller , the devil ( gabriel byrne ) has come upon earth , to impregnate a woman ( robin tunney ) which happens every 1000 years , and basically destroy the world , but apparently god has chosen one man , and that one man is jericho cane ( arnold himself ) . \\nwith the help of a trusty sidekick ( kevin pollack ) , they will stop at nothing to let the devil take over the world ! \\nparts of this are actually so absurd , that they would fit right in with dogma . \\nyes , the film is that weak , but it's better than the other blockbuster right now ( sleepy hollow ) , but it makes the world is not enough look like a 4 star film . \\nanyway , this definitely doesn't seem like an arnold movie . \\nit just wasn't the type of film you can see him doing . \\nsure he gave us a few chuckles with his well known one-liners , but he seemed confused as to where his character and the film was going . \\nit's understandable , especially when the ending had to be changed according to some sources . \\naside form that , he still walked through it , much like he has in the past few films . \\ni'm sorry to say this arnold but maybe these are the end of your action days . \\nspeaking of action , where was it in this film ? \\nthere was hardly any explosions or fights . \\nthe devil made a few places explode , but arnold wasn't kicking some devil butt . \\nthe ending was changed to make it more spiritual , which undoubtedly ruined the film . \\ni was at least hoping for a cool ending if nothing else occurred , but once again i was let down . \\ni also don't know why the film took so long and cost so much . \\nthere was really no super affects at all , unless you consider an invisible devil , who was in it for 5 minutes tops , worth the overpriced budget . \\nthe budget should have gone into a better script , where at least audiences could be somewhat entertained instead of facing boredom . \\nit's pitiful to see how scripts like these get bought and made into a movie . \\ndo they even read these things anymore ? \\nit sure doesn't seem like it . \\nthankfully gabriel's performance gave some light to this poor film . \\nwhen he walks down the street searching for robin tunney , you can't help but feel that he looked like a devil . \\nthe guy is creepy looking anyway ! \\nwhen it's all over , you're just glad it's the end of the movie . \\ndon't bother to see this , if you're expecting a solid action flick , because it's neither solid nor does it have action . \\nit's just another movie that we are suckered in to seeing , due to a strategic marketing campaign . \\nsave your money and see the world is not enough for an entertaining experience . \\n\"\n"
     ]
    }
   ],
   "source": [
    "# First file seems to be about a Schwarzenegger movie. \n",
    "print(movie.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:37.161072Z",
     "start_time": "2023-03-03T11:07:37.149105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split\n",
    "\n",
    "The data has been loaded by scikit-learn into a special data structure, which is neither a numpy array or a pandas dataframe. Nonetheless, we can use scikit-learn's `train_test_split` to split the data into the training and test parts:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:39.577156Z",
     "start_time": "2023-03-03T11:07:39.407117Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(movie.data, movie.target, \n",
    "                                                          test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:39.793373Z",
     "start_time": "2023-03-03T11:07:39.764772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 train and 400 test instances\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(docs_train)} train and {len(docs_test)} test instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation\n",
    "\n",
    "## Create Bag-of-Words representations\n",
    "\n",
    "`CountVectorizer` is a convenient facility to create bag-of-words representations of documents into a numpy array. Setting the arguments of the constructor class, we can configure the basic linguistic preprocessing steps that should be applied to it: supplying a custom tokenizer, stopword list, ngram range, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:42.442353Z",
     "start_time": "2023-03-03T11:07:42.432379Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "    strip_accents=\"unicode\", # convert accented chars to non-accented versions\n",
    "    lowercase=True,\n",
    "    tokenizer=None,        # None - use the default tokenizer\n",
    "    preprocessor=None,     # None - use the default preprocessor\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1,1),     # min and max range of ngrams\n",
    "    analyzer=\"word\",       # split the document into words, rather than e.g. characters\n",
    "    max_df=1.0,            # ignore words with df greater than the value (int represents count, \n",
    "                           # float represents proportion of documents)\n",
    "    min_df=1               # ignore words the df lower than the value (int represents count, \n",
    "                           # float represents proportion)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create an instance of `CountVectorizer` and then call its `fit_transform` method. It first \"fits\" on the data, i.e., extracts individual features from each document, as specified by the arguments to the constructor method (e.g., extract bigrams), and then \"transforms\" the data, i.e. creates numpy arrays where rows are documents, columns are features extracted from the documents, and values in the cells are counts of each feature in each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:46.641206Z",
     "start_time": "2023-03-03T11:07:45.679613Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit and tranform using training text \n",
    "docs_train_counts = count_vectorizer.fit_transform(docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:46.657291Z",
     "start_time": "2023-03-03T11:07:46.642115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 36034)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, there 1600 rows, one for each document, and 36304 columns, one for each feature.\n",
    "\n",
    "Let's check the datatype of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:07:48.790446Z",
     "start_time": "2023-03-03T11:07:48.782467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the data is stored in a special data structure called \"sparse matrix\", specifically Compressed Sparse Row. Because there are many zeros in each row (in the first row, there are 139 non-zero values, out of the total of 36034), the sparse matrix stores the data more efficiently and thus is able to represent relatively large text collections, without running into memory errors.\n",
    "\n",
    "We can, however, convert a sparse matrix to a normal, \"dense\", numpy array, if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.226903Z",
     "start_time": "2021-12-11T17:35:23.213937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train_counts[0, :].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted `count_vectorizer` stores also the vocabulary of the text collection on which it was fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.336608Z",
     "start_time": "2021-12-11T17:35:23.229894Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plot': 24052,\n",
       " 'realization': 25791,\n",
       " 'failing': 11553,\n",
       " 'classes': 5942,\n",
       " 'roommates': 27226,\n",
       " 'try': 33121,\n",
       " 'roomie': 27222,\n",
       " 'kill': 17734,\n",
       " 'school': 27926,\n",
       " 'charter': 5499,\n",
       " 'automatically': 2499,\n",
       " 'grants': 13861,\n",
       " 'grades': 13811,\n",
       " 'student': 30873,\n",
       " 'succeeds': 31043,\n",
       " 'suicide': 31109,\n",
       " 'critique': 7553,\n",
       " 'despite': 8653,\n",
       " 'film': 12018,\n",
       " 'interesting': 16674,\n",
       " 'premise': 24584,\n",
       " 'dark': 8005,\n",
       " 'subject': 30959,\n",
       " 'matter': 19840,\n",
       " 'movie': 21035,\n",
       " 'sucks': 31067,\n",
       " 'unfunny': 33708,\n",
       " 'boring': 3981,\n",
       " 'presents': 24632,\n",
       " 'tom': 32536,\n",
       " 'everett': 11073,\n",
       " 'scott': 28022,\n",
       " 'worst': 35631,\n",
       " 'acting': 859,\n",
       " 'performances': 23449,\n",
       " 'add': 910,\n",
       " 'completely': 6534,\n",
       " 'unsuccessful': 33966,\n",
       " 'romance': 27177,\n",
       " 'element': 10325,\n",
       " 'lame': 18102,\n",
       " 'corny': 7168,\n",
       " 'jokes': 17312,\n",
       " 'long': 18947,\n",
       " 'wait': 34801,\n",
       " 'setup': 28462,\n",
       " 'ending': 10603,\n",
       " 'takes': 31651,\n",
       " 'blackness': 3571,\n",
       " 'black': 3556,\n",
       " 'comedy': 6376,\n",
       " 'gonna': 13689,\n",
       " 'create': 7449,\n",
       " 'don': 9527,\n",
       " 'chicken': 5634,\n",
       " 'end': 10588,\n",
       " 'bad': 2674,\n",
       " 'things': 32187,\n",
       " '10': 9,\n",
       " 'perfect': 23436,\n",
       " 'example': 11139,\n",
       " 've': 34306,\n",
       " 'got': 13764,\n",
       " 'trite': 33019,\n",
       " 'mtv': 21073,\n",
       " 'creation': 7453,\n",
       " 'worthy': 35637,\n",
       " 'barely': 2864,\n",
       " 'laughed': 18247,\n",
       " 'gags': 13030,\n",
       " 'bong': 3897,\n",
       " 'contrived': 7015,\n",
       " 'repetitive': 26433,\n",
       " 'horrified': 15349,\n",
       " 'gratuitous': 13887,\n",
       " 'nudity': 21945,\n",
       " 'tossed': 32646,\n",
       " 'make': 19411,\n",
       " 'college': 6294,\n",
       " 'slap': 29273,\n",
       " 'free': 12750,\n",
       " 'shots': 28816,\n",
       " 'kids': 17720,\n",
       " 'worth': 35632,\n",
       " 'rental': 26395,\n",
       " 'fellas': 11839,\n",
       " 'skip': 29222,\n",
       " 'altogether': 1434,\n",
       " 'little': 18809,\n",
       " 'known': 17892,\n",
       " 'facts': 11535,\n",
       " 'stars': 30404,\n",
       " 'auditions': 2433,\n",
       " 'thing': 32181,\n",
       " 'feature': 11789,\n",
       " 'role': 27156,\n",
       " 'director': 9001,\n",
       " 'hanks': 14450,\n",
       " 'opposed': 22362,\n",
       " 'hiring': 15073,\n",
       " 'fact': 11524,\n",
       " 'passed': 23129,\n",
       " '15': 56,\n",
       " 'years': 35813,\n",
       " 'ago': 1177,\n",
       " 'wasn': 34946,\n",
       " 'wife': 35319,\n",
       " 'rita': 27022,\n",
       " 'wilson': 35363,\n",
       " 'saw': 27779,\n",
       " 'audition': 2431,\n",
       " 'tape': 31736,\n",
       " 'decided': 8178,\n",
       " 'cute': 7809,\n",
       " 'risk': 27013,\n",
       " 'actor': 873,\n",
       " 'played': 23991,\n",
       " 'cooper': 7093,\n",
       " 'mark': 19651,\n",
       " 'paul': 23215,\n",
       " 'gosselaar': 13761,\n",
       " 'best': 3357,\n",
       " 'having': 14640,\n",
       " 'character': 5447,\n",
       " 'zack': 35919,\n",
       " 'morris': 20922,\n",
       " 'tv': 33229,\n",
       " 'saved': 27762,\n",
       " 'bell': 3237,\n",
       " 'parents': 23043,\n",
       " 'dutch': 10004,\n",
       " 'named': 21314,\n",
       " 'hans': 14461,\n",
       " 'paula': 23216,\n",
       " 'guessed': 14149,\n",
       " 'alan': 1265,\n",
       " 'cohn': 6221,\n",
       " 'shot': 28814,\n",
       " 'directing': 8995,\n",
       " 'enduring': 10619,\n",
       " 'mariah': 19626,\n",
       " 'carey': 5038,\n",
       " 'debut': 8143,\n",
       " 'glitter': 13547,\n",
       " 'reminded': 26326,\n",
       " 'bit': 3529,\n",
       " 'chris': 5752,\n",
       " 'rock': 27114,\n",
       " 'bigger': 3434,\n",
       " 'blacker': 3559,\n",
       " 'response': 26624,\n",
       " 'women': 35521,\n",
       " 'saying': 27788,\n",
       " 'raise': 25556,\n",
       " 'child': 5644,\n",
       " 'man': 19470,\n",
       " 'says': 27792,\n",
       " 'drive': 9819,\n",
       " 'car': 5005,\n",
       " 'feet': 11823,\n",
       " 'mean': 19996,\n",
       " 'say': 27786,\n",
       " 'certainly': 5352,\n",
       " 'sure': 31272,\n",
       " 'plenty': 24037,\n",
       " 'pop': 24246,\n",
       " 'star': 30378,\n",
       " 'vehicles': 34322,\n",
       " 'beatles': 3078,\n",
       " 'hard': 14493,\n",
       " 'day': 8067,\n",
       " 'night': 21678,\n",
       " 'spice': 30022,\n",
       " 'girls': 13455,\n",
       " 'world': 35602,\n",
       " 'vapidly': 34264,\n",
       " 'pointless': 24131,\n",
       " 'laughable': 18245,\n",
       " 'complete': 6532,\n",
       " 'tripe': 33004,\n",
       " 'ludicrous': 19132,\n",
       " 'start': 30408,\n",
       " 'story': 30675,\n",
       " 'gruesomely': 14104,\n",
       " 'predictable': 24539,\n",
       " 'offensive': 22188,\n",
       " 'inexplicably': 16291,\n",
       " 'set': 28447,\n",
       " '80s': 366,\n",
       " 'period': 23467,\n",
       " 'piece': 23768,\n",
       " 'really': 25797,\n",
       " 'shows': 28853,\n",
       " 'sign': 28964,\n",
       " 'chicks': 5636,\n",
       " 'leg': 18405,\n",
       " 'warmers': 34909,\n",
       " 'worse': 35622,\n",
       " 'speaking': 29945,\n",
       " 'late': 18227,\n",
       " '90s': 382,\n",
       " 'hip': 15059,\n",
       " 'hop': 15300,\n",
       " 'slang': 29272,\n",
       " '1983': 179,\n",
       " 'meant': 20012,\n",
       " 'partially': 23087,\n",
       " 'autobiographical': 2494,\n",
       " 'plays': 24003,\n",
       " 'billie': 3464,\n",
       " 'frank': 12704,\n",
       " 'young': 35878,\n",
       " 'singer': 29075,\n",
       " 'new': 21580,\n",
       " 'york': 35870,\n",
       " 'struggles': 30850,\n",
       " 'overcome': 22656,\n",
       " 'rough': 27293,\n",
       " 'childhood': 5648,\n",
       " 'abandonment': 598,\n",
       " 'alcoholic': 1292,\n",
       " 'mother': 20960,\n",
       " 'influential': 16344,\n",
       " 'club': 6104,\n",
       " 'dj': 9411,\n",
       " 'julian': 17427,\n",
       " 'dice': 8836,\n",
       " 'lucky': 19127,\n",
       " 'max': 19871,\n",
       " 'beesley': 3152,\n",
       " 'playing': 24000,\n",
       " 'mix': 20649,\n",
       " 'puff': 25178,\n",
       " 'daddy': 7874,\n",
       " 'robert': 27085,\n",
       " 'niro': 21726,\n",
       " 'hears': 14730,\n",
       " 'sing': 29070,\n",
       " 'track': 32723,\n",
       " 'decides': 8181,\n",
       " 'predictably': 24540,\n",
       " 'rapid': 25647,\n",
       " 'succession': 31048,\n",
       " 'fall': 11594,\n",
       " 'starts': 30416,\n",
       " 'hitting': 15116,\n",
       " 'big': 3430,\n",
       " 'gets': 13355,\n",
       " 'jealous': 17133,\n",
       " 'like': 18667,\n",
       " 'ass': 2198,\n",
       " 'suddenly': 31071,\n",
       " 'roller': 27163,\n",
       " 'coaster': 6150,\n",
       " 'superstardom': 31225,\n",
       " 'meantime': 20013,\n",
       " 'emotional': 10506,\n",
       " 'hunt': 15587,\n",
       " 'missing': 20603,\n",
       " 'mom': 20754,\n",
       " 'won': 35524,\n",
       " 'away': 2569,\n",
       " 'honestly': 15252,\n",
       " 'just': 17478,\n",
       " 'think': 32188,\n",
       " 'unicorns': 33726,\n",
       " 'rainbows': 25542,\n",
       " 'll': 18836,\n",
       " 'figure': 11996,\n",
       " 'screams': 28064,\n",
       " 'camp': 4861,\n",
       " 'fun': 12928,\n",
       " 'filmmakers': 12031,\n",
       " 'thought': 32229,\n",
       " 'making': 19419,\n",
       " 'bulk': 4520,\n",
       " 'weepy': 35087,\n",
       " 'dramatic': 9717,\n",
       " 'better': 3380,\n",
       " 'mistake': 20617,\n",
       " 'brief': 4280,\n",
       " 'attempts': 2374,\n",
       " 'comic': 6388,\n",
       " 'relief': 26267,\n",
       " 'scene': 27859,\n",
       " 'effeminate': 10220,\n",
       " 'russian': 27444,\n",
       " 'sounding': 29842,\n",
       " 'wacky': 34767,\n",
       " 'filming': 12029,\n",
       " 'music': 21202,\n",
       " 'video': 34481,\n",
       " 'lead': 18322,\n",
       " 'balloons': 2760,\n",
       " 'instead': 16570,\n",
       " 'audience': 2425,\n",
       " 'screening': 28072,\n",
       " 'tended': 31967,\n",
       " 'laugh': 18244,\n",
       " 'loudest': 19035,\n",
       " 'scenes': 27861,\n",
       " 'brings': 4313,\n",
       " 'good': 13695,\n",
       " 'said': 27552,\n",
       " 'primarily': 24725,\n",
       " 'seen': 28249,\n",
       " 'wide': 35297,\n",
       " 'eyed': 11475,\n",
       " 'deer': 8258,\n",
       " 'headlights': 14695,\n",
       " 'look': 18967,\n",
       " 'frozen': 12872,\n",
       " 'face': 11504,\n",
       " 'actually': 884,\n",
       " 'looks': 18975,\n",
       " 'scared': 27830,\n",
       " 'love': 19055,\n",
       " 'wonder': 35526,\n",
       " 'writing': 35695,\n",
       " 'isn': 16974,\n",
       " 'dialogue': 8811,\n",
       " 'hackneyed': 14291,\n",
       " 'watered': 34976,\n",
       " 'virginal': 34591,\n",
       " 'target': 31757,\n",
       " 'probably': 24781,\n",
       " 'impossible': 15997,\n",
       " 'pull': 25190,\n",
       " 'aplomb': 1823,\n",
       " 'characters': 5459,\n",
       " 'couldn': 7248,\n",
       " 'written': 35697,\n",
       " 'absurdly': 699,\n",
       " 'members': 20126,\n",
       " 'barbie': 2852,\n",
       " 'playset': 24004,\n",
       " 'important': 15986,\n",
       " 'swoons': 31492,\n",
       " 'time': 32390,\n",
       " 'record': 25943,\n",
       " 'executive': 11224,\n",
       " 'demo': 8446,\n",
       " 'oh': 22216,\n",
       " 'team': 31835,\n",
       " 'listens': 18785,\n",
       " 'morning': 20903,\n",
       " 'device': 8755,\n",
       " 'painful': 22863,\n",
       " 'watching': 34970,\n",
       " 'appear': 1855,\n",
       " 'waste': 34950,\n",
       " 'wrong': 35698,\n",
       " 'pains': 22868,\n",
       " 'ego': 10241,\n",
       " 'sanity': 27672,\n",
       " 'fragile': 12670,\n",
       " 'condition': 6669,\n",
       " 'days': 8072,\n",
       " 'evidenced': 11087,\n",
       " 'multiple': 21129,\n",
       " 'hospital': 15375,\n",
       " 'stays': 30454,\n",
       " 'suffer': 31076,\n",
       " 'negative': 21485,\n",
       " 'reviews': 26789,\n",
       " 'likely': 18672,\n",
       " 'heard': 14726,\n",
       " 'priest': 24712,\n",
       " 'rabbi': 25453,\n",
       " 'dosage': 9604,\n",
       " 'featherweight': 11786,\n",
       " 'charm': 5487,\n",
       " 'sprinkled': 30185,\n",
       " 'keeping': 17607,\n",
       " 'faith': 11577,\n",
       " 'fluffy': 12383,\n",
       " 'thoroughly': 32222,\n",
       " 'glazed': 13510,\n",
       " 'sense': 28343,\n",
       " 'innocuous': 16468,\n",
       " 'innocence': 16464,\n",
       " 'cheer': 5561,\n",
       " 'regarding': 26114,\n",
       " 'moral': 20865,\n",
       " 'topics': 32591,\n",
       " 'religion': 26271,\n",
       " 'romantic': 27187,\n",
       " 'triangle': 32955,\n",
       " 'causes': 5235,\n",
       " 'collide': 6298,\n",
       " 'head': 14680,\n",
       " 'youngsters': 35883,\n",
       " 'brian': 4262,\n",
       " 'finn': 12091,\n",
       " 'jacob': 17036,\n",
       " 'schramm': 27942,\n",
       " 'anna': 1699,\n",
       " 'reilly': 26181,\n",
       " 'inseparable': 16507,\n",
       " 'trio': 33002,\n",
       " 'friendship': 12817,\n",
       " 'progressed': 24880,\n",
       " 'compassion': 6489,\n",
       " 'shower': 28842,\n",
       " 'support': 31250,\n",
       " 'feel': 11815,\n",
       " 'excluded': 11193,\n",
       " 'tragedy': 32748,\n",
       " 'soon': 29783,\n",
       " 'struck': 30841,\n",
       " 'forced': 12516,\n",
       " 'adults': 1028,\n",
       " 'edward': 10200,\n",
       " 'norton': 21842,\n",
       " 'ben': 3271,\n",
       " 'stiller': 30573,\n",
       " 'hold': 15162,\n",
       " 'similar': 29021,\n",
       " 'contrastive': 7005,\n",
       " 'jobs': 17271,\n",
       " 'likable': 18666,\n",
       " 'kind': 17760,\n",
       " 'hearted': 14739,\n",
       " 'father': 11724,\n",
       " 'catholic': 5213,\n",
       " 'spry': 30204,\n",
       " 'outgoing': 22556,\n",
       " 'acts': 878,\n",
       " 'jewish': 17218,\n",
       " 'basketball': 2955,\n",
       " 'court': 7308,\n",
       " 'refer': 26053,\n",
       " 'god': 13618,\n",
       " 'squad': 30226,\n",
       " 'relationship': 26235,\n",
       " 'field': 11964,\n",
       " 'abides': 626,\n",
       " 'principle': 24742,\n",
       " 'celibacy': 5293,\n",
       " 'reached': 25749,\n",
       " 'point': 24124,\n",
       " 'finding': 12063,\n",
       " 'bride': 4272,\n",
       " 'practically': 24457,\n",
       " 'mandatory': 19486,\n",
       " 'changes': 5416,\n",
       " 'jenna': 17169,\n",
       " 'elfman': 10338,\n",
       " 'returns': 26742,\n",
       " 'visit': 34626,\n",
       " 'chums': 5795,\n",
       " 'workaholic': 35583,\n",
       " 'devotes': 8781,\n",
       " 'endless': 10605,\n",
       " 'hours': 15417,\n",
       " 'week': 35076,\n",
       " 'business': 4659,\n",
       " 'does': 9455,\n",
       " 'spare': 29912,\n",
       " 'reminisce': 26333,\n",
       " 'ecstatic': 10146,\n",
       " 'seeing': 28239,\n",
       " 'elementary': 10326,\n",
       " 'sweetheart': 31440,\n",
       " 'oddball': 22150,\n",
       " 'ingredients': 16393,\n",
       " 'cocktail': 6180,\n",
       " 'bound': 4036,\n",
       " 'awkward': 2581,\n",
       " 'central': 5328,\n",
       " 'predicting': 24543,\n",
       " 'outcome': 22540,\n",
       " 'entirely': 10767,\n",
       " 'difficult': 8889,\n",
       " 'open': 22323,\n",
       " 'entertaining': 10745,\n",
       " 'refreshingly': 26091,\n",
       " 'relaxed': 26243,\n",
       " 'travels': 32888,\n",
       " 'en': 10548,\n",
       " 'route': 27316,\n",
       " 'emerged': 10473,\n",
       " 'finest': 12071,\n",
       " 'flexibly': 12292,\n",
       " 'versatile': 34402,\n",
       " 'actors': 874,\n",
       " 'hollywood': 15192,\n",
       " 'success': 31044,\n",
       " 'sparked': 29917,\n",
       " 'critically': 7542,\n",
       " 'lauded': 18243,\n",
       " '1996': 193,\n",
       " 'thriller': 32263,\n",
       " 'primal': 24723,\n",
       " 'fear': 11768,\n",
       " 'shockingly': 28763,\n",
       " 'bitter': 3544,\n",
       " 'roles': 27157,\n",
       " 'american': 1507,\n",
       " 'history': 15094,\n",
       " 'recently': 25875,\n",
       " 'david': 8054,\n",
       " 'fincher': 12061,\n",
       " 'vicious': 34459,\n",
       " 'fight': 11985,\n",
       " 'quaint': 25336,\n",
       " 'peculiar': 23295,\n",
       " 'choice': 5702,\n",
       " 'slips': 29375,\n",
       " 'chair': 5380,\n",
       " 'incisive': 16108,\n",
       " 'resourceful': 26605,\n",
       " 'approach': 1907,\n",
       " 'helps': 14859,\n",
       " 'additional': 923,\n",
       " 'craft': 7387,\n",
       " 'surprisingly': 31304,\n",
       " 'perceptive': 23423,\n",
       " 'screenplay': 28074,\n",
       " 'stuart': 30860,\n",
       " 'blumberg': 3762,\n",
       " 'weighing': 35091,\n",
       " 'aspect': 2189,\n",
       " 'unanimously': 33389,\n",
       " 'impressive': 16020,\n",
       " 'directorial': 9003,\n",
       " 'addition': 922,\n",
       " 'pushes': 25300,\n",
       " 'right': 26950,\n",
       " 'buttons': 4703,\n",
       " 'sheepish': 28649,\n",
       " 'generating': 13260,\n",
       " 'screen': 28069,\n",
       " 'presence': 24624,\n",
       " 'zipper': 35997,\n",
       " 'guy': 14252,\n",
       " 'mary': 19727,\n",
       " 'firm': 12122,\n",
       " 'funny': 12962,\n",
       " 'boasting': 3801,\n",
       " 'fully': 12921,\n",
       " 'ripened': 26996,\n",
       " 'maturity': 19852,\n",
       " 'perky': 23485,\n",
       " 'repetition': 26429,\n",
       " 'grow': 14085,\n",
       " 'tiresome': 32453,\n",
       " 'occasionally': 22114,\n",
       " 'case': 5128,\n",
       " 'dharma': 8796,\n",
       " 'greg': 13952,\n",
       " 'perfectly': 23441,\n",
       " 'rambunctious': 25582,\n",
       " 'remaining': 26299,\n",
       " 'cast': 5149,\n",
       " 'offer': 22190,\n",
       " 'fine': 12066,\n",
       " 'anne': 1704,\n",
       " 'bancroft': 2780,\n",
       " 'animated': 1679,\n",
       " 'milos': 20422,\n",
       " 'forman': 12589,\n",
       " 'elderly': 10294,\n",
       " 'quick': 25389,\n",
       " 'contribute': 7007,\n",
       " 'intelligent': 16633,\n",
       " 'advice': 1056,\n",
       " 'date': 8041,\n",
       " 'flick': 12295,\n",
       " 'perfection': 23439,\n",
       " 'word': 35570,\n",
       " 'associate': 2259,\n",
       " 'general': 13251,\n",
       " 'turbulence': 33179,\n",
       " 'process': 24797,\n",
       " 'lift': 18644,\n",
       " 'numerous': 21967,\n",
       " 'failed': 11552,\n",
       " 'establishing': 10976,\n",
       " 'situation': 29134,\n",
       " 'cloud': 6095,\n",
       " 'projected': 24889,\n",
       " 'ahead': 1194,\n",
       " 'settle': 28456,\n",
       " 'cheerful': 5563,\n",
       " 'created': 7450,\n",
       " 'enormously': 10705,\n",
       " 'lovable': 19053,\n",
       " 'personalities': 23537,\n",
       " 'enjoy': 10674,\n",
       " 'interaction': 16658,\n",
       " 'understand': 33560,\n",
       " 'various': 34280,\n",
       " 'dilemmas': 8928,\n",
       " 'humbled': 15532,\n",
       " 'realize': 25793,\n",
       " 'rings': 26983,\n",
       " 'true': 33089,\n",
       " 'excluding': 11194,\n",
       " 'acceptable': 736,\n",
       " 'lack': 18042,\n",
       " 'spontaneity': 30122,\n",
       " 'preceding': 24505,\n",
       " 'entanglements': 10733,\n",
       " 'nonetheless': 21794,\n",
       " 'narrowly': 21356,\n",
       " 'mishandled': 20573,\n",
       " 'finale': 12047,\n",
       " 'wipe': 35428,\n",
       " 'smile': 29475,\n",
       " 'highly': 15003,\n",
       " 'enjoyable': 10676,\n",
       " 'observant': 22069,\n",
       " 'surveying': 31323,\n",
       " 'questions': 25382,\n",
       " 'aww': 2590,\n",
       " 'hell': 14833,\n",
       " 'quality': 25343,\n",
       " 'quite': 25427,\n",
       " 'heaven': 14761,\n",
       " 'sent': 28361,\n",
       " 'charmer': 5490,\n",
       " 'revive': 26806,\n",
       " 'potentially': 24403,\n",
       " 'tired': 32448,\n",
       " 'filmmaking': 12032,\n",
       " 'genre': 13289,\n",
       " 'altman': 1432,\n",
       " 'cookie': 7078,\n",
       " 'fortune': 12627,\n",
       " 'rare': 25666,\n",
       " 'depend': 8524,\n",
       " 'sentimentality': 28369,\n",
       " 'uplifting': 34053,\n",
       " 'viewers': 34506,\n",
       " 'sunny': 31173,\n",
       " 'delightful': 8387,\n",
       " 'dreamy': 9769,\n",
       " 'filled': 12011,\n",
       " 'lovely': 19064,\n",
       " 'skillful': 29206,\n",
       " 'direction': 8996,\n",
       " 'topped': 32595,\n",
       " 'understated': 33567,\n",
       " 'clever': 6008,\n",
       " 'extraordinary': 11439,\n",
       " 'script': 28095,\n",
       " 'ensemble': 10716,\n",
       " 'slowly': 29408,\n",
       " 'introduces': 16794,\n",
       " 'residing': 26567,\n",
       " 'southern': 29863,\n",
       " 'town': 32698,\n",
       " 'called': 4817,\n",
       " 'holly': 15191,\n",
       " 'springs': 30181,\n",
       " 'meet': 20075,\n",
       " 'willie': 35351,\n",
       " 'charles': 5480,\n",
       " 'dutton': 10009,\n",
       " 'honest': 15251,\n",
       " 'slight': 29353,\n",
       " 'drinking': 9811,\n",
       " 'habit': 14278,\n",
       " 'care': 5022,\n",
       " 'lady': 18066,\n",
       " 'nicknamed': 21648,\n",
       " 'losing': 19021,\n",
       " 'grip': 14008,\n",
       " 'loneliness': 18941,\n",
       " 'despair': 8641,\n",
       " 'want': 34880,\n",
       " 'dead': 8087,\n",
       " 'husband': 15617,\n",
       " 'cut': 7806,\n",
       " 'camille': 4857,\n",
       " 'glenn': 13529,\n",
       " 'close': 6075,\n",
       " 'obsessively': 22087,\n",
       " 'play': 23985,\n",
       " 'sister': 29116,\n",
       " 'cora': 7133,\n",
       " 'julianne': 17430,\n",
       " 'moore': 20856,\n",
       " 'briefly': 4284,\n",
       " 'acquainted': 838,\n",
       " 'emma': 10493,\n",
       " 'liv': 18814,\n",
       " 'tyler': 33281,\n",
       " 'apparent': 1847,\n",
       " 'relative': 26237,\n",
       " 'teen': 31886,\n",
       " 'outcast': 22537,\n",
       " 'hope': 15301,\n",
       " 'real': 25777,\n",
       " 'place': 23921,\n",
       " 'live': 18815,\n",
       " 'fleetingly': 12275,\n",
       " 'lover': 19067,\n",
       " 'jason': 17112,\n",
       " 'donnell': 9546,\n",
       " 'ambitious': 1487,\n",
       " 'far': 11659,\n",
       " 'excitable': 11178,\n",
       " 'cop': 7103,\n",
       " 'quarter': 25355,\n",
       " 'hour': 15415,\n",
       " 'picture': 23759,\n",
       " 'motion': 20971,\n",
       " 'stare': 30384,\n",
       " 'hopefully': 15304,\n",
       " 'exclaims': 11190,\n",
       " 'come': 6365,\n",
       " 'puts': 25308,\n",
       " 'pillow': 23814,\n",
       " 'shoots': 28786,\n",
       " 'niece': 21663,\n",
       " 'stops': 30660,\n",
       " 'fruit': 12874,\n",
       " 'salad': 27576,\n",
       " 'bowl': 4062,\n",
       " 'comes': 6380,\n",
       " 'upstairs': 34085,\n",
       " 'finds': 12065,\n",
       " 'flips': 12321,\n",
       " 'convinced': 7064,\n",
       " 'disgrace': 9142,\n",
       " 'family': 11622,\n",
       " 'eats': 10113,\n",
       " 'note': 21869,\n",
       " 'convinces': 7065,\n",
       " 'slightly': 29356,\n",
       " 'slow': 29403,\n",
       " 'sweet': 31436,\n",
       " 'murder': 21168,\n",
       " 'makes': 19415,\n",
       " 'stages': 30303,\n",
       " 'scattering': 27851,\n",
       " 'jewelry': 17216,\n",
       " 'floor': 12345,\n",
       " 'breaking': 4204,\n",
       " 'cabinets': 4744,\n",
       " 'windows': 35384,\n",
       " 'doors': 9573,\n",
       " 'throwing': 32284,\n",
       " 'gun': 14205,\n",
       " 'yard': 35787,\n",
       " 'reasonable': 25816,\n",
       " 'suspect': 31338,\n",
       " 'immediately': 15888,\n",
       " 'taken': 31646,\n",
       " 'custody': 7800,\n",
       " 'jail': 17053,\n",
       " 'cell': 5295,\n",
       " 'know': 17886,\n",
       " 'didn': 8861,\n",
       " 'scrabble': 28034,\n",
       " 'sheriff': 28694,\n",
       " 'faithful': 11578,\n",
       " 'unperturbed': 33861,\n",
       " 'continues': 6972,\n",
       " 'subtle': 31023,\n",
       " 'manipulations': 19539,\n",
       " 'trying': 33122,\n",
       " 'cover': 7330,\n",
       " 'easter': 10099,\n",
       " 'begins': 3179,\n",
       " 'aptly': 1928,\n",
       " 'described': 8603,\n",
       " 'critic': 7540,\n",
       " 'renshaw': 26393,\n",
       " 'spin': 30047,\n",
       " 'fargo': 11668,\n",
       " 'funnier': 12960,\n",
       " 'coen': 6197,\n",
       " 'brothers': 4392,\n",
       " 'darker': 8008,\n",
       " 'somewhat': 29758,\n",
       " 'disturbing': 9353,\n",
       " 'overrated': 22735,\n",
       " 'escapade': 10932,\n",
       " 'ways': 35010,\n",
       " 'reminiscent': 26335,\n",
       " 'midnight': 20344,\n",
       " 'garden': 13117,\n",
       " 'evil': 11091,\n",
       " 'films': 12037,\n",
       " 'focus': 12423,\n",
       " 'eccentricities': 10119,\n",
       " 'residents': 26565,\n",
       " 'loads': 18847,\n",
       " 'observe': 22074,\n",
       " 'portion': 24305,\n",
       " 'fascinating': 11694,\n",
       " 'multi': 21121,\n",
       " 'dimensional': 8941,\n",
       " 'turns': 33201,\n",
       " 'insubstantial': 16598,\n",
       " 'terms': 32020,\n",
       " 'career': 5027,\n",
       " 'magnificent': 19355,\n",
       " 'performance': 23448,\n",
       " 'conniving': 6798,\n",
       " 'source': 29854,\n",
       " 'laughs': 18254,\n",
       " 'prolific': 24901,\n",
       " 'aunt': 2448,\n",
       " 'alexandria': 1314,\n",
       " 'endlessly': 10606,\n",
       " 'obsessed': 22081,\n",
       " 'dignity': 8917,\n",
       " 'equally': 10854,\n",
       " 'essential': 10969,\n",
       " 'handled': 14422,\n",
       " 'intangible': 16619,\n",
       " 'grace': 13797,\n",
       " 'veteran': 34422,\n",
       " 'thespian': 32160,\n",
       " 'mimic': 20427,\n",
       " 'leaves': 18361,\n",
       " 'feeling': 11818,\n",
       " 'warm': 34906,\n",
       " 'fuzzy': 13001,\n",
       " 'inside': 16514,\n",
       " 'ends': 10614,\n",
       " 'loved': 19058,\n",
       " 'light': 18650,\n",
       " 'kindhearted': 17766,\n",
       " 'project': 24888,\n",
       " 'intense': 16640,\n",
       " 'drama': 9715,\n",
       " 'gingerbread': 13438,\n",
       " 'took': 32575,\n",
       " 'tricky': 32978,\n",
       " 'enjoyed': 10678,\n",
       " 'talented': 31659,\n",
       " 'liked': 18670,\n",
       " 'south': 29860,\n",
       " 'everybody': 11078,\n",
       " 'related': 26230,\n",
       " 'cliche': 6013,\n",
       " 'inevitably': 16283,\n",
       " 'employed': 10531,\n",
       " 'draws': 9747,\n",
       " 'pleasing': 24024,\n",
       " 'effect': 10213,\n",
       " 'ol': 22230,\n",
       " 'practical': 24456,\n",
       " 'magic': 19340,\n",
       " 'misguided': 20569,\n",
       " 'high': 14994,\n",
       " 'profile': 24856,\n",
       " 'involved': 16877,\n",
       " 'embarrassing': 10439,\n",
       " 'clap': 5916,\n",
       " 'trap': 32857,\n",
       " 'sandra': 27655,\n",
       " 'bullock': 4534,\n",
       " 'nicole': 21656,\n",
       " 'kidman': 17708,\n",
       " 'sally': 27596,\n",
       " 'gillian': 13425,\n",
       " 'owens': 22797,\n",
       " 'sisters': 29118,\n",
       " 'line': 18727,\n",
       " 'witches': 35463,\n",
       " 'spanning': 29909,\n",
       " '200': 202,\n",
       " 'die': 8863,\n",
       " 'children': 5652,\n",
       " 'zany': 35940,\n",
       " 'aunts': 2450,\n",
       " 'stockard': 30609,\n",
       " 'channing': 5423,\n",
       " 'dianne': 8823,\n",
       " 'wiest': 35316,\n",
       " 'switch': 31484,\n",
       " 'present': 24626,\n",
       " 'stronger': 30835,\n",
       " 'rebellious': 25835,\n",
       " 'sibling': 28910,\n",
       " 'home': 15211,\n",
       " 'meets': 20078,\n",
       " 'abusive': 711,\n",
       " 'goran': 13735,\n",
       " 'visjnic': 34633,\n",
       " 'hometown': 15223,\n",
       " 'falls': 11600,\n",
       " 'caring': 5047,\n",
       " 'devastated': 8733,\n",
       " 'hit': 15096,\n",
       " 'truck': 33079,\n",
       " 'killed': 17736,\n",
       " 'minutes': 20503,\n",
       " 'calls': 4826,\n",
       " 'spat': 29930,\n",
       " 'accidentally': 749,\n",
       " 'desperation': 8647,\n",
       " 'bury': 4647,\n",
       " 'body': 3826,\n",
       " 'backyard': 2670,\n",
       " 'house': 15418,\n",
       " 'wildly': 35337,\n",
       " 'convoluted': 7068,\n",
       " 'subplots': 30988,\n",
       " 'involving': 16880,\n",
       " 'rising': 27012,\n",
       " 'exorcism': 11279,\n",
       " 'mention': 20168,\n",
       " 'spattering': 29935,\n",
       " 'whimsy': 35214,\n",
       " 'pretty': 24679,\n",
       " 'idea': 15723,\n",
       " 'messy': 20243,\n",
       " 'reflected': 26070,\n",
       " 'humor': 15552,\n",
       " 'astoundingly': 2296,\n",
       " 'flat': 12233,\n",
       " 'occasional': 22113,\n",
       " 'moments': 20759,\n",
       " 'touching': 32667,\n",
       " 'charming': 5491,\n",
       " 'way': 35004,\n",
       " 'bird': 3506,\n",
       " 'brained': 4119,\n",
       " 'spirit': 30063,\n",
       " 'taking': 31653,\n",
       " 'terribly': 32033,\n",
       " 'getting': 13357,\n",
       " 'reason': 25815,\n",
       " 'standing': 30360,\n",
       " 'attempt': 2371,\n",
       " 'flesh': 12279,\n",
       " 'actual': 879,\n",
       " 'people': 23400,\n",
       " 'goes': 13645,\n",
       " 'aidan': 1204,\n",
       " 'quinn': 25411,\n",
       " 'handsome': 14430,\n",
       " 'police': 24165,\n",
       " 'investigator': 16852,\n",
       " 'misfortune': 20566,\n",
       " 'opposite': 22365,\n",
       " '70': 344,\n",
       " 'minute': 20502,\n",
       " 'develop': 8738,\n",
       " 'service': 28436,\n",
       " 'moving': 21052,\n",
       " 'lines': 18736,\n",
       " 'headed': 14684,\n",
       " 'trouble': 33062,\n",
       " 'opening': 22326,\n",
       " 'credits': 7471,\n",
       " 'deeply': 8257,\n",
       " 'hated': 14608,\n",
       " 'akiva': 1256,\n",
       " 'goldsman': 13670,\n",
       " 'managed': 19472,\n",
       " 'destroy': 8663,\n",
       " 'batman': 2989,\n",
       " 'series': 28416,\n",
       " 'forever': 12560,\n",
       " 'robin': 27094,\n",
       " 'directed': 8994,\n",
       " 'griffin': 13986,\n",
       " 'dunne': 9971,\n",
       " 'year': 35806,\n",
       " 'clumsy': 6119,\n",
       " 'addicted': 916,\n",
       " 'meg': 20079,\n",
       " 'ryan': 27462,\n",
       " 'matthew': 19845,\n",
       " 'broderick': 4352,\n",
       " 'disliked': 9180,\n",
       " 'taste': 31777,\n",
       " 'talentless': 31660,\n",
       " 'filmmaker': 12030,\n",
       " 'tell': 31926,\n",
       " 'quit': 25426,\n",
       " 'ultimately': 33352,\n",
       " 'buried': 4607,\n",
       " 'rip': 26994,\n",
       " 'movies': 21048,\n",
       " 'woody': 35557,\n",
       " 'allen': 1365,\n",
       " 'bananas': 2779,\n",
       " 'martin': 19710,\n",
       " 'scorsese': 28015,\n",
       " 'woo': 35543,\n",
       " 'falling': 11598,\n",
       " 'def': 8259,\n",
       " 'jam': 17066,\n",
       " 'player': 23992,\n",
       " 'awful': 2576,\n",
       " 'booty': 3962,\n",
       " 'ok': 22227,\n",
       " 'embarassing': 10431,\n",
       " 'showing': 28848,\n",
       " 'african': 1128,\n",
       " 'americans': 1513,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary is just a dictionary, where keys are original words and values are their indices in the produced matrix. The vocabulary will be used internally by the fitted vectorizer, when we transform the test data, deriving a document-by-feature matrix, which has the same columns in the same order as the training data.\n",
    "\n",
    "Let's apply the fitted vectorizer also to the test data. Note we call the `transform` method, not `fit` or `fit_transform`, because the vectorizer has been fitted already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.877682Z",
     "start_time": "2021-12-11T17:35:23.339599Z"
    }
   },
   "outputs": [],
   "source": [
    "docs_test_counts = count_vectorizer.transform(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.892913Z",
     "start_time": "2021-12-11T17:35:23.880675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 36034)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_test_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 400 rows (one per document), but the same number of columns as the training data, 36034."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF weighting\n",
    "\n",
    "Further, we can transform the observed counts into TF-IDF weights in order to reflect the importance of every word in the document. This is achieved with `TfidfTransformer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.908388Z",
     "start_time": "2021-12-11T17:35:23.896418Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the transformer needs to be \"fitted\" on the training data and then the fitted transformer should be used to transform both the training and the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:23.987175Z",
     "start_time": "2021-12-11T17:35:23.912376Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit and transform the training set with \"fit_transform()\"\n",
    "docs_train_tfidf = tfidf_transformer.fit_transform(docs_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:24.003136Z",
     "start_time": "2021-12-11T17:35:23.989170Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform test\n",
    "docs_test_tfidf = tfidf_transformer.transform(docs_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize features\n",
    "\n",
    "Fit a scaler on the training set and use it to transform both the training and test sets. We'll use a `MaxAbsScaler` as it is capable of dealing with sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:24.066963Z",
     "start_time": "2021-12-11T17:35:24.006126Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler \n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(docs_train_tfidf)\n",
    "X_test = scaler.transform(docs_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:24.082919Z",
     "start_time": "2021-12-11T17:35:24.069955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1600x36034 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 389594 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:35:24.098876Z",
     "start_time": "2021-12-11T17:35:24.085911Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "Classifying everything as \"pos\"\n",
    "\n",
    "*pos*:\n",
    "* precision: 800/1600 = 0.5\n",
    "* recall: 800/800 = 1.0\n",
    "* f-score: 2/(1/p + 1/r) = 0.66\n",
    "\n",
    "*neg*:\n",
    "* precision: 0/0 = 0.0\n",
    "* recall: 0/800 = 0.0\n",
    "* f-score: 2/(1/p + 1/r) = 0.0\n",
    "\n",
    "*Macro-averaged*:\n",
    "* precision: 0.25\n",
    "* recall: 0.5\n",
    "* **f-score: 0.33**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:36:20.848451Z",
     "start_time": "2021-12-11T17:35:24.102866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 56.72863030433655 seconds\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=7)\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 3 x 3 = 9 combinations in the grid\n",
    "param_grid = {\n",
    "    'max_depth': [15, 30, 50],\n",
    "    'min_samples_split': [10, 20, 50],\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(dtree, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:36:20.896361Z",
     "start_time": "2021-12-11T17:36:20.850446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>diff, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 20}</td>\n",
       "      <td>0.912413</td>\n",
       "      <td>0.652250</td>\n",
       "      <td>28.513711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 50}</td>\n",
       "      <td>0.876511</td>\n",
       "      <td>0.649245</td>\n",
       "      <td>25.928450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10}</td>\n",
       "      <td>0.927735</td>\n",
       "      <td>0.641545</td>\n",
       "      <td>30.848243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 50}</td>\n",
       "      <td>0.916266</td>\n",
       "      <td>0.640543</td>\n",
       "      <td>30.092016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10}</td>\n",
       "      <td>0.976244</td>\n",
       "      <td>0.639679</td>\n",
       "      <td>34.475545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 20}</td>\n",
       "      <td>0.952784</td>\n",
       "      <td>0.638564</td>\n",
       "      <td>32.979132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 50}</td>\n",
       "      <td>0.913624</td>\n",
       "      <td>0.637586</td>\n",
       "      <td>30.213491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 10}</td>\n",
       "      <td>0.979524</td>\n",
       "      <td>0.635997</td>\n",
       "      <td>35.070779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 50, 'min_samples_split': 20}</td>\n",
       "      <td>0.954968</td>\n",
       "      <td>0.634126</td>\n",
       "      <td>33.597160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       params  mean_train_score  \\\n",
       "1  {'max_depth': 15, 'min_samples_split': 20}          0.912413   \n",
       "2  {'max_depth': 15, 'min_samples_split': 50}          0.876511   \n",
       "0  {'max_depth': 15, 'min_samples_split': 10}          0.927735   \n",
       "8  {'max_depth': 50, 'min_samples_split': 50}          0.916266   \n",
       "3  {'max_depth': 30, 'min_samples_split': 10}          0.976244   \n",
       "4  {'max_depth': 30, 'min_samples_split': 20}          0.952784   \n",
       "5  {'max_depth': 30, 'min_samples_split': 50}          0.913624   \n",
       "6  {'max_depth': 50, 'min_samples_split': 10}          0.979524   \n",
       "7  {'max_depth': 50, 'min_samples_split': 20}          0.954968   \n",
       "\n",
       "   mean_test_score    diff, %  \n",
       "1         0.652250  28.513711  \n",
       "2         0.649245  25.928450  \n",
       "0         0.641545  30.848243  \n",
       "8         0.640543  30.092016  \n",
       "3         0.639679  34.475545  \n",
       "4         0.638564  32.979132  \n",
       "5         0.637586  30.213491  \n",
       "6         0.635997  35.070779  \n",
       "7         0.634126  33.597160  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)[['params', 'mean_train_score', 'mean_test_score']]\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:08.082930Z",
     "start_time": "2021-12-11T17:36:20.898319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 947.1696813106537 seconds\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=7)\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 4 x 3 x 3 = 36 combinations in the grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_depth': [5, 15, 30],\n",
    "    'min_samples_split': [5, 10, 20]\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:08.145332Z",
     "start_time": "2021-12-11T17:52:08.084929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>diff, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 500}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.815016</td>\n",
       "      <td>18.447407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 1000}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.811225</td>\n",
       "      <td>18.826733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 500}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.809618</td>\n",
       "      <td>18.987553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 1000}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.808318</td>\n",
       "      <td>19.117678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 500}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.808068</td>\n",
       "      <td>19.142700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 500}</td>\n",
       "      <td>0.996562</td>\n",
       "      <td>0.806829</td>\n",
       "      <td>19.038693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 1000}</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>0.806778</td>\n",
       "      <td>19.018431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 500}</td>\n",
       "      <td>0.994374</td>\n",
       "      <td>0.802435</td>\n",
       "      <td>19.302540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.801997</td>\n",
       "      <td>19.473118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 500}</td>\n",
       "      <td>0.996718</td>\n",
       "      <td>0.801635</td>\n",
       "      <td>19.572526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 1000}</td>\n",
       "      <td>0.996562</td>\n",
       "      <td>0.801081</td>\n",
       "      <td>19.615528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 200}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.799931</td>\n",
       "      <td>19.956897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 1000}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.799220</td>\n",
       "      <td>20.028016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.799159</td>\n",
       "      <td>20.034106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 200}</td>\n",
       "      <td>0.992187</td>\n",
       "      <td>0.796379</td>\n",
       "      <td>19.734917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 200}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.796306</td>\n",
       "      <td>20.319610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 1000}</td>\n",
       "      <td>0.994687</td>\n",
       "      <td>0.794892</td>\n",
       "      <td>20.086247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.994218</td>\n",
       "      <td>0.791815</td>\n",
       "      <td>20.358030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 200}</td>\n",
       "      <td>0.994843</td>\n",
       "      <td>0.791191</td>\n",
       "      <td>20.470726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.990312</td>\n",
       "      <td>0.789903</td>\n",
       "      <td>20.236967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}</td>\n",
       "      <td>0.954507</td>\n",
       "      <td>0.789168</td>\n",
       "      <td>17.321921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.993905</td>\n",
       "      <td>0.788087</td>\n",
       "      <td>20.708075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}</td>\n",
       "      <td>0.952944</td>\n",
       "      <td>0.787461</td>\n",
       "      <td>17.365452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.787153</td>\n",
       "      <td>21.223172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 1000}</td>\n",
       "      <td>0.946840</td>\n",
       "      <td>0.786694</td>\n",
       "      <td>16.913727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.785702</td>\n",
       "      <td>21.331414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 500}</td>\n",
       "      <td>0.946834</td>\n",
       "      <td>0.781563</td>\n",
       "      <td>17.455073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 500}</td>\n",
       "      <td>0.947302</td>\n",
       "      <td>0.779075</td>\n",
       "      <td>17.758488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 500}</td>\n",
       "      <td>0.941355</td>\n",
       "      <td>0.778959</td>\n",
       "      <td>17.251255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 200}</td>\n",
       "      <td>0.936194</td>\n",
       "      <td>0.778693</td>\n",
       "      <td>16.823497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.941362</td>\n",
       "      <td>0.774847</td>\n",
       "      <td>17.688799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.774678</td>\n",
       "      <td>22.483735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 200}</td>\n",
       "      <td>0.939950</td>\n",
       "      <td>0.769247</td>\n",
       "      <td>18.160941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.927887</td>\n",
       "      <td>0.762463</td>\n",
       "      <td>17.828081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.926176</td>\n",
       "      <td>0.760748</td>\n",
       "      <td>17.861371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.919736</td>\n",
       "      <td>0.758750</td>\n",
       "      <td>17.503473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              params  \\\n",
       "34   {'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 500}   \n",
       "35  {'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 1000}   \n",
       "26    {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 500}   \n",
       "27   {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 1000}   \n",
       "30   {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 500}   \n",
       "18   {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 500}   \n",
       "19  {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 1000}   \n",
       "22   {'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 500}   \n",
       "13    {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 200}   \n",
       "14    {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 500}   \n",
       "15   {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 1000}   \n",
       "29   {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 200}   \n",
       "31  {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 1000}   \n",
       "25    {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 200}   \n",
       "21   {'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 200}   \n",
       "33   {'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 200}   \n",
       "23  {'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 1000}   \n",
       "12    {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 100}   \n",
       "17   {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 200}   \n",
       "20   {'max_depth': 15, 'min_samples_split': 20, 'n_estimators': 100}   \n",
       "3     {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}   \n",
       "16   {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 100}   \n",
       "7    {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}   \n",
       "28   {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 100}   \n",
       "11   {'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 1000}   \n",
       "32   {'max_depth': 30, 'min_samples_split': 20, 'n_estimators': 100}   \n",
       "6     {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 500}   \n",
       "2      {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 500}   \n",
       "10    {'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 500}   \n",
       "9     {'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 200}   \n",
       "1      {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 200}   \n",
       "24    {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}   \n",
       "5     {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 200}   \n",
       "4     {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}   \n",
       "0      {'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}   \n",
       "8     {'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 100}   \n",
       "\n",
       "    mean_train_score  mean_test_score    diff, %  \n",
       "34          0.999375         0.815016  18.447407  \n",
       "35          0.999375         0.811225  18.826733  \n",
       "26          0.999375         0.809618  18.987553  \n",
       "27          0.999375         0.808318  19.117678  \n",
       "30          0.999375         0.808068  19.142700  \n",
       "18          0.996562         0.806829  19.038693  \n",
       "19          0.996249         0.806778  19.018431  \n",
       "22          0.994374         0.802435  19.302540  \n",
       "13          0.995937         0.801997  19.473118  \n",
       "14          0.996718         0.801635  19.572526  \n",
       "15          0.996562         0.801081  19.615528  \n",
       "29          0.999375         0.799931  19.956897  \n",
       "31          0.999375         0.799220  20.028016  \n",
       "25          0.999375         0.799159  20.034106  \n",
       "21          0.992187         0.796379  19.734917  \n",
       "33          0.999375         0.796306  20.319610  \n",
       "23          0.994687         0.794892  20.086247  \n",
       "12          0.994218         0.791815  20.358030  \n",
       "17          0.994843         0.791191  20.470726  \n",
       "20          0.990312         0.789903  20.236967  \n",
       "3           0.954507         0.789168  17.321921  \n",
       "16          0.993905         0.788087  20.708075  \n",
       "7           0.952944         0.787461  17.365452  \n",
       "28          0.999219         0.787153  21.223172  \n",
       "11          0.946840         0.786694  16.913727  \n",
       "32          0.998750         0.785702  21.331414  \n",
       "6           0.946834         0.781563  17.455073  \n",
       "2           0.947302         0.779075  17.758488  \n",
       "10          0.941355         0.778959  17.251255  \n",
       "9           0.936194         0.778693  16.823497  \n",
       "1           0.941362         0.774847  17.688799  \n",
       "24          0.999375         0.774678  22.483735  \n",
       "5           0.939950         0.769247  18.160941  \n",
       "4           0.927887         0.762463  17.828081  \n",
       "0           0.926176         0.760748  17.861371  \n",
       "8           0.919736         0.758750  17.503473  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)[['params', 'mean_train_score', 'mean_test_score']]\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the most important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:08.534463Z",
     "start_time": "2021-12-11T17:52:08.153313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad: 0.01012763195975312\n",
      "worst: 0.007295317299470134\n",
      "supposed: 0.004601026444555701\n",
      "waste: 0.004474678835466964\n",
      "boring: 0.004382501581631053\n",
      "stupid: 0.004376471394903765\n",
      "ridiculous: 0.004100202860159638\n",
      "life: 0.003971495389244511\n",
      "awful: 0.003923475979040344\n",
      "reason: 0.0033764147159750808\n",
      "plot: 0.00310844509310445\n",
      "lame: 0.003084276150923772\n",
      "script: 0.0029994261813080392\n",
      "dull: 0.002976750430702203\n",
      "mess: 0.002971203491250243\n",
      "better: 0.0029071293333055776\n",
      "great: 0.0028408260561642515\n",
      "movie: 0.0027524840896753096\n",
      "wonderfully: 0.0027469561177701205\n",
      "unfortunately: 0.002657658991420461\n",
      "worse: 0.0025836016140119732\n",
      "poor: 0.002492967386859242\n",
      "looks: 0.0024727491095436495\n",
      "problem: 0.002435864261799686\n",
      "wasted: 0.002348432160459075\n",
      "excellent: 0.0023401009873775455\n",
      "attempt: 0.002296575182907708\n",
      "performances: 0.0022028718431327823\n",
      "bland: 0.0021912683310899884\n",
      "dialogue: 0.002054419063239258\n",
      "maybe: 0.002038743526878255\n",
      "just: 0.0020286107057533318\n",
      "perfect: 0.0019964047711216416\n",
      "poorly: 0.0019770383975408353\n",
      "don: 0.0019096439306525432\n",
      "different: 0.0019063234712198213\n",
      "terrible: 0.001828671887841876\n",
      "tries: 0.001803450375877582\n",
      "wasn: 0.0017853780220064483\n",
      "world: 0.0017596363333552867\n",
      "make: 0.0017031228478503282\n",
      "memorable: 0.001692489636869473\n",
      "cheap: 0.0016827272738333175\n",
      "perfectly: 0.0016477364803212137\n",
      "rent: 0.0016276609235298808\n",
      "outstanding: 0.0016226959127291797\n",
      "true: 0.0016000233821390852\n",
      "minute: 0.0015754775466994759\n",
      "flat: 0.0015754005926433446\n",
      "minutes: 0.0014786790031033764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pekarv\\Anaconda3\\envs\\.env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# put them into a separate variable for convenience\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "# the order of the features in `feature_importances` is the same as in count_vectorizer.get_feature_names(),\n",
    "# so we can \"zip\" the two and print the first 50 in the descending order:\n",
    "for k, v in sorted(zip(feature_importances, count_vectorizer.get_feature_names_out()), reverse=True)[:50]:\n",
    "    print(f\"{v}: {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:09.275240Z",
     "start_time": "2021-12-11T17:52:08.535493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/rf-clf.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# create a folder where all trained models will be kept\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "    \n",
    "dump(grid_search.best_estimator_, 'models/rf-clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:28.723094Z",
     "start_time": "2021-12-11T17:52:09.278233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 19.43383479118347 seconds\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvm = LinearSVC(random_state=7, max_iter=10000)\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 7 combinations in the grid\n",
    "param_grid = {\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 5, 10]\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(lsvm, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:28.753971Z",
     "start_time": "2021-12-11T17:52:28.725083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>diff, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.856222</td>\n",
       "      <td>14.377845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>14.939852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846202</td>\n",
       "      <td>15.379848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845576</td>\n",
       "      <td>15.442441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845576</td>\n",
       "      <td>15.442441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.989368</td>\n",
       "      <td>0.835817</td>\n",
       "      <td>15.520090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.0001}</td>\n",
       "      <td>0.938045</td>\n",
       "      <td>0.737694</td>\n",
       "      <td>21.358343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          params  mean_train_score  mean_test_score    diff, %\n",
       "2    {'C': 0.01}          1.000000         0.856222  14.377845\n",
       "3     {'C': 0.1}          1.000000         0.850601  14.939852\n",
       "4       {'C': 1}          1.000000         0.846202  15.379848\n",
       "5       {'C': 5}          1.000000         0.845576  15.442441\n",
       "6      {'C': 10}          1.000000         0.845576  15.442441\n",
       "1   {'C': 0.001}          0.989368         0.835817  15.520090\n",
       "0  {'C': 0.0001}          0.938045         0.737694  21.358343"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)[['params', 'mean_train_score', 'mean_test_score']]\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the best model to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:28.800326Z",
     "start_time": "2021-12-11T17:52:28.755966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/svm-linear-clf.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(grid_search.best_estimator_, 'models/svm-linear-clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:56.245366Z",
     "start_time": "2021-12-11T17:52:28.801323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 27.428337335586548 seconds\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_poly = SVC(kernel=\"poly\", degree=2, random_state=7)\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 5 x 4 = 20 combinations in the grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': [\"scale\", 0.1, 0.5, 0.9],\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(svm_poly, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:52:56.293270Z",
     "start_time": "2021-12-11T17:52:56.250350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>diff, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820580</td>\n",
       "      <td>17.942004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803703</td>\n",
       "      <td>19.629682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'C': 10, 'gamma': 'scale'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802935</td>\n",
       "      <td>19.706465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.9}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>23.428634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749173</td>\n",
       "      <td>25.082685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 1, 'gamma': 'scale'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672644</td>\n",
       "      <td>32.735599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645834</td>\n",
       "      <td>35.416614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'C': 100, 'gamma': 'scale'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638676</td>\n",
       "      <td>36.132443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'C': 1, 'gamma': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'C': 10, 'gamma': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'C': 100, 'gamma': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'C': 10, 'gamma': 0.9}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'C': 100, 'gamma': 0.9}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'C': 1, 'gamma': 0.9}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.9}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>38.712646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1}</td>\n",
       "      <td>0.671546</td>\n",
       "      <td>0.340003</td>\n",
       "      <td>49.370137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale'}</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale'}</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           params  mean_train_score  mean_test_score  \\\n",
       "5        {'C': 0.1, 'gamma': 0.1}          1.000000         0.820580   \n",
       "2       {'C': 0.01, 'gamma': 0.5}          1.000000         0.803703   \n",
       "12    {'C': 10, 'gamma': 'scale'}          1.000000         0.802935   \n",
       "3       {'C': 0.01, 'gamma': 0.9}          1.000000         0.765714   \n",
       "9          {'C': 1, 'gamma': 0.1}          1.000000         0.749173   \n",
       "8      {'C': 1, 'gamma': 'scale'}          1.000000         0.672644   \n",
       "6        {'C': 0.1, 'gamma': 0.5}          1.000000         0.645834   \n",
       "16   {'C': 100, 'gamma': 'scale'}          1.000000         0.638676   \n",
       "10         {'C': 1, 'gamma': 0.5}          1.000000         0.612874   \n",
       "14        {'C': 10, 'gamma': 0.5}          1.000000         0.612874   \n",
       "18       {'C': 100, 'gamma': 0.5}          1.000000         0.612874   \n",
       "17       {'C': 100, 'gamma': 0.1}          1.000000         0.612874   \n",
       "15        {'C': 10, 'gamma': 0.9}          1.000000         0.612874   \n",
       "19       {'C': 100, 'gamma': 0.9}          1.000000         0.612874   \n",
       "13        {'C': 10, 'gamma': 0.1}          1.000000         0.612874   \n",
       "11         {'C': 1, 'gamma': 0.9}          1.000000         0.612874   \n",
       "7        {'C': 0.1, 'gamma': 0.9}          1.000000         0.612874   \n",
       "1       {'C': 0.01, 'gamma': 0.1}          0.671546         0.340003   \n",
       "4    {'C': 0.1, 'gamma': 'scale'}          0.337200         0.337199   \n",
       "0   {'C': 0.01, 'gamma': 'scale'}          0.337200         0.337199   \n",
       "\n",
       "      diff, %  \n",
       "5   17.942004  \n",
       "2   19.629682  \n",
       "12  19.706465  \n",
       "3   23.428634  \n",
       "9   25.082685  \n",
       "8   32.735599  \n",
       "6   35.416614  \n",
       "16  36.132443  \n",
       "10  38.712646  \n",
       "14  38.712646  \n",
       "18  38.712646  \n",
       "17  38.712646  \n",
       "15  38.712646  \n",
       "19  38.712646  \n",
       "13  38.712646  \n",
       "11  38.712646  \n",
       "7   38.712646  \n",
       "1   49.370137  \n",
       "4    0.000127  \n",
       "0    0.000127  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)[['params', 'mean_train_score', 'mean_test_score']]\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:53:26.501246Z",
     "start_time": "2021-12-11T17:52:56.295263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 30.19201636314392 seconds\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_poly = SVC(kernel=\"rbf\", gamma=\"scale\", random_state=7)\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 5 x 4 = 20 combinations in the grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': [\"scale\", 0.1, 0.5, 0.9],\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(svm_poly, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:53:26.597317Z",
     "start_time": "2021-12-11T17:53:26.503240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>diff, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'C': 100, 'gamma': 'scale'}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.850599</td>\n",
       "      <td>14.940077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'C': 10, 'gamma': 'scale'}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.850599</td>\n",
       "      <td>14.940077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 1, 'gamma': 'scale'}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.838058</td>\n",
       "      <td>16.194179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'C': 1, 'gamma': 0.5}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'C': 100, 'gamma': 0.5}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'C': 10, 'gamma': 0.5}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.345611</td>\n",
       "      <td>65.438925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'C': 1, 'gamma': 0.9}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.342814</td>\n",
       "      <td>65.718561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'C': 10, 'gamma': 0.9}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.342814</td>\n",
       "      <td>65.718561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'C': 100, 'gamma': 0.9}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.342814</td>\n",
       "      <td>65.718561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.9}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.5}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale'}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.9}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.01, 'gamma': 0.5}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale'}</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.337199</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           params  mean_train_score  mean_test_score  \\\n",
       "16   {'C': 100, 'gamma': 'scale'}            1.0000         0.850599   \n",
       "12    {'C': 10, 'gamma': 'scale'}            1.0000         0.850599   \n",
       "8      {'C': 1, 'gamma': 'scale'}            1.0000         0.838058   \n",
       "10         {'C': 1, 'gamma': 0.5}            1.0000         0.345611   \n",
       "18       {'C': 100, 'gamma': 0.5}            1.0000         0.345611   \n",
       "17       {'C': 100, 'gamma': 0.1}            1.0000         0.345611   \n",
       "14        {'C': 10, 'gamma': 0.5}            1.0000         0.345611   \n",
       "13        {'C': 10, 'gamma': 0.1}            1.0000         0.345611   \n",
       "9          {'C': 1, 'gamma': 0.1}            1.0000         0.345611   \n",
       "11         {'C': 1, 'gamma': 0.9}            1.0000         0.342814   \n",
       "15        {'C': 10, 'gamma': 0.9}            1.0000         0.342814   \n",
       "19       {'C': 100, 'gamma': 0.9}            1.0000         0.342814   \n",
       "1       {'C': 0.01, 'gamma': 0.1}            0.3372         0.337199   \n",
       "7        {'C': 0.1, 'gamma': 0.9}            0.3372         0.337199   \n",
       "6        {'C': 0.1, 'gamma': 0.5}            0.3372         0.337199   \n",
       "5        {'C': 0.1, 'gamma': 0.1}            0.3372         0.337199   \n",
       "4    {'C': 0.1, 'gamma': 'scale'}            0.3372         0.337199   \n",
       "3       {'C': 0.01, 'gamma': 0.9}            0.3372         0.337199   \n",
       "2       {'C': 0.01, 'gamma': 0.5}            0.3372         0.337199   \n",
       "0   {'C': 0.01, 'gamma': 'scale'}            0.3372         0.337199   \n",
       "\n",
       "      diff, %  \n",
       "16  14.940077  \n",
       "12  14.940077  \n",
       "8   16.194179  \n",
       "10  65.438925  \n",
       "18  65.438925  \n",
       "17  65.438925  \n",
       "14  65.438925  \n",
       "13  65.438925  \n",
       "9   65.438925  \n",
       "11  65.718561  \n",
       "15  65.718561  \n",
       "19  65.718561  \n",
       "1    0.000127  \n",
       "7    0.000127  \n",
       "6    0.000127  \n",
       "5    0.000127  \n",
       "4    0.000127  \n",
       "3    0.000127  \n",
       "2    0.000127  \n",
       "0    0.000127  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)[['params', 'mean_train_score', 'mean_test_score']]\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:53:26.661046Z",
     "start_time": "2021-12-11T17:53:26.602302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8518541797611565\n",
      "Recall: 0.8515978293638831\n",
      "F score: 0.8517206064375876\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "lsvm = load(\"models/svm-linear-clf.joblib\")\n",
    "\n",
    "yhat = lsvm.predict(X_test)\n",
    "\n",
    "# micro-averaged precision, recall and f-score\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, yhat, average=\"macro\")\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"Recall: {r}\")\n",
    "print(f\"F score: {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy scores on the test set turn out to be very similar to the one achieved during cross-validation.\n",
    "\n",
    "Plot a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:54:15.852292Z",
     "start_time": "2021-12-11T17:54:15.596140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x25fd6bebd30>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, yhat, labels=lsvm.classes_,\n",
    "                                        xticks_rotation=\"vertical\", normalize=\"true\",\n",
    "                                        cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify previously unseen reviews\n",
    "\n",
    "Some reviews from the Rotten Tomatoes website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T17:53:26.993250Z",
     "start_time": "2021-12-11T17:53:26.981249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Never let the audience off the hook, Hitchcock once said. \n",
      "               Ho achieves this in spades and with more than one hook. => neg\n",
      "\n",
      "The smartest mainstream film about class made in many \n",
      "               years, Bong Joon-ho's Parasite lays bare the lie that hard \n",
      "               work can bring anyone closer to their dreams. => pos\n",
      "\n",
      "[A] funny, inventive, scary film. => pos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_reviews = [\n",
    "               \"\"\"Never let the audience off the hook, Hitchcock once said. \n",
    "               Ho achieves this in spades and with more than one hook.\"\"\",\n",
    "    \n",
    "               \"\"\"The smartest mainstream film about class made in many \n",
    "               years, Bong Joon-ho's Parasite lays bare the lie that hard \n",
    "               work can bring anyone closer to their dreams.\"\"\",\n",
    "    \n",
    "               \"\"\"[A] funny, inventive, scary film.\"\"\"\n",
    "            ]\n",
    "\n",
    "# preprocess and transform\n",
    "new_reviews_counts = count_vectorizer.transform(new_reviews)\n",
    "new_reviews_tfidf = tfidf_transformer.transform(new_reviews_counts)\n",
    "new_scaled = scaler.transform(new_reviews_tfidf)\n",
    "\n",
    "# predict labels\n",
    "predictions = lsvm.predict(new_scaled)\n",
    "\n",
    "# print results\n",
    "for review, category in zip(new_reviews, predictions):\n",
    "    print(f'{review} => {movie.target_names[category]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citing this notebook\n",
    "\n",
    "If you use this notebook in your work, please cite it as follows:\n",
    "    \n",
    "Pekar, V. (2022). Big Data for Decision Making. Lecture examples and exercises. (Version 1.0.0). URL: https://github.com/vpekar/bd4dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
