{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase-level sentiment analysis\n",
    "\n",
    "Please make sure you have downloaded the polarity data using \"Document-Level Sentiment Analysis.ipynb\" before you run this notebook.\n",
    "\n",
    "You may also need to first install SpaCy and the English model to be able to process English text. To do that, please run the following commands on the Anaconda prompt:\n",
    "\n",
    "> conda install spacy\n",
    "\n",
    "> python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T16:59:52.350609Z",
     "start_time": "2021-11-26T16:59:49.769362Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\pekarv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "    \n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T16:59:54.110909Z",
     "start_time": "2021-11-26T16:59:53.343216Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "MAX_DIST = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T16:59:54.721545Z",
     "start_time": "2021-11-26T16:59:54.699479Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dep_graph(sentence):\n",
    "    deps = {}\n",
    "    for word in sentence:\n",
    "        if word.i != word.head.i:\n",
    "            deps[word.i] = word.head.i\n",
    "    return deps\n",
    "\n",
    "def get_path_to_root(w_id, deps, path):\n",
    "    path.append(w_id) \n",
    "    if not deps.get(w_id):\n",
    "        return path\n",
    "    else:\n",
    "        return get_path_to_root(deps[w_id], deps, path)\n",
    "\n",
    "def build_all_paths(sentence, sdict):\n",
    "    deps = get_dep_graph(sentence)\n",
    "    e2paths = {}\n",
    "    s2paths = {}\n",
    "    for w in sentence:\n",
    "        if w.ent_iob_ in \"BI\":\n",
    "            path = get_path_to_root(w.i, deps, [])\n",
    "            if w.ent_id in e2paths:\n",
    "                prev_path = e2paths[w.ent_id]\n",
    "                if len(path) < len(prev_path):\n",
    "                    e2paths[w.ent_id] = path\n",
    "            else:\n",
    "                e2paths[w.ent_id] = path\n",
    "        score = sdict.get(w.lemma_)\n",
    "        if score:\n",
    "            s2paths[w.i] = (get_path_to_root(w.i, deps, []), score, w.text)\n",
    "    return e2paths, s2paths\n",
    "\n",
    "def get_distance(p1, p2):\n",
    "    \"\"\"Measure the distance between two paths to the root in the number of edges\n",
    "    \"\"\"\n",
    "    common = None\n",
    "    for i in p1:\n",
    "        if i in p2:\n",
    "            common = i\n",
    "            break\n",
    "    if common:\n",
    "        return p1.index(common) + p2.index(common)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def process_sentence(sentence, sdict):\n",
    "    global MAX_DIST\n",
    "    # entities\n",
    "    ents = dict([(e.ent_id, (e.text, e.label_)) for e in sentence.ents])\n",
    "\n",
    "    e2paths, s2paths = build_all_paths(sentence, sdict)\n",
    "\n",
    "    for eid, p1 in e2paths.items():\n",
    "        for sid, (p2, score, w_text) in s2paths.items():\n",
    "            d = get_distance(p1, p2)\n",
    "            if d is not None and d < MAX_DIST:\n",
    "                e_text, e_label = ents[eid]\n",
    "                yield e_text, e_label, score, w_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T16:59:55.928256Z",
     "start_time": "2021-11-26T16:59:55.914175Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_lexicon = SentimentIntensityAnalyzer().lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T17:02:00.122526Z",
     "start_time": "2021-11-26T17:01:52.903374Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "df = pd.DataFrame(columns=['name', 'label', 'sentiment', 'description', 'text'])\n",
    "ids = 0\n",
    "\n",
    "for fn in glob(r\"datasets\\txt_sentoken\\*\\*\"):\n",
    "    try:\n",
    "        raw = open(fn).read()\n",
    "    except PermissionError:\n",
    "        print(f\"Permission error: {fn}\")\n",
    "        continue\n",
    "    for text in raw.split(\"\\n\"):        \n",
    "        for s in nlp(text).sents:\n",
    "            parsed_sentence = nlp(s.text)\n",
    "            for e_text, e_label, score, w_text in process_sentence(parsed_sentence, sentiment_lexicon):\n",
    "                if e_label in [\"PERSON\"] and len(e_text.strip()) > 3:\n",
    "                    ids += 1\n",
    "                    df.loc[ids] = [e_text, e_label, score, w_text, s.text]\n",
    "        if ids > 10000:\n",
    "            break\n",
    "    if ids > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T17:02:03.527674Z",
     "start_time": "2021-11-26T17:02:03.508624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>king arthur's</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1.3</td>\n",
       "      <td>spirited</td>\n",
       "      <td>the story revolves around the adventures of fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>williams</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>criminal</td>\n",
       "      <td>instead of having the criminal \" napolean \" wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>george c</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1.5</td>\n",
       "      <td>like</td>\n",
       "      <td>the deeper welles digs into his investigation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hugh</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1.5</td>\n",
       "      <td>grant</td>\n",
       "      <td>it's a terrible mess of a movie starring a ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adam sandler-annoying</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>annoying</td>\n",
       "      <td>not just adam sandler-annoying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jim carrey</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>annoying</td>\n",
       "      <td>, we're talking jim carrey-annoying .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dreadful hideaway</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>hid</td>\n",
       "      <td>the only interesting character in the movie is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yakov smirnov</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1.2</td>\n",
       "      <td>joke</td>\n",
       "      <td>his is a one-joke character-- the old foreign-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>suvari</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>fault</td>\n",
       "      <td>now i'm not sure if this was ms . suvari's fau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>john harrigan</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1.4</td>\n",
       "      <td>plays</td>\n",
       "      <td>cox plays the role of big john harrigan in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>o'hara</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>hates</td>\n",
       "      <td>also no points for guessing garofalo hates o'h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name   label  sentiment description  \\\n",
       "1           king arthur's  PERSON        1.3    spirited   \n",
       "2                williams  PERSON       -2.4    criminal   \n",
       "3                george c  PERSON        1.5        like   \n",
       "4                    hugh  PERSON        1.5       grant   \n",
       "5   adam sandler-annoying  PERSON       -1.7    annoying   \n",
       "6              jim carrey  PERSON       -1.7    annoying   \n",
       "7       dreadful hideaway  PERSON       -0.7         hid   \n",
       "8           yakov smirnov  PERSON        1.2        joke   \n",
       "9                  suvari  PERSON       -1.7       fault   \n",
       "10          john harrigan  PERSON        1.4       plays   \n",
       "11                 o'hara  PERSON       -2.7       hates   \n",
       "\n",
       "                                                 text  \n",
       "1   the story revolves around the adventures of fr...  \n",
       "2   instead of having the criminal \" napolean \" wi...  \n",
       "3   the deeper welles digs into his investigation ...  \n",
       "4   it's a terrible mess of a movie starring a ter...  \n",
       "5                      not just adam sandler-annoying  \n",
       "6               , we're talking jim carrey-annoying .  \n",
       "7   the only interesting character in the movie is...  \n",
       "8   his is a one-joke character-- the old foreign-...  \n",
       "9   now i'm not sure if this was ms . suvari's fau...  \n",
       "10  cox plays the role of big john harrigan in the...  \n",
       "11  also no points for guessing garofalo hates o'h...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T17:03:31.714479Z",
     "start_time": "2021-11-26T17:03:31.708463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('jim carrey', -1.7)\n",
      "('john harrigan', 1.4)\n"
     ]
    }
   ],
   "source": [
    "actors = [\"jim carrey\", \"john harrigan\"]\n",
    "\n",
    "for x in df.groupby(\"name\")[\"sentiment\"].mean().sort_values().iteritems():\n",
    "    if x[0] in actors:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "authors": [{ "name": "Viktor Pekar" }],
    "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

