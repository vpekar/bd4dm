{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "The exercise is concerned with the Boston house-prices dataset, which is part of the scikit-learn distribution. The target variable in the dataset is the value of the house in $1000's.\n",
    "\n",
    "The task is:\n",
    "\n",
    "1. Train and evaluate a second-degree polynomial regression model using a 0.1 train-test split.\n",
    "2. Plot the training and validation curves for the model.\n",
    "3. Comment on whether the trained model displays any overfitting, and if regularization is likely to improve the model's accuracy.\n",
    "4. Confirm if you are right by evaluating a Ridge and Lasso models, and by plotting their learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(palette=\"Set2\")\n",
    "\n",
    "# import code to create polynomial features\n",
    "from sklearn.preprocessing import ???\n",
    "\n",
    "# import code for linear regression\n",
    "from sklearn.linear_model import ???\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "X_full, y_full = dataset.data, dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train and evaluate a second-degree polynomial regression model using a 0.1 train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create second-degree polynomial features\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"Given a model object, predictors and the target, fit and evaluate a model,\n",
    "    output its RMSE on the training set and on the validation set\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=7)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_predict = model.predict(X_train)\n",
    "    y_val_predict = model.predict(X_val)\n",
    "\n",
    "    # record the results\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_predict, y_train))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val_predict, y_val))\n",
    "    \n",
    "    return train_rmse, val_rmse\n",
    "\n",
    "\n",
    "# run the evaluation\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(model, X, y):\n",
    "    \n",
    "    # create a train-test split\n",
    "    \n",
    "    ???\n",
    "    \n",
    "    train_errors, val_errors = [], []\n",
    "    \n",
    "    # take different sizes of the training data, starting from 50s instance, with the step of 10\n",
    "    for m in range(50, len(X_train), 10):\n",
    "        \n",
    "        # fit a model\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        \n",
    "        # evaluate the model on both training and validation sets\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        \n",
    "        # calculate RMSE and record the results\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train_predict, y_train[:m]))\n",
    "        val_rmse = np.sqrt(mean_squared_error(y_val_predict, y_val))\n",
    "        \n",
    "        train_errors.append(train_rmse)\n",
    "        val_errors.append(val_rmse)\n",
    "        \n",
    "    # make a plot\n",
    "    plt.plot(train_errors, \"r-\", linewidth=2, label=\"train\")\n",
    "    plt.plot(val_errors, \"b-\", linewidth=3, label=\"val\")\n",
    "    plt.ylim(0, 45)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"Training set size (in tens of instances)\")\n",
    "    plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Plot the training and validation curves for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Comment on whether the trained model displays any overfitting, and if regularization is likely to improve the model's accuracy.\n",
    "\n",
    "Comment:\n",
    "> ???\n",
    "\n",
    "4. Confirm if you are right by evaluating a Ridge and Lasso models, and by plotting their learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# first standartize X_poly\n",
    "scaler = StandardScaler()\n",
    "X_poly_st = scaler.fit_transform(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate ridge regression\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ridge regression\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try LASSO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LASSO\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves for LASSO\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
