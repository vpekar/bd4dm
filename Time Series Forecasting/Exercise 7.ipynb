{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting time series\n",
    "\n",
    "The task is to build a Decision Tree and a Random Forest models to predict the sales amounts of chairs in a furniture shop, given past data on the sales of chairs and other types of furniture. The accuracy of the models should be measured in terms of RMSE and compared to a persistence baseline.\n",
    "\n",
    "Experiment with different hyperparameter settings for the Decision Tree and Random Forest algorithms to find the best models. Comment on how these models compare with forecasts of sales of chairs achieved with a VAR model from the previous exercise.\n",
    "\n",
    "Please use \"furniture_subcategories.csv\", which contains the same prorocessed data as in the previous exercise.\n",
    "\n",
    "Complete the solution by writing code and comments in places indicated with \"???\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting logging to print only error messages from Sklearnex\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"SKLEARNEX\").setLevel(logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(palette=\"Set2\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "We'll read the pre-processed data, and then re-arrange the columns so that \"Chairs\" is the last column. It will later be used to create the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_dates=[\"Order Date\"] converts the column to datetime automatically,\n",
    "# guessing the date format \n",
    "df = pd.read_csv(\"furniture_subcategories.csv\",\n",
    "                 index_col=\"Order Date\", \n",
    "                 parse_dates=[\"Order Date\"])\n",
    "df = df[['Bookcases', 'Tables', 'Furnishings', 'Chairs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split\n",
    "\n",
    "We will use random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = ???\n",
    "\n",
    "# make sure the training and test sets have the same column name as dfs\n",
    "train_set.columns = df.columns\n",
    "test_set.columns = df.columns\n",
    "\n",
    "print(f\"{train_set.shape[0]} train and {test_set.shape[0]} test instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Let's plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot(figsize=(16,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does not appear any seasonality or trend in the series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and transformation\n",
    "\n",
    "Before we can start buinding a model, we need to ensure all the columns are **stationary**. We will use the Augmented Dickey-Fuller (ADF) test and the KPSS (Kwiatkowski-Phillips-Schmidt-Shin) tests to test the series for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment ??? (2-3 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???\n",
    "train_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_diff.columns:\n",
    "    print(x)\n",
    "    ???\n",
    "    print(f\"ADF, p-value: {adf_pval}\")\n",
    "    ???\n",
    "    print(f\"KPSS, p-value: {kpss_pval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment??? (2-3 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_diff = test_set.diff().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models\n",
    "\n",
    "## Baseline\n",
    "\n",
    "The persistence baseline is outputting the previous day's sales of chairs as the prediction of this day's sales amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_predictions = test_diff[\"Chairs\"].shift()[1:]\n",
    "mse = mean_squared_error(test_diff[\"Chairs\"][1:], baseline_predictions)\n",
    "baseline_rmse = np.sqrt(mse)\n",
    "print(f\"{x}: {baseline_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra transformation steps\n",
    "\n",
    "We need to do some transformation steps required to be able to input the data into the scikit-learn's implementation of the ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ar_vars(endog, exog, lags=2):\n",
    "    \"\"\"Create autoregressive variables from endogenous and exogenous\n",
    "    variables\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(endog)-lags):\n",
    "        endog_row = endog[i:i + lags, 0]\n",
    "        exog_row = exog[i:i + lags,:].flatten()\n",
    "        X.append(np.concatenate([endog_row, exog_row]))\n",
    "        y.append(endog[i + lags, 0])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create separate arrays for the predictors and the target, for both the training and test data. Similar to the VAR model, we'll use 2 lags to create autoregressive variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, ytrain = create_ar_vars(endog=train_diff[\"Chairs\"].values.reshape(-1, 1),\n",
    "                                exog=train_diff[[\"Bookcases\", \"Tables\", \"Furnishings\"]].values.reshape(-1, 1), \n",
    "                                lags=2)\n",
    "\n",
    "Xtest, ytest = create_ar_vars(endog=test_diff[\"Chairs\"].values.reshape(-1, 1), \n",
    "                              exog=test_diff[[\"Bookcases\", \"Tables\", \"Furnishings\"]].values.reshape(-1, 1),\n",
    "                              lags=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both predictor arrays need to be scaled (but the target variable should not be transformed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = ???\n",
    "Xtrain = ???\n",
    "Xtest = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use a grid search to find the most optimal hyperparameters settings.\n",
    "\n",
    "## Decision Tree regression\n",
    "\n",
    "We'll fine-tune `min_samples_split` (the minimum number of instances required to be at a node before it gets split) and `max_depth` (the maximum depth of each tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeRegressor(random_state=7)\n",
    "param_grid = [\n",
    "    {'max_depth': [???, None],\n",
    "    'min_samples_split': [2, ???]}\n",
    "]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "dtree_grid_search = GridSearchCV(estimator=dtree, cv=tscv,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring='neg_mean_squared_error', \n",
    "                        return_train_score=True)\n",
    "\n",
    "start = time.time()\n",
    "dtree_grid_search.fit(Xtrain, ytrain)\n",
    "duration = time.time() - start\n",
    "print(f'Took {duration:.3f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(dtree_grid_search.cv_results_)[['params', 'mean_train_score', \n",
    "                                                    'mean_test_score']]\n",
    "cv_results[\"mean_train_score\"] = np.sqrt(-cv_results[\"mean_train_score\"])\n",
    "cv_results[\"mean_test_score\"] = np.sqrt(-cv_results[\"mean_test_score\"])\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "cv_results.sort_values('mean_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest regression\n",
    "\n",
    "We'll fine-tune `n_estimators` (the number of decision trees used in the random forest) as well as `min_samples_split` and `max_depth` (hyperparameters of specific trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=7)\n",
    "param_grid = [\n",
    "    {'n_estimators': [10, ???], \n",
    "     'max_depth': [???, None],\n",
    "     'min_samples_split': [2, ???]\n",
    "    },\n",
    "]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rf_grid_search = GridSearchCV(estimator=rf, cv=tscv,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring='neg_mean_squared_error', \n",
    "                        return_train_score=True)\n",
    "\n",
    "start = time.time()\n",
    "rf_grid_search.fit(Xtrain, ytrain)\n",
    "duration = time.time() - start\n",
    "print(f'Took {duration:.3f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the accuracy scores for every model evaluated during the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(rf_grid_search.cv_results_)[['params', 'mean_train_score', \n",
    "                                                    'mean_test_score']]\n",
    "cv_results[\"mean_train_score\"] = np.sqrt(-cv_results[\"mean_train_score\"])\n",
    "cv_results[\"mean_test_score\"] = np.sqrt(-cv_results[\"mean_test_score\"])\n",
    "cv_results[\"diff, %\"] = 100*(cv_results[\"mean_train_score\"]-cv_results[\"mean_test_score\"]\n",
    "                                                     )/cv_results[\"mean_train_score\"]\n",
    "\n",
    "cv_results.sort_values('mean_test_score', inplace=True)\n",
    "\n",
    "# set the width of the params column\n",
    "cv_results.style.set_properties(subset=['params'], **{'width': '200px'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment??? (one-two sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the best DT and RF models on the test data\n",
    "\n",
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = dtree_grid_search.best_estimator_\n",
    "\n",
    "yhat = best_model.predict(Xtest)\n",
    "\n",
    "dtree_mse = mean_squared_error(ytest, yhat)\n",
    "dtree_rmse = np.sqrt(dtree_mse)\n",
    "dtree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By how much did the Decision Tree model improve on the persistence baseline, percent-wise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rf_grid_search.best_estimator_\n",
    "\n",
    "yhat = best_model.predict(Xtest)\n",
    "\n",
    "rf_mse = mean_squared_error(ytest, yhat)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "rf_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By how much did the Random Forest model improve on the persistence baseline, percent-wise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Comment ??? (one-two sentences)\n",
    "\n",
    "Mention how the accuracy of the ML models compares to that of the VAR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
